{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wkxyA95fD2a2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import copy\n",
        "from scipy.fft import fft, fftfreq \n",
        "import pickle\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import math\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wk20N9WTMAyO",
        "outputId": "412136b8-01b4-479d-f9e9-a013644d7bd8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Currently selected TF version: 2.x\n",
            "Available versions:\n",
            "* 1.x\n",
            "* 2.x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"TensorFlow version = {tf.__version__}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQIFNYbMLafp",
        "outputId": "aad614c6-ae84-48d4-a722-b0449a23ffce"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version = 2.8.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-lkwL4UcD2a3"
      },
      "outputs": [],
      "source": [
        "logdir = \"logs/scalars/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-r66RkFVD2a4"
      },
      "outputs": [],
      "source": [
        "SAMPLE_RATE = 119\n",
        "LABEL_MAP = {\"RIGHT\": 1, \"LEFT\": -1}\n",
        "WINDOW_SIZE = 150 #this should be variable\n",
        "WINDOW_STEP = 1 #this should be variable\n",
        "SIGNALS = \"aX,aY,aZ,gX,gY,gZ,mX,mY,mZ\"\n",
        "SIGNALS = SIGNALS.split(\",\")\n",
        "FEATURES = \"max,min,mean,var,median\"#,amplitude,freq\"\n",
        "FEATURES = FEATURES.split(\",\")\n",
        "MOVE_SIZE = 150\n",
        "FEATURES_PER_WINDOW = 45\n",
        "CLASSES = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JzwdRvqpD2a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "874952f2-3a5d-40ba-83af-42a992cf2300"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-2fdc8d4bab3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"still_first.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'still_first.csv'"
          ]
        }
      ],
      "source": [
        "data_df = pd.read_csv(\"still_first.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "n6s78dXYD2a5",
        "outputId": "737fa278-607a-429c-dd7a-1490890e8754"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-56f2bcef6264>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclean_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'clean_data' is not defined"
          ]
        }
      ],
      "source": [
        "clean_data(data_df)\n",
        "data_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DkDv5GmJD2a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "f0826775-f431-4db7-a4a9-be9c8a5a8649"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-8354168ca5cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabel_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"still_home_1.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'still_home_1.csv'"
          ]
        }
      ],
      "source": [
        "label_df = pd.read_csv(\"still_home_1.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BH2bkbJuD2a7",
        "outputId": "26d55bf3-b963-4a8e-de0d-05c11b928f5c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ddbabd05-1d5b-49bd-a8db-fe42ca4ac5fe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>move</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22:6:22:208</td>\n",
              "      <td>LEFT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>22:6:28:846</td>\n",
              "      <td>LEFT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22:6:36:977</td>\n",
              "      <td>LEFT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>22:6:45:429</td>\n",
              "      <td>RIGHT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>22:6:54:451</td>\n",
              "      <td>LEFT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>22:7:18:213</td>\n",
              "      <td>LEFT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>22:7:23:283</td>\n",
              "      <td>RIGHT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>22:7:34:758</td>\n",
              "      <td>LEFT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>22:7:40:203</td>\n",
              "      <td>LEFT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>22:7:51:639</td>\n",
              "      <td>RIGHT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>22:7:56:328</td>\n",
              "      <td>RIGHT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>22:8:33:379</td>\n",
              "      <td>LEFT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>22:8:49:670</td>\n",
              "      <td>RIGHT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>22:8:53:975</td>\n",
              "      <td>RIGHT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>22:9:0:381</td>\n",
              "      <td>LEFT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>22:9:7:719</td>\n",
              "      <td>RIGHT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>22:9:13:507</td>\n",
              "      <td>LEFT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>22:9:19:961</td>\n",
              "      <td>LEFT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>22:10:0:984</td>\n",
              "      <td>RIGHT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>22:10:8:368</td>\n",
              "      <td>LEFT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>22:10:13:845</td>\n",
              "      <td>RIGHT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>22:10:23:549</td>\n",
              "      <td>RIGHT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22:10:28:448</td>\n",
              "      <td>LEFT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>22:10:34:209</td>\n",
              "      <td>LEFT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>22:10:42:175</td>\n",
              "      <td>RIGHT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>22:10:50:269</td>\n",
              "      <td>LEFT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>22:11:12:418</td>\n",
              "      <td>LEFT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>22:11:15:925</td>\n",
              "      <td>RIGHT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>22:11:25:737</td>\n",
              "      <td>RIGHT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>22:11:32:199</td>\n",
              "      <td>RIGHT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>22:11:37:270</td>\n",
              "      <td>LEFT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>22:11:43:794</td>\n",
              "      <td>LEFT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>22:11:52:568</td>\n",
              "      <td>RIGHT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>22:12:0:192</td>\n",
              "      <td>LEFT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>22:12:6:855</td>\n",
              "      <td>RIGHT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>22:12:12:281</td>\n",
              "      <td>RIGHT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>22:12:20:651</td>\n",
              "      <td>LEFT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>22:12:27:656</td>\n",
              "      <td>RIGHT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>22:12:32:426</td>\n",
              "      <td>LEFT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>22:12:40:146</td>\n",
              "      <td>LEFT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>22:12:51:493</td>\n",
              "      <td>LEFT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>22:12:57:390</td>\n",
              "      <td>RIGHT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>22:13:40:230</td>\n",
              "      <td>RIGHT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>22:13:44:682</td>\n",
              "      <td>LEFT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>22:13:51:437</td>\n",
              "      <td>LEFT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>22:13:55:967</td>\n",
              "      <td>RIGHT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>22:14:2:704</td>\n",
              "      <td>LEFT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>22:14:10:209</td>\n",
              "      <td>RIGHT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>22:14:15:755</td>\n",
              "      <td>LEFT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>22:14:23:879</td>\n",
              "      <td>RIGHT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>22:14:28:320</td>\n",
              "      <td>RIGHT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>22:14:36:260</td>\n",
              "      <td>RIGHT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>22:14:44:864</td>\n",
              "      <td>LEFT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>22:14:51:900</td>\n",
              "      <td>RIGHT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>22:14:58:275</td>\n",
              "      <td>LEFT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>22:15:8:503</td>\n",
              "      <td>LEFT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>22:15:16:119</td>\n",
              "      <td>RIGHT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>22:15:23:288</td>\n",
              "      <td>RIGHT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>22:15:30:946</td>\n",
              "      <td>LEFT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>22:15:36:285</td>\n",
              "      <td>LEFT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ddbabd05-1d5b-49bd-a8db-fe42ca4ac5fe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ddbabd05-1d5b-49bd-a8db-fe42ca4ac5fe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ddbabd05-1d5b-49bd-a8db-fe42ca4ac5fe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            time   move\n",
              "0    22:6:22:208   LEFT\n",
              "1    22:6:28:846   LEFT\n",
              "2    22:6:36:977   LEFT\n",
              "3    22:6:45:429  RIGHT\n",
              "4    22:6:54:451   LEFT\n",
              "5    22:7:18:213   LEFT\n",
              "6    22:7:23:283  RIGHT\n",
              "7    22:7:34:758   LEFT\n",
              "8    22:7:40:203   LEFT\n",
              "9    22:7:51:639  RIGHT\n",
              "10   22:7:56:328  RIGHT\n",
              "11   22:8:33:379   LEFT\n",
              "12   22:8:49:670  RIGHT\n",
              "13   22:8:53:975  RIGHT\n",
              "14    22:9:0:381   LEFT\n",
              "15    22:9:7:719  RIGHT\n",
              "16   22:9:13:507   LEFT\n",
              "17   22:9:19:961   LEFT\n",
              "18   22:10:0:984  RIGHT\n",
              "19   22:10:8:368   LEFT\n",
              "20  22:10:13:845  RIGHT\n",
              "21  22:10:23:549  RIGHT\n",
              "22  22:10:28:448   LEFT\n",
              "23  22:10:34:209   LEFT\n",
              "24  22:10:42:175  RIGHT\n",
              "25  22:10:50:269   LEFT\n",
              "26  22:11:12:418   LEFT\n",
              "27  22:11:15:925  RIGHT\n",
              "28  22:11:25:737  RIGHT\n",
              "29  22:11:32:199  RIGHT\n",
              "30  22:11:37:270   LEFT\n",
              "31  22:11:43:794   LEFT\n",
              "32  22:11:52:568  RIGHT\n",
              "33   22:12:0:192   LEFT\n",
              "34   22:12:6:855  RIGHT\n",
              "35  22:12:12:281  RIGHT\n",
              "36  22:12:20:651   LEFT\n",
              "37  22:12:27:656  RIGHT\n",
              "38  22:12:32:426   LEFT\n",
              "39  22:12:40:146   LEFT\n",
              "40  22:12:51:493   LEFT\n",
              "41  22:12:57:390  RIGHT\n",
              "42  22:13:40:230  RIGHT\n",
              "43  22:13:44:682   LEFT\n",
              "44  22:13:51:437   LEFT\n",
              "45  22:13:55:967  RIGHT\n",
              "46   22:14:2:704   LEFT\n",
              "47  22:14:10:209  RIGHT\n",
              "48  22:14:15:755   LEFT\n",
              "49  22:14:23:879  RIGHT\n",
              "50  22:14:28:320  RIGHT\n",
              "51  22:14:36:260  RIGHT\n",
              "52  22:14:44:864   LEFT\n",
              "53  22:14:51:900  RIGHT\n",
              "54  22:14:58:275   LEFT\n",
              "55   22:15:8:503   LEFT\n",
              "56  22:15:16:119  RIGHT\n",
              "57  22:15:23:288  RIGHT\n",
              "58  22:15:30:946   LEFT\n",
              "59  22:15:36:285   LEFT"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "label_df[\"time\"] = label_df[\"time\"].str.replace(\" \", \"\")\n",
        "label_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xcWzn1mnD2a5"
      },
      "outputs": [],
      "source": [
        "def clean_data(data_df):\n",
        "    data_df.rename(columns={data_df.columns[0] : \"time\"}, inplace=True)\n",
        "    data_df[\"time\"] = data_df[\"time\"].str.strip(\"\\t\")\n",
        "    data_df.drop(data_df.tail(1).index,inplace=True) # drop last n rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0sk05pkTD2a7"
      },
      "outputs": [],
      "source": [
        "def get_sig_stats(sig):\n",
        "    maxi, mini = np.max(sig), np.min(sig)\n",
        "    avg, var = np.mean(sig), np.var(sig)\n",
        "    median = np.median(sig)\n",
        "    \n",
        "    #_sig = copy.deepcopy(sig)\n",
        "    #_sig = _sig - np.mean(sig)\n",
        "    \n",
        "    #fourierTransform = np.fft.rfft(_sig)/len(_sig)           # Normalize amplitude\n",
        "    #fourierTransform = fourierTransform[range(int(len(_sig)/2))] # Exclude sampling frequency\n",
        "    \n",
        "    #amplitude, freq = np.abs(np.max(fourierTransform)), np.argmax(fourierTransform)\n",
        "    \n",
        "    return maxi, mini, avg, var, median#, amplitude, freq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Uirf5eXLD2a8"
      },
      "outputs": [],
      "source": [
        "def normalize_columns(values, column_type=\"g\"):\n",
        "    if column_type == \"g\":\n",
        "        mini, maxi, start_col, stop_col = -2000, 2000, 3, 6\n",
        "    elif column_type == \"a\":\n",
        "        mini, maxi, start_col, stop_col = -4, 4, 0, 3\n",
        "    elif column_type == \"m\":\n",
        "        mini, maxi, start_col, stop_col = -400, 400, 6, 9\n",
        "    \n",
        "    values[:, start_col:stop_col] = (values[:, start_col:stop_col] - mini)/(maxi-mini) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7-8sI_wRD2a8"
      },
      "outputs": [],
      "source": [
        "def generate_columns(features, sigs):\n",
        "    cols = []\n",
        "    for sig in sigs:\n",
        "        for ft in features:\n",
        "            cols.append(sig + \"_\" + ft)\n",
        "            \n",
        "    return cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nh7wsXHhD2a8"
      },
      "outputs": [],
      "source": [
        "def fill_windows_list(windows_list, signals):\n",
        "    for sig in range(len(signals)):\n",
        "        signal = signals[sig]\n",
        "        #print(signal.shape)\n",
        "        #break\n",
        "        i = 0\n",
        "        while i < (len(windows_list)):\n",
        "            sig_to_eval = signal[i:i+WINDOW_SIZE]\n",
        "            #print(sig_to_eval.shape)\n",
        "            windows_list[i, sig*len(FEATURES):sig*len(FEATURES)+len(FEATURES)] = np.array(get_sig_stats(sig_to_eval))\n",
        "            i += WINDOW_STEP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "e40vwhoKD2a9"
      },
      "outputs": [],
      "source": [
        "def time_to_float(time_list):\n",
        "    float_list = []\n",
        "    for t in time_list:\n",
        "        ti = t.split(\":\")\n",
        "        my_float = 0\n",
        "        if len(ti) == 3:\n",
        "            my_float += int(ti[0]) * 3600 + int(ti[1]) * 60 + float(ti[2])\n",
        "        elif len(ti) == 4:\n",
        "            my_float += int(ti[0]) * 3600 + int(ti[1]) * 60 + int(ti[2]) + float(\"0.\" + ti[3])\n",
        "            \n",
        "        float_list.append(my_float)\n",
        "        \n",
        "    return float_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "P0FVQVdbD2a9"
      },
      "outputs": [],
      "source": [
        "def find_starting_point(elem, search_list):\n",
        "    for i in range(len(search_list) - 1):\n",
        "        if elem >= search_list[i] and elem <= search_list[i+1]:\n",
        "            return i+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "viofdMk0D2a9"
      },
      "outputs": [],
      "source": [
        "def convert_df_time(label, data):\n",
        "    label_time_list = label[\"time\"].to_list()\n",
        "    data_time_list = data[\"time\"].to_list()\n",
        "    \n",
        "    label_float_list = time_to_float(label_time_list)\n",
        "    data_float_list = time_to_float(data_time_list)\n",
        "    \n",
        "    label[\"time\"] = label_float_list\n",
        "    data[\"time\"] = data_float_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "OAscXM77D2a9"
      },
      "outputs": [],
      "source": [
        "def create_label_entries(label, data, threshold=0.8, normalize=True):    \n",
        "    signals = data.values\n",
        "    signals = copy.deepcopy(signals[:, 1:])\n",
        "    \n",
        "    if normalize:\n",
        "        normalize_columns(signals, \"a\")\n",
        "        normalize_columns(signals, \"g\")\n",
        "        normalize_columns(signals, \"m\")\n",
        "    \n",
        "    signals = np.transpose(signals)\n",
        "    \n",
        "    labels_no_window_list = np.zeros((len(data), ))    \n",
        "    labels_window_list = np.zeros((len(data) - WINDOW_SIZE, ))  \n",
        "    \n",
        "    windows_list = np.zeros((len(data) - WINDOW_SIZE, len(SIGNALS)*len(FEATURES)))\n",
        "    \n",
        "    fill_windows_list(windows_list, signals)\n",
        "    \n",
        "    label_float_list = label[\"time\"].to_list()\n",
        "    data_float_list = data[\"time\"].to_list()\n",
        "    \n",
        "    for i_label in range(len(label)):\n",
        "        label_start_point = find_starting_point(label_float_list[i_label], data_float_list)\n",
        "        labels_no_window_list[label_start_point:label_start_point+MOVE_SIZE] = LABEL_MAP[label.iloc[i_label, label.columns.get_loc(\"move\")]]\n",
        "\n",
        "    for i_window in range(len(labels_window_list)):\n",
        "        label_sum = np.sum(labels_no_window_list[i_window : i_window + WINDOW_SIZE])\n",
        "        proportion = abs(label_sum)/WINDOW_SIZE\n",
        "        \n",
        "        if proportion > threshold:\n",
        "            if label_sum < 0:\n",
        "                #there is left\n",
        "                labels_window_list[i_window] = -1\n",
        "            elif label_sum > 0:\n",
        "                #there is right\n",
        "                labels_window_list[i_window] = 1\n",
        "            #0 is by default cause it's set to 0\n",
        "    \n",
        "    return windows_list, labels_window_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "OOyI96w_D2a-"
      },
      "outputs": [],
      "source": [
        "def create_window_data_df(windows, windows_labels):\n",
        "    cols = generate_columns(sigs=SIGNALS, features=FEATURES) + [\"label\"]\n",
        "    windows_labels.reshape(windows_labels.shape[0],-1)\n",
        "    \n",
        "    columned_labels = np.array([windows_labels])\n",
        "    columned_labels = columned_labels.T\n",
        "    \n",
        "    all_values = np.append(windows, columned_labels, axis=1)\n",
        "    \n",
        "    df = pd.DataFrame(all_values, index=[i for i in range(len(all_values))], columns=cols)\n",
        "    \n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "uBdAGpjbD2a-"
      },
      "outputs": [],
      "source": [
        "def define_model(lr=0.005):\n",
        "    model = tf.keras.Sequential([ #input shape = (batch, 300, 6, 1)\n",
        "    #keras.Input(shape=(FEATURES_PER_WINDOW, 1)),\n",
        "    tf.keras.layers.Dense(64, activation=\"relu\", name=\"Dense1\"),#, input_shape=(FEATURES_PER_WINDOW, 1)),\n",
        "    tf.keras.layers.Dense(128, activation=\"relu\", name=\"Dense1_1\"),\n",
        "    tf.keras.layers.Dropout(0.5), \n",
        "    tf.keras.layers.Dense(64, activation=\"relu\", name=\"Dense1_2\"),\n",
        "    tf.keras.layers.Dropout(0.4),     \n",
        "    tf.keras.layers.Dense(32, activation=\"relu\", name=\"Dense2\"),\n",
        "    tf.keras.layers.Dense(16, activation=\"relu\", name=\"Dense3\"),\n",
        "    tf.keras.layers.Dropout(0.3), \n",
        "    tf.keras.layers.Flatten(name=\"Flatten\"),\n",
        "    tf.keras.layers.Dense(8, activation=\"relu\", name=\"Dense4\"),\n",
        "    tf.keras.layers.Dense(3, activation=\"softmax\", name=\"Output\")\n",
        "    ])\n",
        "    \n",
        "    opt = keras.optimizers.Adam(learning_rate=lr)\n",
        "\n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy', tf.keras.metrics.CategoricalCrossentropy()])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "W-O3CXE_D2bD"
      },
      "outputs": [],
      "source": [
        "def define_model_2(lr=0.005, classes=3):\n",
        "    model = tf.keras.Sequential([ #input shape = (batch, 300, 6, 1)\n",
        "    #keras.Input(shape=(FEATURES_PER_WINDOW, 1)),\n",
        "    tf.keras.layers.Dense(64, activation=\"relu\", name=\"Dense1\"),#, input_shape=(FEATURES_PER_WINDOW, 1)),\n",
        "    #tf.keras.layers.Dense(128, activation=\"relu\", name=\"Dense1_1\"),\n",
        "    #tf.keras.layers.Dropout(0.5), \n",
        "    #tf.keras.layers.Dense(64, activation=\"relu\", name=\"Dense1_2\"),\n",
        "    tf.keras.layers.Dropout(0.4),     \n",
        "    tf.keras.layers.Dense(32, activation=\"relu\", name=\"Dense2\"),\n",
        "    tf.keras.layers.Dense(16, activation=\"relu\", name=\"Dense3\"),\n",
        "    tf.keras.layers.Dropout(0.3), \n",
        "    tf.keras.layers.Flatten(name=\"Flatten\"),\n",
        "    tf.keras.layers.Dense(8, activation=\"relu\", name=\"Dense4\"),\n",
        "    tf.keras.layers.Dense(classes, activation=\"softmax\", name=\"Output\")\n",
        "    ])\n",
        "    \n",
        "    opt = keras.optimizers.Adam(learning_rate=lr)\n",
        "\n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy', tf.keras.metrics.CategoricalCrossentropy()])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def define_model_3(lr=0.005, classes=3):\n",
        "    model = tf.keras.Sequential([ #input shape = (batch, 300, 6, 1)\n",
        "    #keras.Input(shape=(FEATURES_PER_WINDOW, 1)),\n",
        "    #tf.keras.layers.Dense(64, activation=\"relu\", name=\"Dense1\"),#, input_shape=(FEATURES_PER_WINDOW, 1)),\n",
        "    #tf.keras.layers.Dense(128, activation=\"relu\", name=\"Dense1_1\"),\n",
        "    #tf.keras.layers.Dropout(0.5), \n",
        "    #tf.keras.layers.Dense(64, activation=\"relu\", name=\"Dense1_2\"),\n",
        "    #tf.keras.layers.Dropout(0.4),     \n",
        "    #tf.keras.layers.Dense(32, activation=\"relu\", name=\"Dense2\"),\n",
        "    tf.keras.layers.Dense(16, activation=\"relu\", name=\"Dense3\"),\n",
        "    tf.keras.layers.Dropout(0.3), \n",
        "    tf.keras.layers.Flatten(name=\"Flatten\"),\n",
        "    tf.keras.layers.Dense(8, activation=\"relu\", name=\"Dense4\"),\n",
        "    tf.keras.layers.Dense(classes, activation=\"softmax\", name=\"Output\")\n",
        "    ])\n",
        "    \n",
        "    opt = keras.optimizers.Adam(learning_rate=lr)\n",
        "\n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy', tf.keras.metrics.CategoricalCrossentropy()])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "P7AfmEszbwNO"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "zojUBOc_D2a-"
      },
      "outputs": [],
      "source": [
        "\n",
        "# evaluate a model using k-fold cross-validation\n",
        "def evaluate_model(dataX, dataY, new_Y, n_folds=5):\n",
        "    scores, histories, categ_crossentropies = list(), list(), list()\n",
        "    # prepare cross validation\n",
        "    kfold = StratifiedKFold(n_folds, shuffle=True, random_state=1)\n",
        "    # enumerate splits\n",
        "    for train_ix, test_ix in kfold.split(dataX, new_Y):\n",
        "        # define model\n",
        "        model = define_model_3(lr=0.02)\n",
        "        # select rows for train and test\n",
        "        trainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\n",
        "        # fit model\n",
        "        #print(trainY.shape)\n",
        "        #print(trainX.shape)\n",
        "        \n",
        "        history = model.fit(trainX, trainY, epochs=35, batch_size=32, verbose=1, callbacks=[tensorboard_callback])#, validation_data=(testX, testY), verbose=1, callbacks=[tensorboard_callback])\n",
        "        # evaluate model\n",
        "        categ_crossentropy, acc, _ = model.evaluate(testX, testY, verbose=0)\n",
        "\n",
        "        print('> %.3f' % (acc * 100.0))\n",
        "        print(f'> {categ_crossentropy}')\n",
        "        # stores scores\n",
        "        scores.append(acc)\n",
        "        histories.append(history)\n",
        "        categ_crossentropies.append(categ_crossentropy)\n",
        "    return scores, histories, categ_crossentropies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Ew0PRtQKD2a_"
      },
      "outputs": [],
      "source": [
        "def one_hot_encode(to_encode):\n",
        "    one_hot_list = np.zeros((len(to_encode), CLASSES),dtype=int)\n",
        "    for i in range(len(to_encode)):\n",
        "        #print(to_encode[i])\n",
        "        one_hot_list[i, to_encode[i][0]] = 1\n",
        "        \n",
        "    return one_hot_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "gL7huOH0D2a_"
      },
      "outputs": [],
      "source": [
        "def prep_data(main_data):\n",
        "    data = main_data.values\n",
        "    dataX = copy.deepcopy(data[:, :-1]) #all Xs\n",
        "    dataY = copy.deepcopy(data[:, -1:]) #all Ys\n",
        "    dataY += 1 #0 left, 1 nothing, 2 right\n",
        "    #print(dataY)\n",
        "    \n",
        "    one_hot_Y = one_hot_encode(dataY.astype(int))\n",
        "    \n",
        "    return dataX, dataY.T[0].astype(int), one_hot_Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "t9oEe_GVD2a_"
      },
      "outputs": [],
      "source": [
        "def get_X_Y_bal(idxs, X, Y, one_hot_Y):\n",
        "    bal_X = X[idxs]\n",
        "    bal_Y = Y[idxs]\n",
        "    bal_one_hot_Y = one_hot_Y[idxs]\n",
        "    \n",
        "    return bal_X, bal_Y, bal_one_hot_Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "4Jx5I1VXD2a_"
      },
      "outputs": [],
      "source": [
        "def get_no_magnetometer_data(dataX):\n",
        "    return dataX[:, :30]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "6Yrd6WWMD2bA"
      },
      "outputs": [],
      "source": [
        "def get_balanced_dataset(dataX, dataY, one_hot_Y, seed = 0):\n",
        "    np.random.seed(seed)\n",
        "    no_idx, left_idx, right_idx = np.where(dataY == 1), np.where(dataY == 0), np.where(dataY == 2)\n",
        "    bal_size = min(len(left_idx[0]), len(right_idx[0]))\n",
        "    bal_left, bal_nothing, bal_right = np.random.choice(left_idx[0], size=bal_size, replace=False), np.random.choice(no_idx[0], size=bal_size, replace=False), np.random.choice(right_idx[0], size=bal_size, replace=False)   \n",
        "    all_balanced_idxs = np.concatenate([bal_nothing, bal_left, bal_right])\n",
        "    bal_X, bal_Y, bal_one_hot_Y = get_X_Y_bal(all_balanced_idxs, dataX, dataY, one_hot_Y)\n",
        "    \n",
        "    return bal_X, bal_Y, bal_one_hot_Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Yt6iu4TLD2bA"
      },
      "outputs": [],
      "source": [
        "def pickle_object(obj, filename):\n",
        "    with open(filename + '.pkl', 'wb') as f:\n",
        "        pickle.dump(obj, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "fnn6yEsxD2bA"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_data_X, train_data_Y, callbacks=[], epochs=10, batch_size=64, verbose=1, validation_split=0.0):\n",
        "    #model = define_model()\n",
        "    model.fit(train_data_X, train_data_Y, callbacks=callbacks, epochs=epochs, batch_size=batch_size, verbose=verbose, validation_split=validation_split)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "cp67s8MVD2bA"
      },
      "outputs": [],
      "source": [
        "def save_model_lite(model, model_name):\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "    tflite_model = converter.convert()\n",
        "\n",
        "    # Save the model to disk\n",
        "    open(model_name + \".tflite\", \"wb\").write(tflite_model)\n",
        "\n",
        "    basic_model_size = os.path.getsize(model_name + \".tflite\")\n",
        "    print(\"Model is %d bytes\" % basic_model_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# evaluate a model using k-fold cross-validation\n",
        "def evaluate_tflite_model(dataX, dataY, new_Y, n_folds=5, lr=0.005, bs=64):\n",
        "    scores, histories, categ_crossentropies = list(), list(), list()\n",
        "    \n",
        "    # prepare cross validation\n",
        "    kfold = StratifiedKFold(n_folds, shuffle=True, random_state=1)\n",
        "    # enumerate splits\n",
        "    for train_ix, test_ix in kfold.split(dataX, new_Y):\n",
        "        # define model\n",
        "        s = 0\n",
        "        model = define_model_2(lr=lr)\n",
        "        # select rows for train and test\n",
        "        trainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\n",
        "        # fit model\n",
        "        #print(trainY.shape)\n",
        "        #print(trainX.shape)\n",
        "        \n",
        "        history = model.fit(trainX, trainY, epochs=50, batch_size=bs, verbose=1, callbacks=[tensorboard_callback])#, validation_data=(testX, testY), verbose=1, callbacks=[tensorboard_callback])\n",
        "        # evaluate model\n",
        "        save_model_lite(model, \"tflite_test\")\n",
        "        preds = predict_tflite(\"tflite_test.tflite\", testX)\n",
        "        #categ_crossentropy, acc, _ = model.evaluate(testX, testY, verbose=0)\n",
        "        for i in range(len(preds)):\n",
        "          if preds[i] == np.argmax(testY[i]):\n",
        "            s += 1\n",
        "        acc = s/len(preds) \n",
        "        print('> %.3f' % (acc * 100.0))\n",
        "        #print(f'> {categ_crossentropy}')\n",
        "        # stores scores\n",
        "        scores.append(acc)\n",
        "        #histories.append(history)\n",
        "        #categ_crossentropies.append(categ_crossentropy)\n",
        "    return scores"
      ],
      "metadata": {
        "id": "fQw0UXqsg3bG"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_tflite(filename, testing_X):\n",
        "  interpreter = tf.lite.Interpreter(model_path=filename)\n",
        "  interpreter.allocate_tensors()\n",
        "\n",
        "  # Get input and output tensors.\n",
        "  input_details = interpreter.get_input_details()\n",
        "  output_details = interpreter.get_output_details()\n",
        "  preds = []\n",
        "  # Test model on random input data.\n",
        "  input_shape = input_details[0]['shape']\n",
        "  for idx in range(len(testing_X)):\n",
        "    inp = testing_X[idx].reshape((1,30))\n",
        "    inp = inp.astype(np.float32)\n",
        "    #input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
        "    interpreter.set_tensor(input_details[0]['index'], inp)\n",
        "\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # The function `get_tensor()` returns a copy of the tensor data.\n",
        "    # Use `tensor()` in order to get a pointer to the tensor.\n",
        "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "    preds.append(np.argmax(output_data[0]))\n",
        "    #ok = np.argmax(output_data[0]) == np.argmax(testing_Y[idx])\n",
        "    #s+=ok\n",
        "    #print(output_data[0])\n",
        "  return preds\n",
        "  #print(s)"
      ],
      "metadata": {
        "id": "dwNuWUVyhx4A"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prepared_data(data_filename, label_filename, threshold=0.8):\n",
        "  data_df = pd.read_csv(data_filename)\n",
        "  label_df = pd.read_csv(label_filename)\n",
        "\n",
        "  clean_data(data_df)\n",
        "  label_df[\"time\"] = label_df[\"time\"].str.replace(\" \", \"\")\n",
        "\n",
        "  convert_df_time(label_df, data_df)\n",
        "  windows_list, windows_labels = create_label_entries(label_df, data_df, threshold=threshold)\n",
        "  main_df = create_window_data_df(windows_list, windows_labels)\n",
        "\n",
        "  return main_df"
      ],
      "metadata": {
        "id": "WCMcirFVPs0J"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "l1NX6VnyD2bA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "7ec91168-8ee0-4a47-b838-469dc9d00f95"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-2a5bde6a7c90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconvert_df_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'label_df' is not defined"
          ]
        }
      ],
      "source": [
        "convert_df_time(label_df, data_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtew3YOxD2bA"
      },
      "outputs": [],
      "source": [
        "###TESTING FUNCTION LABEL\n",
        "windows_list, windows_labels = create_label_entries(label_df, data_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6LUrqygD2bB"
      },
      "outputs": [],
      "source": [
        "main_df = create_window_data_df(windows_list, windows_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "id": "IBNdePECD2bB",
        "outputId": "f00df833-0c79-4c42-ac4d-8972ba48775c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b15b36ac-70ea-4b4f-96fe-ba2588236fc3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aX_max</th>\n",
              "      <th>aX_min</th>\n",
              "      <th>aX_mean</th>\n",
              "      <th>aX_var</th>\n",
              "      <th>aX_median</th>\n",
              "      <th>aY_max</th>\n",
              "      <th>aY_min</th>\n",
              "      <th>aY_mean</th>\n",
              "      <th>aY_var</th>\n",
              "      <th>aY_median</th>\n",
              "      <th>...</th>\n",
              "      <th>mY_min</th>\n",
              "      <th>mY_mean</th>\n",
              "      <th>mY_var</th>\n",
              "      <th>mY_median</th>\n",
              "      <th>mZ_max</th>\n",
              "      <th>mZ_min</th>\n",
              "      <th>mZ_mean</th>\n",
              "      <th>mZ_var</th>\n",
              "      <th>mZ_median</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.440500</td>\n",
              "      <td>0.431500</td>\n",
              "      <td>0.432673</td>\n",
              "      <td>7.082889e-07</td>\n",
              "      <td>0.432625</td>\n",
              "      <td>0.507875</td>\n",
              "      <td>0.505750</td>\n",
              "      <td>0.507108</td>\n",
              "      <td>1.001389e-07</td>\n",
              "      <td>0.507125</td>\n",
              "      <td>...</td>\n",
              "      <td>0.556946</td>\n",
              "      <td>0.557925</td>\n",
              "      <td>1.332732e-07</td>\n",
              "      <td>0.558029</td>\n",
              "      <td>0.496170</td>\n",
              "      <td>0.494201</td>\n",
              "      <td>0.495338</td>\n",
              "      <td>2.618701e-07</td>\n",
              "      <td>0.495391</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.437750</td>\n",
              "      <td>0.431500</td>\n",
              "      <td>0.432613</td>\n",
              "      <td>3.054889e-07</td>\n",
              "      <td>0.432625</td>\n",
              "      <td>0.507875</td>\n",
              "      <td>0.506250</td>\n",
              "      <td>0.507123</td>\n",
              "      <td>9.155625e-08</td>\n",
              "      <td>0.507125</td>\n",
              "      <td>...</td>\n",
              "      <td>0.556946</td>\n",
              "      <td>0.557927</td>\n",
              "      <td>1.326578e-07</td>\n",
              "      <td>0.558029</td>\n",
              "      <td>0.496170</td>\n",
              "      <td>0.494201</td>\n",
              "      <td>0.495332</td>\n",
              "      <td>2.643901e-07</td>\n",
              "      <td>0.495391</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.437750</td>\n",
              "      <td>0.431500</td>\n",
              "      <td>0.432602</td>\n",
              "      <td>2.963306e-07</td>\n",
              "      <td>0.432625</td>\n",
              "      <td>0.507875</td>\n",
              "      <td>0.506250</td>\n",
              "      <td>0.507127</td>\n",
              "      <td>8.895556e-08</td>\n",
              "      <td>0.507125</td>\n",
              "      <td>...</td>\n",
              "      <td>0.556946</td>\n",
              "      <td>0.557928</td>\n",
              "      <td>1.320384e-07</td>\n",
              "      <td>0.558029</td>\n",
              "      <td>0.496170</td>\n",
              "      <td>0.494201</td>\n",
              "      <td>0.495326</td>\n",
              "      <td>2.668381e-07</td>\n",
              "      <td>0.495391</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.433375</td>\n",
              "      <td>0.431500</td>\n",
              "      <td>0.432567</td>\n",
              "      <td>1.184722e-07</td>\n",
              "      <td>0.432625</td>\n",
              "      <td>0.507875</td>\n",
              "      <td>0.506375</td>\n",
              "      <td>0.507132</td>\n",
              "      <td>8.391389e-08</td>\n",
              "      <td>0.507125</td>\n",
              "      <td>...</td>\n",
              "      <td>0.556946</td>\n",
              "      <td>0.557932</td>\n",
              "      <td>1.318000e-07</td>\n",
              "      <td>0.558029</td>\n",
              "      <td>0.496170</td>\n",
              "      <td>0.494201</td>\n",
              "      <td>0.495324</td>\n",
              "      <td>2.664538e-07</td>\n",
              "      <td>0.495384</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.433375</td>\n",
              "      <td>0.431500</td>\n",
              "      <td>0.432565</td>\n",
              "      <td>1.178583e-07</td>\n",
              "      <td>0.432625</td>\n",
              "      <td>0.507875</td>\n",
              "      <td>0.506375</td>\n",
              "      <td>0.507128</td>\n",
              "      <td>8.478056e-08</td>\n",
              "      <td>0.507125</td>\n",
              "      <td>...</td>\n",
              "      <td>0.556946</td>\n",
              "      <td>0.557936</td>\n",
              "      <td>1.315302e-07</td>\n",
              "      <td>0.558029</td>\n",
              "      <td>0.496170</td>\n",
              "      <td>0.494201</td>\n",
              "      <td>0.495322</td>\n",
              "      <td>2.660604e-07</td>\n",
              "      <td>0.495376</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62250</th>\n",
              "      <td>0.441875</td>\n",
              "      <td>0.440625</td>\n",
              "      <td>0.441152</td>\n",
              "      <td>6.288958e-08</td>\n",
              "      <td>0.441125</td>\n",
              "      <td>0.514750</td>\n",
              "      <td>0.513375</td>\n",
              "      <td>0.514288</td>\n",
              "      <td>3.936389e-08</td>\n",
              "      <td>0.514312</td>\n",
              "      <td>...</td>\n",
              "      <td>0.559127</td>\n",
              "      <td>0.559946</td>\n",
              "      <td>1.258307e-07</td>\n",
              "      <td>0.560028</td>\n",
              "      <td>0.487809</td>\n",
              "      <td>0.485459</td>\n",
              "      <td>0.486516</td>\n",
              "      <td>5.003555e-07</td>\n",
              "      <td>0.486420</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62251</th>\n",
              "      <td>0.441875</td>\n",
              "      <td>0.440625</td>\n",
              "      <td>0.441158</td>\n",
              "      <td>6.383958e-08</td>\n",
              "      <td>0.441125</td>\n",
              "      <td>0.514750</td>\n",
              "      <td>0.513375</td>\n",
              "      <td>0.514290</td>\n",
              "      <td>3.923333e-08</td>\n",
              "      <td>0.514375</td>\n",
              "      <td>...</td>\n",
              "      <td>0.559127</td>\n",
              "      <td>0.559938</td>\n",
              "      <td>1.253841e-07</td>\n",
              "      <td>0.560005</td>\n",
              "      <td>0.487809</td>\n",
              "      <td>0.485459</td>\n",
              "      <td>0.486527</td>\n",
              "      <td>5.098931e-07</td>\n",
              "      <td>0.486466</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62252</th>\n",
              "      <td>0.441875</td>\n",
              "      <td>0.440625</td>\n",
              "      <td>0.441162</td>\n",
              "      <td>6.407222e-08</td>\n",
              "      <td>0.441125</td>\n",
              "      <td>0.514750</td>\n",
              "      <td>0.513375</td>\n",
              "      <td>0.514295</td>\n",
              "      <td>3.755833e-08</td>\n",
              "      <td>0.514375</td>\n",
              "      <td>...</td>\n",
              "      <td>0.559127</td>\n",
              "      <td>0.559930</td>\n",
              "      <td>1.264583e-07</td>\n",
              "      <td>0.559982</td>\n",
              "      <td>0.487809</td>\n",
              "      <td>0.485459</td>\n",
              "      <td>0.486536</td>\n",
              "      <td>5.199156e-07</td>\n",
              "      <td>0.486511</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62253</th>\n",
              "      <td>0.441875</td>\n",
              "      <td>0.440625</td>\n",
              "      <td>0.441164</td>\n",
              "      <td>6.419514e-08</td>\n",
              "      <td>0.441125</td>\n",
              "      <td>0.514750</td>\n",
              "      <td>0.513375</td>\n",
              "      <td>0.514298</td>\n",
              "      <td>3.724722e-08</td>\n",
              "      <td>0.514375</td>\n",
              "      <td>...</td>\n",
              "      <td>0.559127</td>\n",
              "      <td>0.559923</td>\n",
              "      <td>1.274251e-07</td>\n",
              "      <td>0.559982</td>\n",
              "      <td>0.487809</td>\n",
              "      <td>0.485459</td>\n",
              "      <td>0.486545</td>\n",
              "      <td>5.297779e-07</td>\n",
              "      <td>0.486511</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62254</th>\n",
              "      <td>0.441875</td>\n",
              "      <td>0.440625</td>\n",
              "      <td>0.441166</td>\n",
              "      <td>6.364514e-08</td>\n",
              "      <td>0.441125</td>\n",
              "      <td>0.514750</td>\n",
              "      <td>0.513375</td>\n",
              "      <td>0.514298</td>\n",
              "      <td>3.701458e-08</td>\n",
              "      <td>0.514375</td>\n",
              "      <td>...</td>\n",
              "      <td>0.559127</td>\n",
              "      <td>0.559915</td>\n",
              "      <td>1.292275e-07</td>\n",
              "      <td>0.559982</td>\n",
              "      <td>0.487809</td>\n",
              "      <td>0.485459</td>\n",
              "      <td>0.486548</td>\n",
              "      <td>5.303385e-07</td>\n",
              "      <td>0.486511</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>62255 rows × 46 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b15b36ac-70ea-4b4f-96fe-ba2588236fc3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b15b36ac-70ea-4b4f-96fe-ba2588236fc3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b15b36ac-70ea-4b4f-96fe-ba2588236fc3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         aX_max    aX_min   aX_mean        aX_var  aX_median    aY_max  \\\n",
              "0      0.440500  0.431500  0.432673  7.082889e-07   0.432625  0.507875   \n",
              "1      0.437750  0.431500  0.432613  3.054889e-07   0.432625  0.507875   \n",
              "2      0.437750  0.431500  0.432602  2.963306e-07   0.432625  0.507875   \n",
              "3      0.433375  0.431500  0.432567  1.184722e-07   0.432625  0.507875   \n",
              "4      0.433375  0.431500  0.432565  1.178583e-07   0.432625  0.507875   \n",
              "...         ...       ...       ...           ...        ...       ...   \n",
              "62250  0.441875  0.440625  0.441152  6.288958e-08   0.441125  0.514750   \n",
              "62251  0.441875  0.440625  0.441158  6.383958e-08   0.441125  0.514750   \n",
              "62252  0.441875  0.440625  0.441162  6.407222e-08   0.441125  0.514750   \n",
              "62253  0.441875  0.440625  0.441164  6.419514e-08   0.441125  0.514750   \n",
              "62254  0.441875  0.440625  0.441166  6.364514e-08   0.441125  0.514750   \n",
              "\n",
              "         aY_min   aY_mean        aY_var  aY_median  ...    mY_min   mY_mean  \\\n",
              "0      0.505750  0.507108  1.001389e-07   0.507125  ...  0.556946  0.557925   \n",
              "1      0.506250  0.507123  9.155625e-08   0.507125  ...  0.556946  0.557927   \n",
              "2      0.506250  0.507127  8.895556e-08   0.507125  ...  0.556946  0.557928   \n",
              "3      0.506375  0.507132  8.391389e-08   0.507125  ...  0.556946  0.557932   \n",
              "4      0.506375  0.507128  8.478056e-08   0.507125  ...  0.556946  0.557936   \n",
              "...         ...       ...           ...        ...  ...       ...       ...   \n",
              "62250  0.513375  0.514288  3.936389e-08   0.514312  ...  0.559127  0.559946   \n",
              "62251  0.513375  0.514290  3.923333e-08   0.514375  ...  0.559127  0.559938   \n",
              "62252  0.513375  0.514295  3.755833e-08   0.514375  ...  0.559127  0.559930   \n",
              "62253  0.513375  0.514298  3.724722e-08   0.514375  ...  0.559127  0.559923   \n",
              "62254  0.513375  0.514298  3.701458e-08   0.514375  ...  0.559127  0.559915   \n",
              "\n",
              "             mY_var  mY_median    mZ_max    mZ_min   mZ_mean        mZ_var  \\\n",
              "0      1.332732e-07   0.558029  0.496170  0.494201  0.495338  2.618701e-07   \n",
              "1      1.326578e-07   0.558029  0.496170  0.494201  0.495332  2.643901e-07   \n",
              "2      1.320384e-07   0.558029  0.496170  0.494201  0.495326  2.668381e-07   \n",
              "3      1.318000e-07   0.558029  0.496170  0.494201  0.495324  2.664538e-07   \n",
              "4      1.315302e-07   0.558029  0.496170  0.494201  0.495322  2.660604e-07   \n",
              "...             ...        ...       ...       ...       ...           ...   \n",
              "62250  1.258307e-07   0.560028  0.487809  0.485459  0.486516  5.003555e-07   \n",
              "62251  1.253841e-07   0.560005  0.487809  0.485459  0.486527  5.098931e-07   \n",
              "62252  1.264583e-07   0.559982  0.487809  0.485459  0.486536  5.199156e-07   \n",
              "62253  1.274251e-07   0.559982  0.487809  0.485459  0.486545  5.297779e-07   \n",
              "62254  1.292275e-07   0.559982  0.487809  0.485459  0.486548  5.303385e-07   \n",
              "\n",
              "       mZ_median  label  \n",
              "0       0.495391    0.0  \n",
              "1       0.495391    0.0  \n",
              "2       0.495391    0.0  \n",
              "3       0.495384    0.0  \n",
              "4       0.495376    0.0  \n",
              "...          ...    ...  \n",
              "62250   0.486420    0.0  \n",
              "62251   0.486466    0.0  \n",
              "62252   0.486511    0.0  \n",
              "62253   0.486511    0.0  \n",
              "62254   0.486511    0.0  \n",
              "\n",
              "[62255 rows x 46 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "main_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = get_prepared_data(data_filename = \"data_1.csv\", label_filename = \"label_1.csv\",threshold=0.9)\n",
        "#df2 = get_prepared_data(data_filename = \"data_2.csv\", label_filename = \"label_2.csv\")\n",
        "#df3 = get_prepared_data(data_filename = \"data_3.csv\", label_filename = \"label_3.csv\", threshold=0.9)\n",
        "df4 = get_prepared_data(data_filename = \"data_4.csv\", label_filename = \"label_4.csv\", threshold=0.9)"
      ],
      "metadata": {
        "id": "uasdLAv_SI1B"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_df = pd.concat([df1, df4], axis=0)"
      ],
      "metadata": {
        "id": "It99VGhzpXb9"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-8x3cqtIlXtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "ba0urr02D2bB"
      },
      "outputs": [],
      "source": [
        "dX, dY, one_hot_Y = prep_data(main_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oQMqoKSD2bB",
        "outputId": "215cd95f-624c-4be4-ae24-4810cf8eb918"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1769 98445  1653]\n"
          ]
        }
      ],
      "source": [
        "print(np.sum(one_hot_Y, axis=0)) #number of entries per gesture type L N R"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "null_idx = np.where(dY == 1)[0]\n",
        "print(len(null_idx))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_ClSKSqrW2A",
        "outputId": "350da80a-5527-4b97-ae5c-97808730b98e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataX = dX[~np.in1d(np.arange(dX.shape[0]),null_idx)]\n",
        "test_dataX.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Z7H6LSZsARd",
        "outputId": "72ac5669-b5e5-4a4e-e794-b9f2c2800db8"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3422, 45)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_one_hot_Y = one_hot_Y[~np.in1d(np.arange(dX.shape[0]),null_idx)]\n",
        "print(test_one_hot_Y.shape)\n",
        "test_one_hot_Y = np.delete(test_one_hot_Y, 1, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOzGQng6u0Vy",
        "outputId": "fc1a398f-0aa4-425b-f086-815dc6c5d7dc"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3422, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.sum(test_one_hot_Y, axis=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mNiUlwPwGO8",
        "outputId": "97ef367d-244c-49fb-8cff-4e996d0b8795"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1769 1653]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_no_mX = get_no_magnetometer_data(test_dataX)"
      ],
      "metadata": {
        "id": "Jk9LMjDbsAVP"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = define_model_2(lr=0.002, classes=2)\n",
        "train_model(model, test_no_mX, test_one_hot_Y, epochs=100, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aje2ZOcpwYkS",
        "outputId": "f6ae1707-ba3e-4d26-bd6a-0c85c237e2ef"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "107/107 [==============================] - 1s 4ms/step - loss: 0.4887 - accuracy: 0.7472 - categorical_crossentropy: 0.4887\n",
            "Epoch 2/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.1237 - accuracy: 0.9711 - categorical_crossentropy: 0.1237\n",
            "Epoch 3/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0923 - accuracy: 0.9790 - categorical_crossentropy: 0.0923\n",
            "Epoch 4/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0859 - accuracy: 0.9795 - categorical_crossentropy: 0.0859\n",
            "Epoch 5/100\n",
            "107/107 [==============================] - 0s 5ms/step - loss: 0.0891 - accuracy: 0.9784 - categorical_crossentropy: 0.0891\n",
            "Epoch 6/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0876 - accuracy: 0.9807 - categorical_crossentropy: 0.0876\n",
            "Epoch 7/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0762 - accuracy: 0.9819 - categorical_crossentropy: 0.0762\n",
            "Epoch 8/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0766 - accuracy: 0.9819 - categorical_crossentropy: 0.0766\n",
            "Epoch 9/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0790 - accuracy: 0.9787 - categorical_crossentropy: 0.0790\n",
            "Epoch 10/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0873 - accuracy: 0.9778 - categorical_crossentropy: 0.0873\n",
            "Epoch 11/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0931 - accuracy: 0.9760 - categorical_crossentropy: 0.0931\n",
            "Epoch 12/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0765 - accuracy: 0.9822 - categorical_crossentropy: 0.0765\n",
            "Epoch 13/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0757 - accuracy: 0.9790 - categorical_crossentropy: 0.0757\n",
            "Epoch 14/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0746 - accuracy: 0.9798 - categorical_crossentropy: 0.0746\n",
            "Epoch 15/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0703 - accuracy: 0.9813 - categorical_crossentropy: 0.0703\n",
            "Epoch 16/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0745 - accuracy: 0.9807 - categorical_crossentropy: 0.0745\n",
            "Epoch 17/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.9816 - categorical_crossentropy: 0.0693\n",
            "Epoch 18/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.9810 - categorical_crossentropy: 0.0682\n",
            "Epoch 19/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0684 - accuracy: 0.9801 - categorical_crossentropy: 0.0684\n",
            "Epoch 20/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.9819 - categorical_crossentropy: 0.0657\n",
            "Epoch 21/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0712 - accuracy: 0.9822 - categorical_crossentropy: 0.0712\n",
            "Epoch 22/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0721 - accuracy: 0.9793 - categorical_crossentropy: 0.0721\n",
            "Epoch 23/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0581 - accuracy: 0.9833 - categorical_crossentropy: 0.0581\n",
            "Epoch 24/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0705 - accuracy: 0.9822 - categorical_crossentropy: 0.0705\n",
            "Epoch 25/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0727 - accuracy: 0.9793 - categorical_crossentropy: 0.0727\n",
            "Epoch 26/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.9822 - categorical_crossentropy: 0.0693\n",
            "Epoch 27/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.9810 - categorical_crossentropy: 0.0693\n",
            "Epoch 28/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.9822 - categorical_crossentropy: 0.0674\n",
            "Epoch 29/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0619 - accuracy: 0.9848 - categorical_crossentropy: 0.0619\n",
            "Epoch 30/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0801 - accuracy: 0.9778 - categorical_crossentropy: 0.0801\n",
            "Epoch 31/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0652 - accuracy: 0.9828 - categorical_crossentropy: 0.0652\n",
            "Epoch 32/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0759 - accuracy: 0.9801 - categorical_crossentropy: 0.0759\n",
            "Epoch 33/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.9825 - categorical_crossentropy: 0.0689\n",
            "Epoch 34/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0655 - accuracy: 0.9833 - categorical_crossentropy: 0.0655\n",
            "Epoch 35/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0698 - accuracy: 0.9825 - categorical_crossentropy: 0.0698\n",
            "Epoch 36/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0684 - accuracy: 0.9828 - categorical_crossentropy: 0.0684\n",
            "Epoch 37/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.9839 - categorical_crossentropy: 0.0663\n",
            "Epoch 38/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0803 - accuracy: 0.9781 - categorical_crossentropy: 0.0803\n",
            "Epoch 39/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0835 - accuracy: 0.9766 - categorical_crossentropy: 0.0835\n",
            "Epoch 40/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0798 - accuracy: 0.9790 - categorical_crossentropy: 0.0798\n",
            "Epoch 41/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0634 - accuracy: 0.9828 - categorical_crossentropy: 0.0634\n",
            "Epoch 42/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0711 - accuracy: 0.9790 - categorical_crossentropy: 0.0711\n",
            "Epoch 43/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.9793 - categorical_crossentropy: 0.0667\n",
            "Epoch 44/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0702 - accuracy: 0.9804 - categorical_crossentropy: 0.0702\n",
            "Epoch 45/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.9828 - categorical_crossentropy: 0.0669\n",
            "Epoch 46/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 0.9839 - categorical_crossentropy: 0.0645\n",
            "Epoch 47/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.9833 - categorical_crossentropy: 0.0694\n",
            "Epoch 48/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0665 - accuracy: 0.9819 - categorical_crossentropy: 0.0665\n",
            "Epoch 49/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.9822 - categorical_crossentropy: 0.0694\n",
            "Epoch 50/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0596 - accuracy: 0.9857 - categorical_crossentropy: 0.0596\n",
            "Epoch 51/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.9825 - categorical_crossentropy: 0.0681\n",
            "Epoch 52/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0588 - accuracy: 0.9860 - categorical_crossentropy: 0.0588\n",
            "Epoch 53/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0615 - accuracy: 0.9845 - categorical_crossentropy: 0.0615\n",
            "Epoch 54/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0629 - accuracy: 0.9842 - categorical_crossentropy: 0.0629\n",
            "Epoch 55/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0701 - accuracy: 0.9825 - categorical_crossentropy: 0.0701\n",
            "Epoch 56/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 0.9825 - categorical_crossentropy: 0.0645\n",
            "Epoch 57/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.9845 - categorical_crossentropy: 0.0638\n",
            "Epoch 58/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0615 - accuracy: 0.9860 - categorical_crossentropy: 0.0615\n",
            "Epoch 59/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0539 - accuracy: 0.9868 - categorical_crossentropy: 0.0539\n",
            "Epoch 60/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0605 - accuracy: 0.9845 - categorical_crossentropy: 0.0605\n",
            "Epoch 61/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0650 - accuracy: 0.9839 - categorical_crossentropy: 0.0650\n",
            "Epoch 62/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0577 - accuracy: 0.9877 - categorical_crossentropy: 0.0577\n",
            "Epoch 63/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0648 - accuracy: 0.9842 - categorical_crossentropy: 0.0648\n",
            "Epoch 64/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0649 - accuracy: 0.9848 - categorical_crossentropy: 0.0649\n",
            "Epoch 65/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0665 - accuracy: 0.9845 - categorical_crossentropy: 0.0665\n",
            "Epoch 66/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.9813 - categorical_crossentropy: 0.0681\n",
            "Epoch 67/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0728 - accuracy: 0.9793 - categorical_crossentropy: 0.0728\n",
            "Epoch 68/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.9842 - categorical_crossentropy: 0.0664\n",
            "Epoch 69/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0650 - accuracy: 0.9839 - categorical_crossentropy: 0.0650\n",
            "Epoch 70/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.9839 - categorical_crossentropy: 0.0682\n",
            "Epoch 71/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.9854 - categorical_crossentropy: 0.0643\n",
            "Epoch 72/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0608 - accuracy: 0.9857 - categorical_crossentropy: 0.0608\n",
            "Epoch 73/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.9848 - categorical_crossentropy: 0.0669\n",
            "Epoch 74/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.9833 - categorical_crossentropy: 0.0686\n",
            "Epoch 75/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0730 - accuracy: 0.9810 - categorical_crossentropy: 0.0730\n",
            "Epoch 76/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0583 - accuracy: 0.9883 - categorical_crossentropy: 0.0583\n",
            "Epoch 77/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0668 - accuracy: 0.9836 - categorical_crossentropy: 0.0668\n",
            "Epoch 78/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.9851 - categorical_crossentropy: 0.0628\n",
            "Epoch 79/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.9839 - categorical_crossentropy: 0.0690\n",
            "Epoch 80/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0644 - accuracy: 0.9857 - categorical_crossentropy: 0.0644\n",
            "Epoch 81/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 0.9842 - categorical_crossentropy: 0.0659\n",
            "Epoch 82/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0725 - accuracy: 0.9839 - categorical_crossentropy: 0.0725\n",
            "Epoch 83/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0711 - accuracy: 0.9839 - categorical_crossentropy: 0.0711\n",
            "Epoch 84/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0670 - accuracy: 0.9836 - categorical_crossentropy: 0.0670\n",
            "Epoch 85/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0588 - accuracy: 0.9868 - categorical_crossentropy: 0.0588\n",
            "Epoch 86/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.9836 - categorical_crossentropy: 0.0672\n",
            "Epoch 87/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0730 - accuracy: 0.9825 - categorical_crossentropy: 0.0730\n",
            "Epoch 88/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.9842 - categorical_crossentropy: 0.0687\n",
            "Epoch 89/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0862 - accuracy: 0.9787 - categorical_crossentropy: 0.0862\n",
            "Epoch 90/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0782 - accuracy: 0.9825 - categorical_crossentropy: 0.0782\n",
            "Epoch 91/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0730 - accuracy: 0.9833 - categorical_crossentropy: 0.0730\n",
            "Epoch 92/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0794 - accuracy: 0.9798 - categorical_crossentropy: 0.0794\n",
            "Epoch 93/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0798 - accuracy: 0.9801 - categorical_crossentropy: 0.0798\n",
            "Epoch 94/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0840 - accuracy: 0.9787 - categorical_crossentropy: 0.0840\n",
            "Epoch 95/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0699 - accuracy: 0.9842 - categorical_crossentropy: 0.0699\n",
            "Epoch 96/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0750 - accuracy: 0.9819 - categorical_crossentropy: 0.0750\n",
            "Epoch 97/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0705 - accuracy: 0.9831 - categorical_crossentropy: 0.0705\n",
            "Epoch 98/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.9845 - categorical_crossentropy: 0.0669\n",
            "Epoch 99/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0848 - accuracy: 0.9784 - categorical_crossentropy: 0.0848\n",
            "Epoch 100/100\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.0718 - accuracy: 0.9833 - categorical_crossentropy: 0.0718\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_model_lite(model, \"no_magneto_2_classes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEQkAyz8wYoR",
        "outputId": "11e42b25-333b-494b-f285-fea90e38733a"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) Dense1_input with unsupported characters which will be renamed to dense1_input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpqry6qdmh/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpqry6qdmh/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model is 21808 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! apt-get -qq install xxd\n",
        "\n",
        "\n",
        "!echo \"const unsigned char model_data[] = {\" > /content/model_small.h\n",
        "!cat no_magneto_2_classes.tflite | xxd -i      >> /content/model_small.h\n",
        "!echo \"};\"                              >> /content/model_small.h\n",
        "\n",
        "import os\n",
        "model_h_size = os.path.getsize(\"model_small.h\")\n",
        "print(f\"Header file, model.h, is {model_h_size:,} bytes.\")\n",
        "print(\"\\nOpen the side panel (refresh if needed). Double click model.h to download the file.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-Bickey0Szk",
        "outputId": "9b22ad2e-ad2a-453d-c1a4-8669c2e90060"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting previously unselected package xxd.\n",
            "(Reading database ... 155335 files and directories currently installed.)\n",
            "Preparing to unpack .../xxd_2%3a8.0.1453-1ubuntu1.8_amd64.deb ...\n",
            "Unpacking xxd (2:8.0.1453-1ubuntu1.8) ...\n",
            "Setting up xxd (2:8.0.1453-1ubuntu1.8) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Header file, model.h, is 134,523 bytes.\n",
            "\n",
            "Open the side panel (refresh if needed). Double click model.h to download the file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8v3A0Kj_0LNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########## end of test with 2 outcomes"
      ],
      "metadata": {
        "id": "_2B8D2ZQthGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "PaXisHOlD2bB"
      },
      "outputs": [],
      "source": [
        "dataX = dX.reshape((dX.shape[0], len(FEATURES)*len(SIGNALS)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EqacGqjD2bB",
        "outputId": "127e397f-6ec9-4e68-9bf4-6decece20929"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(101867, 45)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "dataX.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "a76CfGTcD2bC"
      },
      "outputs": [],
      "source": [
        "no_mX = get_no_magnetometer_data(dataX)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = define_model_2(lr=0.005)\n",
        "train_model(model, no_mX, one_hot_Y, epochs=100, batch_size=256)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nU-U0eZkv-_M",
        "outputId": "6176e664-b2f0-4b88-f2f7-ba3f50a99a8a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "398/398 [==============================] - 3s 5ms/step - loss: 0.2544 - accuracy: 0.9076 - categorical_crossentropy: 0.2544\n",
            "Epoch 2/100\n",
            "398/398 [==============================] - 1s 4ms/step - loss: 0.1934 - accuracy: 0.9130 - categorical_crossentropy: 0.1934\n",
            "Epoch 3/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1782 - accuracy: 0.9127 - categorical_crossentropy: 0.1782\n",
            "Epoch 4/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1718 - accuracy: 0.9125 - categorical_crossentropy: 0.1718\n",
            "Epoch 5/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1718 - accuracy: 0.9124 - categorical_crossentropy: 0.1718\n",
            "Epoch 6/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1722 - accuracy: 0.9125 - categorical_crossentropy: 0.1722\n",
            "Epoch 7/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1706 - accuracy: 0.9126 - categorical_crossentropy: 0.1706\n",
            "Epoch 8/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1717 - accuracy: 0.9135 - categorical_crossentropy: 0.1717\n",
            "Epoch 9/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1706 - accuracy: 0.9126 - categorical_crossentropy: 0.1706\n",
            "Epoch 10/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1697 - accuracy: 0.9135 - categorical_crossentropy: 0.1697\n",
            "Epoch 11/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1672 - accuracy: 0.9134 - categorical_crossentropy: 0.1672\n",
            "Epoch 12/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1670 - accuracy: 0.9135 - categorical_crossentropy: 0.1670\n",
            "Epoch 13/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1689 - accuracy: 0.9136 - categorical_crossentropy: 0.1689\n",
            "Epoch 14/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1681 - accuracy: 0.9154 - categorical_crossentropy: 0.1681\n",
            "Epoch 15/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1720 - accuracy: 0.9139 - categorical_crossentropy: 0.1720\n",
            "Epoch 16/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1720 - accuracy: 0.9153 - categorical_crossentropy: 0.1720\n",
            "Epoch 17/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1702 - accuracy: 0.9151 - categorical_crossentropy: 0.1702\n",
            "Epoch 18/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1680 - accuracy: 0.9152 - categorical_crossentropy: 0.1680\n",
            "Epoch 19/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1668 - accuracy: 0.9153 - categorical_crossentropy: 0.1668\n",
            "Epoch 20/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1668 - accuracy: 0.9156 - categorical_crossentropy: 0.1668\n",
            "Epoch 21/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1651 - accuracy: 0.9154 - categorical_crossentropy: 0.1651\n",
            "Epoch 22/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1658 - accuracy: 0.9146 - categorical_crossentropy: 0.1658\n",
            "Epoch 23/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1635 - accuracy: 0.9161 - categorical_crossentropy: 0.1635\n",
            "Epoch 24/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1628 - accuracy: 0.9159 - categorical_crossentropy: 0.1628\n",
            "Epoch 25/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1627 - accuracy: 0.9160 - categorical_crossentropy: 0.1627\n",
            "Epoch 26/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1621 - accuracy: 0.9164 - categorical_crossentropy: 0.1621\n",
            "Epoch 27/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1607 - accuracy: 0.9163 - categorical_crossentropy: 0.1607\n",
            "Epoch 28/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1614 - accuracy: 0.9165 - categorical_crossentropy: 0.1614\n",
            "Epoch 29/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1629 - accuracy: 0.9166 - categorical_crossentropy: 0.1629\n",
            "Epoch 30/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1606 - accuracy: 0.9175 - categorical_crossentropy: 0.1606\n",
            "Epoch 31/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1604 - accuracy: 0.9173 - categorical_crossentropy: 0.1604\n",
            "Epoch 32/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1604 - accuracy: 0.9167 - categorical_crossentropy: 0.1604\n",
            "Epoch 33/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1611 - accuracy: 0.9168 - categorical_crossentropy: 0.1611\n",
            "Epoch 34/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1605 - accuracy: 0.9180 - categorical_crossentropy: 0.1605\n",
            "Epoch 35/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1599 - accuracy: 0.9164 - categorical_crossentropy: 0.1599\n",
            "Epoch 36/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1585 - accuracy: 0.9188 - categorical_crossentropy: 0.1585\n",
            "Epoch 37/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1621 - accuracy: 0.9174 - categorical_crossentropy: 0.1621\n",
            "Epoch 38/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1639 - accuracy: 0.9189 - categorical_crossentropy: 0.1639\n",
            "Epoch 39/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1616 - accuracy: 0.9185 - categorical_crossentropy: 0.1616\n",
            "Epoch 40/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1576 - accuracy: 0.9188 - categorical_crossentropy: 0.1576\n",
            "Epoch 41/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1595 - accuracy: 0.9179 - categorical_crossentropy: 0.1595\n",
            "Epoch 42/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1593 - accuracy: 0.9186 - categorical_crossentropy: 0.1593\n",
            "Epoch 43/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1584 - accuracy: 0.9176 - categorical_crossentropy: 0.1584\n",
            "Epoch 44/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1569 - accuracy: 0.9192 - categorical_crossentropy: 0.1569\n",
            "Epoch 45/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1565 - accuracy: 0.9179 - categorical_crossentropy: 0.1565\n",
            "Epoch 46/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1594 - accuracy: 0.9185 - categorical_crossentropy: 0.1594\n",
            "Epoch 47/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1583 - accuracy: 0.9180 - categorical_crossentropy: 0.1583\n",
            "Epoch 48/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1572 - accuracy: 0.9195 - categorical_crossentropy: 0.1572\n",
            "Epoch 49/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1571 - accuracy: 0.9197 - categorical_crossentropy: 0.1571\n",
            "Epoch 50/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1628 - accuracy: 0.9187 - categorical_crossentropy: 0.1628\n",
            "Epoch 51/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1630 - accuracy: 0.9185 - categorical_crossentropy: 0.1630\n",
            "Epoch 52/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1579 - accuracy: 0.9200 - categorical_crossentropy: 0.1579\n",
            "Epoch 53/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1625 - accuracy: 0.9185 - categorical_crossentropy: 0.1625\n",
            "Epoch 54/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1621 - accuracy: 0.9188 - categorical_crossentropy: 0.1621\n",
            "Epoch 55/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1646 - accuracy: 0.9184 - categorical_crossentropy: 0.1646\n",
            "Epoch 56/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1633 - accuracy: 0.9193 - categorical_crossentropy: 0.1633\n",
            "Epoch 57/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1625 - accuracy: 0.9192 - categorical_crossentropy: 0.1625\n",
            "Epoch 58/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1636 - accuracy: 0.9166 - categorical_crossentropy: 0.1636\n",
            "Epoch 59/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1678 - accuracy: 0.9175 - categorical_crossentropy: 0.1678\n",
            "Epoch 60/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1637 - accuracy: 0.9163 - categorical_crossentropy: 0.1637\n",
            "Epoch 61/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1652 - accuracy: 0.9179 - categorical_crossentropy: 0.1652\n",
            "Epoch 62/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1616 - accuracy: 0.9205 - categorical_crossentropy: 0.1616\n",
            "Epoch 63/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1600 - accuracy: 0.9191 - categorical_crossentropy: 0.1600\n",
            "Epoch 64/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1619 - accuracy: 0.9188 - categorical_crossentropy: 0.1619\n",
            "Epoch 65/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1623 - accuracy: 0.9187 - categorical_crossentropy: 0.1623\n",
            "Epoch 66/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1617 - accuracy: 0.9191 - categorical_crossentropy: 0.1617\n",
            "Epoch 67/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1621 - accuracy: 0.9195 - categorical_crossentropy: 0.1621\n",
            "Epoch 68/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1625 - accuracy: 0.9186 - categorical_crossentropy: 0.1625\n",
            "Epoch 69/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1607 - accuracy: 0.9193 - categorical_crossentropy: 0.1607\n",
            "Epoch 70/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1609 - accuracy: 0.9200 - categorical_crossentropy: 0.1609\n",
            "Epoch 71/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1711 - accuracy: 0.9186 - categorical_crossentropy: 0.1711\n",
            "Epoch 72/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1718 - accuracy: 0.9185 - categorical_crossentropy: 0.1718\n",
            "Epoch 73/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1727 - accuracy: 0.9175 - categorical_crossentropy: 0.1727\n",
            "Epoch 74/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1745 - accuracy: 0.9164 - categorical_crossentropy: 0.1745\n",
            "Epoch 75/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1704 - accuracy: 0.9178 - categorical_crossentropy: 0.1704\n",
            "Epoch 76/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1704 - accuracy: 0.9196 - categorical_crossentropy: 0.1704\n",
            "Epoch 77/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1735 - accuracy: 0.9173 - categorical_crossentropy: 0.1735\n",
            "Epoch 78/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1703 - accuracy: 0.9177 - categorical_crossentropy: 0.1703\n",
            "Epoch 79/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1776 - accuracy: 0.9167 - categorical_crossentropy: 0.1776\n",
            "Epoch 80/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1701 - accuracy: 0.9173 - categorical_crossentropy: 0.1701\n",
            "Epoch 81/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1695 - accuracy: 0.9185 - categorical_crossentropy: 0.1695\n",
            "Epoch 82/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1706 - accuracy: 0.9181 - categorical_crossentropy: 0.1706\n",
            "Epoch 83/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1724 - accuracy: 0.9172 - categorical_crossentropy: 0.1724\n",
            "Epoch 84/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1693 - accuracy: 0.9179 - categorical_crossentropy: 0.1693\n",
            "Epoch 85/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1683 - accuracy: 0.9195 - categorical_crossentropy: 0.1683\n",
            "Epoch 86/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1689 - accuracy: 0.9179 - categorical_crossentropy: 0.1689\n",
            "Epoch 87/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1685 - accuracy: 0.9186 - categorical_crossentropy: 0.1685\n",
            "Epoch 88/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1690 - accuracy: 0.9180 - categorical_crossentropy: 0.1690\n",
            "Epoch 89/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1708 - accuracy: 0.9190 - categorical_crossentropy: 0.1708\n",
            "Epoch 90/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1688 - accuracy: 0.9181 - categorical_crossentropy: 0.1688\n",
            "Epoch 91/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1688 - accuracy: 0.9192 - categorical_crossentropy: 0.1688\n",
            "Epoch 92/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1725 - accuracy: 0.9174 - categorical_crossentropy: 0.1725\n",
            "Epoch 93/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1761 - accuracy: 0.9167 - categorical_crossentropy: 0.1761\n",
            "Epoch 94/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1728 - accuracy: 0.9174 - categorical_crossentropy: 0.1728\n",
            "Epoch 95/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1690 - accuracy: 0.9178 - categorical_crossentropy: 0.1690\n",
            "Epoch 96/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1691 - accuracy: 0.9173 - categorical_crossentropy: 0.1691\n",
            "Epoch 97/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1702 - accuracy: 0.9172 - categorical_crossentropy: 0.1702\n",
            "Epoch 98/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1705 - accuracy: 0.9176 - categorical_crossentropy: 0.1705\n",
            "Epoch 99/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1709 - accuracy: 0.9184 - categorical_crossentropy: 0.1709\n",
            "Epoch 100/100\n",
            "398/398 [==============================] - 1s 3ms/step - loss: 0.1689 - accuracy: 0.9182 - categorical_crossentropy: 0.1689\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Yk8yBiU2D2bC"
      },
      "outputs": [],
      "source": [
        "bal_X, bal_Y, bal_one_hot_Y = get_balanced_dataset(dX, dY, one_hot_Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "i2VNswaZD2bC"
      },
      "outputs": [],
      "source": [
        "nom_bal_X, nom_bal_Y, nom_bal_one_hot_Y = get_balanced_dataset(no_mX, dY, one_hot_Y, 5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nom_bal_X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVNzicZZeeh0",
        "outputId": "e2807fe2-7fda-4f3f-ea84-0c0d43777968"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12825, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = evaluate_tflite_model(nom_bal_X, nom_bal_one_hot_Y, nom_bal_Y, lr=0.005, bs=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Loh6kRZNmROt",
        "outputId": "cf1dc76d-4314-4d9d-9c4f-48f34f9915dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/c_api_util.py\u001b[0m in \u001b[0;36mtf_buffer\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    198\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m     \u001b[0;32myield\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2689\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2690\u001b[0;31m         \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2691\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Operation 'sequential_15/Dense3/MatMul/ReadVariableOp/resource' has no attr named '_class'.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: 'zmq.backend.cython.message.Frame.__dealloc__'\n",
            "Traceback (most recent call last):\n",
            "  File \"zmq/backend/cython/checkrc.pxd\", line 13, in zmq.backend.cython.checkrc._check_rc\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "161/161 [==============================] - 45s 3ms/step - loss: 0.5859 - accuracy: 0.7711 - categorical_crossentropy: 0.5859\n",
            "Epoch 2/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3523 - accuracy: 0.8965 - categorical_crossentropy: 0.3523\n",
            "Epoch 3/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3438 - accuracy: 0.8954 - categorical_crossentropy: 0.3438\n",
            "Epoch 4/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3330 - accuracy: 0.8998 - categorical_crossentropy: 0.3330\n",
            "Epoch 5/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3376 - accuracy: 0.8957 - categorical_crossentropy: 0.3376\n",
            "Epoch 6/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3321 - accuracy: 0.8967 - categorical_crossentropy: 0.3321\n",
            "Epoch 7/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3299 - accuracy: 0.8967 - categorical_crossentropy: 0.3299\n",
            "Epoch 8/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3351 - accuracy: 0.8899 - categorical_crossentropy: 0.3351\n",
            "Epoch 9/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3262 - accuracy: 0.8960 - categorical_crossentropy: 0.3262\n",
            "Epoch 10/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3411 - accuracy: 0.8912 - categorical_crossentropy: 0.3411\n",
            "Epoch 11/50\n",
            "161/161 [==============================] - 1s 3ms/step - loss: 0.3398 - accuracy: 0.8905 - categorical_crossentropy: 0.3398\n",
            "Epoch 12/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3313 - accuracy: 0.8885 - categorical_crossentropy: 0.3313\n",
            "Epoch 13/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3170 - accuracy: 0.8959 - categorical_crossentropy: 0.3170\n",
            "Epoch 14/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3134 - accuracy: 0.9012 - categorical_crossentropy: 0.3134\n",
            "Epoch 15/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3082 - accuracy: 0.8987 - categorical_crossentropy: 0.3082\n",
            "Epoch 16/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3119 - accuracy: 0.8993 - categorical_crossentropy: 0.3119\n",
            "Epoch 17/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3128 - accuracy: 0.8971 - categorical_crossentropy: 0.3128\n",
            "Epoch 18/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.2965 - accuracy: 0.9037 - categorical_crossentropy: 0.2965\n",
            "Epoch 19/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.2965 - accuracy: 0.9017 - categorical_crossentropy: 0.2965\n",
            "Epoch 20/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.2928 - accuracy: 0.9038 - categorical_crossentropy: 0.2928\n",
            "Epoch 21/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.2866 - accuracy: 0.9058 - categorical_crossentropy: 0.2866\n",
            "Epoch 22/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.2932 - accuracy: 0.9024 - categorical_crossentropy: 0.2932\n",
            "Epoch 23/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.2971 - accuracy: 0.9040 - categorical_crossentropy: 0.2971\n",
            "Epoch 24/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3012 - accuracy: 0.9032 - categorical_crossentropy: 0.3012\n",
            "Epoch 25/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3241 - accuracy: 0.8978 - categorical_crossentropy: 0.3241\n",
            "Epoch 26/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3034 - accuracy: 0.9021 - categorical_crossentropy: 0.3034\n",
            "Epoch 27/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.2940 - accuracy: 0.9040 - categorical_crossentropy: 0.2940\n",
            "Epoch 28/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3008 - accuracy: 0.9006 - categorical_crossentropy: 0.3008\n",
            "Epoch 29/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.2846 - accuracy: 0.9092 - categorical_crossentropy: 0.2846\n",
            "Epoch 30/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.2946 - accuracy: 0.9030 - categorical_crossentropy: 0.2946\n",
            "Epoch 31/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3055 - accuracy: 0.9025 - categorical_crossentropy: 0.3055\n",
            "Epoch 32/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3133 - accuracy: 0.8994 - categorical_crossentropy: 0.3133\n",
            "Epoch 33/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3141 - accuracy: 0.9026 - categorical_crossentropy: 0.3141\n",
            "Epoch 34/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3283 - accuracy: 0.8952 - categorical_crossentropy: 0.3283\n",
            "Epoch 35/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3212 - accuracy: 0.8978 - categorical_crossentropy: 0.3212\n",
            "Epoch 36/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3166 - accuracy: 0.9020 - categorical_crossentropy: 0.3166\n",
            "Epoch 37/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3133 - accuracy: 0.9016 - categorical_crossentropy: 0.3133\n",
            "Epoch 38/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3098 - accuracy: 0.9019 - categorical_crossentropy: 0.3098\n",
            "Epoch 39/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3192 - accuracy: 0.8995 - categorical_crossentropy: 0.3192\n",
            "Epoch 40/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3091 - accuracy: 0.8996 - categorical_crossentropy: 0.3091\n",
            "Epoch 41/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3142 - accuracy: 0.9004 - categorical_crossentropy: 0.3142\n",
            "Epoch 42/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3146 - accuracy: 0.8997 - categorical_crossentropy: 0.3146\n",
            "Epoch 43/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3108 - accuracy: 0.8991 - categorical_crossentropy: 0.3108\n",
            "Epoch 44/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3121 - accuracy: 0.8985 - categorical_crossentropy: 0.3121\n",
            "Epoch 45/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.2990 - accuracy: 0.9036 - categorical_crossentropy: 0.2990\n",
            "Epoch 46/50\n",
            "161/161 [==============================] - 1s 5ms/step - loss: 0.2997 - accuracy: 0.9038 - categorical_crossentropy: 0.2997\n",
            "Epoch 47/50\n",
            "161/161 [==============================] - 1s 4ms/step - loss: 0.3002 - accuracy: 0.9050 - categorical_crossentropy: 0.3002\n",
            "Epoch 48/50\n",
            "161/161 [==============================] - 1s 6ms/step - loss: 0.2973 - accuracy: 0.9032 - categorical_crossentropy: 0.2973\n",
            "Epoch 49/50\n",
            "161/161 [==============================] - 1s 4ms/step - loss: 0.2926 - accuracy: 0.9058 - categorical_crossentropy: 0.2926\n",
            "Epoch 50/50\n",
            "161/161 [==============================] - 1s 6ms/step - loss: 0.2953 - accuracy: 0.9026 - categorical_crossentropy: 0.2953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) Dense1_input with unsupported characters which will be renamed to dense1_input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp3bu6c2bt/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp3bu6c2bt/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model is 21864 bytes\n",
            "> 91.111\n",
            "Epoch 1/50\n",
            "161/161 [==============================] - 1s 3ms/step - loss: 0.6323 - accuracy: 0.7431 - categorical_crossentropy: 0.6323\n",
            "Epoch 2/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3776 - accuracy: 0.8835 - categorical_crossentropy: 0.3776\n",
            "Epoch 3/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3335 - accuracy: 0.8974 - categorical_crossentropy: 0.3335\n",
            "Epoch 4/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3341 - accuracy: 0.8968 - categorical_crossentropy: 0.3341\n",
            "Epoch 5/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3273 - accuracy: 0.9006 - categorical_crossentropy: 0.3273\n",
            "Epoch 6/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3128 - accuracy: 0.9037 - categorical_crossentropy: 0.3128\n",
            "Epoch 7/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3329 - accuracy: 0.8981 - categorical_crossentropy: 0.3329\n",
            "Epoch 8/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3331 - accuracy: 0.8962 - categorical_crossentropy: 0.3331\n",
            "Epoch 9/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3343 - accuracy: 0.8938 - categorical_crossentropy: 0.3343\n",
            "Epoch 10/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3217 - accuracy: 0.9009 - categorical_crossentropy: 0.3217\n",
            "Epoch 11/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3176 - accuracy: 0.9001 - categorical_crossentropy: 0.3176\n",
            "Epoch 12/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3271 - accuracy: 0.8958 - categorical_crossentropy: 0.3271\n",
            "Epoch 13/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3255 - accuracy: 0.8991 - categorical_crossentropy: 0.3255\n",
            "Epoch 14/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3201 - accuracy: 0.8984 - categorical_crossentropy: 0.3201\n",
            "Epoch 15/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3210 - accuracy: 0.8974 - categorical_crossentropy: 0.3210\n",
            "Epoch 16/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3110 - accuracy: 0.9019 - categorical_crossentropy: 0.3110\n",
            "Epoch 17/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3318 - accuracy: 0.8948 - categorical_crossentropy: 0.3318\n",
            "Epoch 18/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3334 - accuracy: 0.8955 - categorical_crossentropy: 0.3334\n",
            "Epoch 19/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3207 - accuracy: 0.8989 - categorical_crossentropy: 0.3207\n",
            "Epoch 20/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3198 - accuracy: 0.8976 - categorical_crossentropy: 0.3198\n",
            "Epoch 21/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3201 - accuracy: 0.8991 - categorical_crossentropy: 0.3201\n",
            "Epoch 22/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3141 - accuracy: 0.9020 - categorical_crossentropy: 0.3141\n",
            "Epoch 23/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3302 - accuracy: 0.8972 - categorical_crossentropy: 0.3302\n",
            "Epoch 24/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3228 - accuracy: 0.8986 - categorical_crossentropy: 0.3228\n",
            "Epoch 25/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3108 - accuracy: 0.8993 - categorical_crossentropy: 0.3108\n",
            "Epoch 26/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3113 - accuracy: 0.8992 - categorical_crossentropy: 0.3113\n",
            "Epoch 27/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3258 - accuracy: 0.8958 - categorical_crossentropy: 0.3258\n",
            "Epoch 28/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3095 - accuracy: 0.9011 - categorical_crossentropy: 0.3095\n",
            "Epoch 29/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3251 - accuracy: 0.8955 - categorical_crossentropy: 0.3251\n",
            "Epoch 30/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3055 - accuracy: 0.9033 - categorical_crossentropy: 0.3055\n",
            "Epoch 31/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3058 - accuracy: 0.9017 - categorical_crossentropy: 0.3058\n",
            "Epoch 32/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3138 - accuracy: 0.8990 - categorical_crossentropy: 0.3138\n",
            "Epoch 33/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3170 - accuracy: 0.8997 - categorical_crossentropy: 0.3170\n",
            "Epoch 34/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3090 - accuracy: 0.9032 - categorical_crossentropy: 0.3090\n",
            "Epoch 35/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.2974 - accuracy: 0.9045 - categorical_crossentropy: 0.2974\n",
            "Epoch 36/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3021 - accuracy: 0.9039 - categorical_crossentropy: 0.3021\n",
            "Epoch 37/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3066 - accuracy: 0.9041 - categorical_crossentropy: 0.3066\n",
            "Epoch 38/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3027 - accuracy: 0.9040 - categorical_crossentropy: 0.3027\n",
            "Epoch 39/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.2993 - accuracy: 0.9038 - categorical_crossentropy: 0.2993\n",
            "Epoch 40/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.2981 - accuracy: 0.9047 - categorical_crossentropy: 0.2981\n",
            "Epoch 41/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3006 - accuracy: 0.9028 - categorical_crossentropy: 0.3006\n",
            "Epoch 42/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3070 - accuracy: 0.9021 - categorical_crossentropy: 0.3070\n",
            "Epoch 43/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3041 - accuracy: 0.9018 - categorical_crossentropy: 0.3041\n",
            "Epoch 44/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.2947 - accuracy: 0.9038 - categorical_crossentropy: 0.2947\n",
            "Epoch 45/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3071 - accuracy: 0.9039 - categorical_crossentropy: 0.3071\n",
            "Epoch 46/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3041 - accuracy: 0.9024 - categorical_crossentropy: 0.3041\n",
            "Epoch 47/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.2981 - accuracy: 0.9044 - categorical_crossentropy: 0.2981\n",
            "Epoch 48/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.2904 - accuracy: 0.9048 - categorical_crossentropy: 0.2904\n",
            "Epoch 49/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.2946 - accuracy: 0.9057 - categorical_crossentropy: 0.2946\n",
            "Epoch 50/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.2974 - accuracy: 0.9037 - categorical_crossentropy: 0.2974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) Dense1_input with unsupported characters which will be renamed to dense1_input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpr6h92qrc/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpr6h92qrc/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model is 21864 bytes\n",
            "> 91.423\n",
            "Epoch 1/50\n",
            "161/161 [==============================] - 1s 3ms/step - loss: 0.6699 - accuracy: 0.7167 - categorical_crossentropy: 0.6699\n",
            "Epoch 2/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3492 - accuracy: 0.8914 - categorical_crossentropy: 0.3492\n",
            "Epoch 3/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3392 - accuracy: 0.8902 - categorical_crossentropy: 0.3392\n",
            "Epoch 4/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3474 - accuracy: 0.8928 - categorical_crossentropy: 0.3474\n",
            "Epoch 5/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3305 - accuracy: 0.8958 - categorical_crossentropy: 0.3305\n",
            "Epoch 6/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3536 - accuracy: 0.8834 - categorical_crossentropy: 0.3536\n",
            "Epoch 7/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3410 - accuracy: 0.8861 - categorical_crossentropy: 0.3410\n",
            "Epoch 8/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3467 - accuracy: 0.8828 - categorical_crossentropy: 0.3467\n",
            "Epoch 9/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3625 - accuracy: 0.8784 - categorical_crossentropy: 0.3625\n",
            "Epoch 10/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3543 - accuracy: 0.8805 - categorical_crossentropy: 0.3543\n",
            "Epoch 11/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3687 - accuracy: 0.8668 - categorical_crossentropy: 0.3687\n",
            "Epoch 12/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3707 - accuracy: 0.8736 - categorical_crossentropy: 0.3707\n",
            "Epoch 13/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3664 - accuracy: 0.8807 - categorical_crossentropy: 0.3664\n",
            "Epoch 14/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3608 - accuracy: 0.8827 - categorical_crossentropy: 0.3608\n",
            "Epoch 15/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3591 - accuracy: 0.8810 - categorical_crossentropy: 0.3591\n",
            "Epoch 16/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3452 - accuracy: 0.8855 - categorical_crossentropy: 0.3452\n",
            "Epoch 17/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3707 - accuracy: 0.8702 - categorical_crossentropy: 0.3707\n",
            "Epoch 18/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3639 - accuracy: 0.8715 - categorical_crossentropy: 0.3639\n",
            "Epoch 19/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3389 - accuracy: 0.8858 - categorical_crossentropy: 0.3389\n",
            "Epoch 20/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3314 - accuracy: 0.8878 - categorical_crossentropy: 0.3314\n",
            "Epoch 21/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3525 - accuracy: 0.8837 - categorical_crossentropy: 0.3525\n",
            "Epoch 22/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3528 - accuracy: 0.8838 - categorical_crossentropy: 0.3528\n",
            "Epoch 23/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3687 - accuracy: 0.8774 - categorical_crossentropy: 0.3687\n",
            "Epoch 24/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3605 - accuracy: 0.8825 - categorical_crossentropy: 0.3605\n",
            "Epoch 25/50\n",
            "161/161 [==============================] - 1s 3ms/step - loss: 0.4102 - accuracy: 0.8732 - categorical_crossentropy: 0.4102\n",
            "Epoch 26/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.4076 - accuracy: 0.8702 - categorical_crossentropy: 0.4076\n",
            "Epoch 27/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3977 - accuracy: 0.8761 - categorical_crossentropy: 0.3977\n",
            "Epoch 28/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3888 - accuracy: 0.8803 - categorical_crossentropy: 0.3888\n",
            "Epoch 29/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3850 - accuracy: 0.8795 - categorical_crossentropy: 0.3850\n",
            "Epoch 30/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3811 - accuracy: 0.8815 - categorical_crossentropy: 0.3811\n",
            "Epoch 31/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3849 - accuracy: 0.8808 - categorical_crossentropy: 0.3849\n",
            "Epoch 32/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3807 - accuracy: 0.8780 - categorical_crossentropy: 0.3807\n",
            "Epoch 33/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3658 - accuracy: 0.8775 - categorical_crossentropy: 0.3658\n",
            "Epoch 34/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3579 - accuracy: 0.8796 - categorical_crossentropy: 0.3579\n",
            "Epoch 35/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3624 - accuracy: 0.8824 - categorical_crossentropy: 0.3624\n",
            "Epoch 36/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3662 - accuracy: 0.8809 - categorical_crossentropy: 0.3662\n",
            "Epoch 37/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3582 - accuracy: 0.8803 - categorical_crossentropy: 0.3582\n",
            "Epoch 38/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3455 - accuracy: 0.8845 - categorical_crossentropy: 0.3455\n",
            "Epoch 39/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3410 - accuracy: 0.8847 - categorical_crossentropy: 0.3410\n",
            "Epoch 40/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3368 - accuracy: 0.8890 - categorical_crossentropy: 0.3368\n",
            "Epoch 41/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3352 - accuracy: 0.8865 - categorical_crossentropy: 0.3352\n",
            "Epoch 42/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3389 - accuracy: 0.8846 - categorical_crossentropy: 0.3389\n",
            "Epoch 43/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3406 - accuracy: 0.8872 - categorical_crossentropy: 0.3406\n",
            "Epoch 44/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3400 - accuracy: 0.8848 - categorical_crossentropy: 0.3400\n",
            "Epoch 45/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3351 - accuracy: 0.8866 - categorical_crossentropy: 0.3351\n",
            "Epoch 46/50\n",
            "161/161 [==============================] - 1s 3ms/step - loss: 0.3377 - accuracy: 0.8861 - categorical_crossentropy: 0.3377\n",
            "Epoch 47/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3297 - accuracy: 0.8898 - categorical_crossentropy: 0.3297\n",
            "Epoch 48/50\n",
            "161/161 [==============================] - 1s 3ms/step - loss: 0.3342 - accuracy: 0.8888 - categorical_crossentropy: 0.3342\n",
            "Epoch 49/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3290 - accuracy: 0.8872 - categorical_crossentropy: 0.3290\n",
            "Epoch 50/50\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.3208 - accuracy: 0.8903 - categorical_crossentropy: 0.3208\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: 'zmq.backend.cython.message.Frame.__dealloc__'\n",
            "Traceback (most recent call last):\n",
            "  File \"zmq/backend/cython/checkrc.pxd\", line 13, in zmq.backend.cython.checkrc._check_rc\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85CE4zRop0XI",
        "outputId": "c6e04de6-a8d7-441a-e4b5-7b7c9cf331d8"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.48810703666997024,\n",
              " 0.9266600594648167,\n",
              " 0.9271555996035679,\n",
              " 0.8072348860257681,\n",
              " 0.8973723351512147]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yoyo = nom_bal_X.reshape((nom_bal_X.shape[0], nom_bal_X.shape[1]))\n",
        "nom_bal_X.shape\n",
        "yoyo.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVYIaFmCknWP",
        "outputId": "33d3db94-b4cf-4cf4-dd2e-e17d90a17041"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12390, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YhkI1wnD2bC"
      },
      "outputs": [],
      "source": [
        "scores, h, crossentropy = evaluate_model(bal_X, bal_one_hot_Y, bal_Y)\n",
        "print(np.mean(scores), np.mean(crossentropy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KS8J7jTqD2bC"
      },
      "outputs": [],
      "source": [
        "scores, h, crossentropy = evaluate_model(nom_bal_X, nom_bal_one_hot_Y, nom_bal_Y)\n",
        "print(np.mean(scores), np.mean(crossentropy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "7fEsXRrHD2bC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "401dca1b-9817-4bc3-d85d-04a305cb89ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "316/316 [==============================] - 2s 3ms/step - loss: 0.7472 - accuracy: 0.6675 - categorical_crossentropy: 0.7472\n",
            "Epoch 2/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.3598 - accuracy: 0.9059 - categorical_crossentropy: 0.3598\n",
            "Epoch 3/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.3322 - accuracy: 0.9066 - categorical_crossentropy: 0.3322\n",
            "Epoch 4/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2960 - accuracy: 0.9174 - categorical_crossentropy: 0.2960\n",
            "Epoch 5/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2735 - accuracy: 0.9195 - categorical_crossentropy: 0.2735\n",
            "Epoch 6/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2771 - accuracy: 0.9202 - categorical_crossentropy: 0.2771\n",
            "Epoch 7/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2799 - accuracy: 0.9158 - categorical_crossentropy: 0.2799\n",
            "Epoch 8/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2718 - accuracy: 0.9199 - categorical_crossentropy: 0.2718\n",
            "Epoch 9/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2684 - accuracy: 0.9206 - categorical_crossentropy: 0.2684\n",
            "Epoch 10/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2603 - accuracy: 0.9224 - categorical_crossentropy: 0.2603\n",
            "Epoch 11/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2575 - accuracy: 0.9238 - categorical_crossentropy: 0.2575\n",
            "Epoch 12/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2545 - accuracy: 0.9242 - categorical_crossentropy: 0.2545\n",
            "Epoch 13/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2583 - accuracy: 0.9232 - categorical_crossentropy: 0.2583\n",
            "Epoch 14/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2581 - accuracy: 0.9213 - categorical_crossentropy: 0.2581\n",
            "Epoch 15/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2611 - accuracy: 0.9252 - categorical_crossentropy: 0.2611\n",
            "Epoch 16/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2598 - accuracy: 0.9218 - categorical_crossentropy: 0.2598\n",
            "Epoch 17/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2546 - accuracy: 0.9245 - categorical_crossentropy: 0.2546\n",
            "Epoch 18/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2570 - accuracy: 0.9220 - categorical_crossentropy: 0.2570\n",
            "Epoch 19/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2587 - accuracy: 0.9219 - categorical_crossentropy: 0.2587\n",
            "Epoch 20/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2594 - accuracy: 0.9217 - categorical_crossentropy: 0.2594\n",
            "Epoch 21/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2567 - accuracy: 0.9247 - categorical_crossentropy: 0.2567\n",
            "Epoch 22/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2528 - accuracy: 0.9237 - categorical_crossentropy: 0.2528\n",
            "Epoch 23/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2576 - accuracy: 0.9227 - categorical_crossentropy: 0.2576\n",
            "Epoch 24/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2699 - accuracy: 0.9209 - categorical_crossentropy: 0.2699\n",
            "Epoch 25/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2549 - accuracy: 0.9241 - categorical_crossentropy: 0.2549\n",
            "Epoch 26/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2516 - accuracy: 0.9246 - categorical_crossentropy: 0.2516\n",
            "Epoch 27/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2525 - accuracy: 0.9240 - categorical_crossentropy: 0.2525\n",
            "Epoch 28/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2532 - accuracy: 0.9227 - categorical_crossentropy: 0.2532\n",
            "Epoch 29/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2487 - accuracy: 0.9263 - categorical_crossentropy: 0.2487\n",
            "Epoch 30/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2530 - accuracy: 0.9231 - categorical_crossentropy: 0.2530\n",
            "Epoch 31/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2535 - accuracy: 0.9244 - categorical_crossentropy: 0.2535\n",
            "Epoch 32/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2501 - accuracy: 0.9253 - categorical_crossentropy: 0.2501\n",
            "Epoch 33/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2519 - accuracy: 0.9244 - categorical_crossentropy: 0.2519\n",
            "Epoch 34/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2541 - accuracy: 0.9222 - categorical_crossentropy: 0.2541\n",
            "Epoch 35/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2663 - accuracy: 0.9204 - categorical_crossentropy: 0.2663\n",
            "Epoch 36/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2454 - accuracy: 0.9251 - categorical_crossentropy: 0.2454\n",
            "Epoch 37/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2533 - accuracy: 0.9235 - categorical_crossentropy: 0.2533\n",
            "Epoch 38/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2563 - accuracy: 0.9224 - categorical_crossentropy: 0.2563\n",
            "Epoch 39/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2593 - accuracy: 0.9221 - categorical_crossentropy: 0.2593\n",
            "Epoch 40/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2558 - accuracy: 0.9242 - categorical_crossentropy: 0.2558\n",
            "Epoch 41/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2619 - accuracy: 0.9211 - categorical_crossentropy: 0.2619\n",
            "Epoch 42/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2764 - accuracy: 0.9107 - categorical_crossentropy: 0.2764\n",
            "Epoch 43/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2539 - accuracy: 0.9217 - categorical_crossentropy: 0.2539\n",
            "Epoch 44/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2624 - accuracy: 0.9201 - categorical_crossentropy: 0.2624\n",
            "Epoch 45/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2494 - accuracy: 0.9273 - categorical_crossentropy: 0.2494\n",
            "Epoch 46/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2510 - accuracy: 0.9250 - categorical_crossentropy: 0.2510\n",
            "Epoch 47/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2563 - accuracy: 0.9232 - categorical_crossentropy: 0.2563\n",
            "Epoch 48/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2508 - accuracy: 0.9255 - categorical_crossentropy: 0.2508\n",
            "Epoch 49/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2451 - accuracy: 0.9256 - categorical_crossentropy: 0.2451\n",
            "Epoch 50/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2448 - accuracy: 0.9261 - categorical_crossentropy: 0.2448\n",
            "Epoch 51/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2510 - accuracy: 0.9242 - categorical_crossentropy: 0.2510\n",
            "Epoch 52/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2905 - accuracy: 0.9147 - categorical_crossentropy: 0.2905\n",
            "Epoch 53/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2456 - accuracy: 0.9243 - categorical_crossentropy: 0.2456\n",
            "Epoch 54/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2460 - accuracy: 0.9267 - categorical_crossentropy: 0.2460\n",
            "Epoch 55/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2641 - accuracy: 0.9229 - categorical_crossentropy: 0.2641\n",
            "Epoch 56/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2872 - accuracy: 0.9167 - categorical_crossentropy: 0.2872\n",
            "Epoch 57/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2700 - accuracy: 0.9188 - categorical_crossentropy: 0.2700\n",
            "Epoch 58/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2566 - accuracy: 0.9235 - categorical_crossentropy: 0.2566\n",
            "Epoch 59/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2635 - accuracy: 0.9209 - categorical_crossentropy: 0.2635\n",
            "Epoch 60/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2583 - accuracy: 0.9241 - categorical_crossentropy: 0.2583\n",
            "Epoch 61/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2491 - accuracy: 0.9250 - categorical_crossentropy: 0.2491\n",
            "Epoch 62/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2608 - accuracy: 0.9183 - categorical_crossentropy: 0.2608\n",
            "Epoch 63/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2737 - accuracy: 0.9154 - categorical_crossentropy: 0.2737\n",
            "Epoch 64/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2639 - accuracy: 0.9176 - categorical_crossentropy: 0.2639\n",
            "Epoch 65/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2594 - accuracy: 0.9226 - categorical_crossentropy: 0.2594\n",
            "Epoch 66/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2550 - accuracy: 0.9251 - categorical_crossentropy: 0.2550\n",
            "Epoch 67/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2546 - accuracy: 0.9211 - categorical_crossentropy: 0.2546\n",
            "Epoch 68/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2563 - accuracy: 0.9197 - categorical_crossentropy: 0.2563\n",
            "Epoch 69/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2650 - accuracy: 0.9222 - categorical_crossentropy: 0.2650\n",
            "Epoch 70/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2517 - accuracy: 0.9238 - categorical_crossentropy: 0.2517\n",
            "Epoch 71/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2543 - accuracy: 0.9238 - categorical_crossentropy: 0.2543\n",
            "Epoch 72/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2557 - accuracy: 0.9217 - categorical_crossentropy: 0.2557\n",
            "Epoch 73/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2435 - accuracy: 0.9257 - categorical_crossentropy: 0.2435\n",
            "Epoch 74/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2619 - accuracy: 0.9216 - categorical_crossentropy: 0.2619\n",
            "Epoch 75/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2548 - accuracy: 0.9190 - categorical_crossentropy: 0.2548\n",
            "Epoch 76/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2460 - accuracy: 0.9263 - categorical_crossentropy: 0.2460\n",
            "Epoch 77/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2514 - accuracy: 0.9227 - categorical_crossentropy: 0.2514\n",
            "Epoch 78/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2600 - accuracy: 0.9196 - categorical_crossentropy: 0.2600\n",
            "Epoch 79/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2646 - accuracy: 0.9187 - categorical_crossentropy: 0.2646\n",
            "Epoch 80/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2513 - accuracy: 0.9232 - categorical_crossentropy: 0.2513\n",
            "Epoch 81/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2591 - accuracy: 0.9215 - categorical_crossentropy: 0.2591\n",
            "Epoch 82/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2552 - accuracy: 0.9185 - categorical_crossentropy: 0.2552\n",
            "Epoch 83/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2626 - accuracy: 0.9159 - categorical_crossentropy: 0.2626\n",
            "Epoch 84/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2792 - accuracy: 0.9130 - categorical_crossentropy: 0.2792\n",
            "Epoch 85/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2511 - accuracy: 0.9236 - categorical_crossentropy: 0.2511\n",
            "Epoch 86/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2503 - accuracy: 0.9239 - categorical_crossentropy: 0.2503\n",
            "Epoch 87/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2685 - accuracy: 0.9222 - categorical_crossentropy: 0.2685\n",
            "Epoch 88/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2502 - accuracy: 0.9237 - categorical_crossentropy: 0.2502\n",
            "Epoch 89/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.3714 - accuracy: 0.8805 - categorical_crossentropy: 0.3714\n",
            "Epoch 90/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2559 - accuracy: 0.9248 - categorical_crossentropy: 0.2559\n",
            "Epoch 91/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2511 - accuracy: 0.9248 - categorical_crossentropy: 0.2511\n",
            "Epoch 92/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2571 - accuracy: 0.9232 - categorical_crossentropy: 0.2571\n",
            "Epoch 93/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2482 - accuracy: 0.9275 - categorical_crossentropy: 0.2482\n",
            "Epoch 94/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2705 - accuracy: 0.9187 - categorical_crossentropy: 0.2705\n",
            "Epoch 95/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2575 - accuracy: 0.9219 - categorical_crossentropy: 0.2575\n",
            "Epoch 96/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2537 - accuracy: 0.9243 - categorical_crossentropy: 0.2537\n",
            "Epoch 97/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2529 - accuracy: 0.9234 - categorical_crossentropy: 0.2529\n",
            "Epoch 98/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2603 - accuracy: 0.9219 - categorical_crossentropy: 0.2603\n",
            "Epoch 99/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2564 - accuracy: 0.9246 - categorical_crossentropy: 0.2564\n",
            "Epoch 100/100\n",
            "316/316 [==============================] - 1s 3ms/step - loss: 0.2524 - accuracy: 0.9250 - categorical_crossentropy: 0.2524\n"
          ]
        }
      ],
      "source": [
        "model = define_model(lr=0.005)\n",
        "train_model(model, nom_bal_X, nom_bal_one_hot_Y, epochs=100, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_model_lite(model, \"no_magneto_b64_005_93_small_all_data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Vd7fxXagEvH",
        "outputId": "23d24581-481a-4adf-c1bb-fe0300255fc0"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) Dense1_input with unsupported characters which will be renamed to dense1_input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp1ve7igbc/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp1ve7igbc/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model is 21844 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7I4t95yD2bD",
        "outputId": "0aa4bcbc-fe65-41ec-e734-f636fb83608f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.6762 - accuracy: 0.7347 - categorical_crossentropy: 0.6762\n",
            "Epoch 2/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.3904 - accuracy: 0.8807 - categorical_crossentropy: 0.3904\n",
            "Epoch 3/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.3470 - accuracy: 0.8877 - categorical_crossentropy: 0.3470\n",
            "Epoch 4/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.3490 - accuracy: 0.8908 - categorical_crossentropy: 0.3490\n",
            "Epoch 5/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.3463 - accuracy: 0.8897 - categorical_crossentropy: 0.3463\n",
            "Epoch 6/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.3314 - accuracy: 0.8936 - categorical_crossentropy: 0.3314\n",
            "Epoch 7/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.3277 - accuracy: 0.8968 - categorical_crossentropy: 0.3277\n",
            "Epoch 8/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.3234 - accuracy: 0.8979 - categorical_crossentropy: 0.3234\n",
            "Epoch 9/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.3450 - accuracy: 0.8890 - categorical_crossentropy: 0.3450\n",
            "Epoch 10/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.3559 - accuracy: 0.8899 - categorical_crossentropy: 0.3559\n",
            "Epoch 11/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.3567 - accuracy: 0.8877 - categorical_crossentropy: 0.3567\n",
            "Epoch 12/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.3373 - accuracy: 0.8933 - categorical_crossentropy: 0.3373\n",
            "Epoch 13/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.3258 - accuracy: 0.8983 - categorical_crossentropy: 0.3258\n",
            "Epoch 14/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.3267 - accuracy: 0.8979 - categorical_crossentropy: 0.3267\n",
            "Epoch 15/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.3221 - accuracy: 0.8992 - categorical_crossentropy: 0.3221\n",
            "Epoch 16/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.3247 - accuracy: 0.8982 - categorical_crossentropy: 0.3247\n",
            "Epoch 17/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.3251 - accuracy: 0.8982 - categorical_crossentropy: 0.3251\n",
            "Epoch 18/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.3236 - accuracy: 0.9009 - categorical_crossentropy: 0.3236\n",
            "Epoch 19/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.3161 - accuracy: 0.9000 - categorical_crossentropy: 0.3161\n",
            "Epoch 20/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.3051 - accuracy: 0.9028 - categorical_crossentropy: 0.3051\n",
            "Epoch 21/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.3019 - accuracy: 0.9051 - categorical_crossentropy: 0.3019\n",
            "Epoch 22/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.3038 - accuracy: 0.9006 - categorical_crossentropy: 0.3038\n",
            "Epoch 23/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.3070 - accuracy: 0.9033 - categorical_crossentropy: 0.3070\n",
            "Epoch 24/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.3005 - accuracy: 0.9060 - categorical_crossentropy: 0.3005\n",
            "Epoch 25/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.3079 - accuracy: 0.9024 - categorical_crossentropy: 0.3079\n",
            "Epoch 26/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2960 - accuracy: 0.9053 - categorical_crossentropy: 0.2960\n",
            "Epoch 27/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2960 - accuracy: 0.9054 - categorical_crossentropy: 0.2960\n",
            "Epoch 28/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2923 - accuracy: 0.9067 - categorical_crossentropy: 0.2923\n",
            "Epoch 29/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.3054 - accuracy: 0.9034 - categorical_crossentropy: 0.3054\n",
            "Epoch 30/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2941 - accuracy: 0.9053 - categorical_crossentropy: 0.2941\n",
            "Epoch 31/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2962 - accuracy: 0.9048 - categorical_crossentropy: 0.2962\n",
            "Epoch 32/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2904 - accuracy: 0.9071 - categorical_crossentropy: 0.2904\n",
            "Epoch 33/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2947 - accuracy: 0.9043 - categorical_crossentropy: 0.2947\n",
            "Epoch 34/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2983 - accuracy: 0.9053 - categorical_crossentropy: 0.2983\n",
            "Epoch 35/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2935 - accuracy: 0.9055 - categorical_crossentropy: 0.2935\n",
            "Epoch 36/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2991 - accuracy: 0.9055 - categorical_crossentropy: 0.2991\n",
            "Epoch 37/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2932 - accuracy: 0.9072 - categorical_crossentropy: 0.2932\n",
            "Epoch 38/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2987 - accuracy: 0.9040 - categorical_crossentropy: 0.2987\n",
            "Epoch 39/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2914 - accuracy: 0.9054 - categorical_crossentropy: 0.2914\n",
            "Epoch 40/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.3006 - accuracy: 0.9046 - categorical_crossentropy: 0.3006\n",
            "Epoch 41/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2897 - accuracy: 0.9053 - categorical_crossentropy: 0.2897\n",
            "Epoch 42/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2845 - accuracy: 0.9074 - categorical_crossentropy: 0.2845\n",
            "Epoch 43/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2896 - accuracy: 0.9078 - categorical_crossentropy: 0.2896\n",
            "Epoch 44/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2856 - accuracy: 0.9088 - categorical_crossentropy: 0.2856\n",
            "Epoch 45/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2875 - accuracy: 0.9080 - categorical_crossentropy: 0.2875\n",
            "Epoch 46/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2861 - accuracy: 0.9091 - categorical_crossentropy: 0.2861\n",
            "Epoch 47/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2948 - accuracy: 0.9047 - categorical_crossentropy: 0.2948\n",
            "Epoch 48/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2835 - accuracy: 0.9087 - categorical_crossentropy: 0.2835\n",
            "Epoch 49/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2836 - accuracy: 0.9104 - categorical_crossentropy: 0.2836\n",
            "Epoch 50/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2859 - accuracy: 0.9089 - categorical_crossentropy: 0.2859\n",
            "Epoch 51/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2802 - accuracy: 0.9095 - categorical_crossentropy: 0.2802\n",
            "Epoch 52/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2892 - accuracy: 0.9070 - categorical_crossentropy: 0.2892\n",
            "Epoch 53/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2813 - accuracy: 0.9071 - categorical_crossentropy: 0.2813\n",
            "Epoch 54/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2872 - accuracy: 0.9081 - categorical_crossentropy: 0.2872\n",
            "Epoch 55/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2766 - accuracy: 0.9087 - categorical_crossentropy: 0.2766\n",
            "Epoch 56/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2903 - accuracy: 0.9062 - categorical_crossentropy: 0.2903\n",
            "Epoch 57/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2818 - accuracy: 0.9081 - categorical_crossentropy: 0.2818\n",
            "Epoch 58/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2832 - accuracy: 0.9079 - categorical_crossentropy: 0.2832\n",
            "Epoch 59/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2869 - accuracy: 0.9083 - categorical_crossentropy: 0.2869\n",
            "Epoch 60/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2944 - accuracy: 0.9039 - categorical_crossentropy: 0.2944\n",
            "Epoch 61/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.3048 - accuracy: 0.9054 - categorical_crossentropy: 0.3048\n",
            "Epoch 62/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.3034 - accuracy: 0.9047 - categorical_crossentropy: 0.3034\n",
            "Epoch 63/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2991 - accuracy: 0.9027 - categorical_crossentropy: 0.2991\n",
            "Epoch 64/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.3009 - accuracy: 0.9050 - categorical_crossentropy: 0.3009\n",
            "Epoch 65/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2902 - accuracy: 0.9074 - categorical_crossentropy: 0.2902\n",
            "Epoch 66/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2918 - accuracy: 0.9046 - categorical_crossentropy: 0.2918\n",
            "Epoch 67/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2941 - accuracy: 0.9080 - categorical_crossentropy: 0.2941\n",
            "Epoch 68/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2953 - accuracy: 0.9058 - categorical_crossentropy: 0.2953\n",
            "Epoch 69/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2904 - accuracy: 0.9060 - categorical_crossentropy: 0.2904\n",
            "Epoch 70/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2926 - accuracy: 0.9078 - categorical_crossentropy: 0.2926\n",
            "Epoch 71/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2881 - accuracy: 0.9069 - categorical_crossentropy: 0.2881\n",
            "Epoch 72/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2937 - accuracy: 0.9050 - categorical_crossentropy: 0.2937\n",
            "Epoch 73/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2876 - accuracy: 0.9079 - categorical_crossentropy: 0.2876\n",
            "Epoch 74/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2980 - accuracy: 0.9037 - categorical_crossentropy: 0.2980\n",
            "Epoch 75/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2891 - accuracy: 0.9057 - categorical_crossentropy: 0.2891\n",
            "Epoch 76/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2941 - accuracy: 0.9065 - categorical_crossentropy: 0.2941\n",
            "Epoch 77/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2899 - accuracy: 0.9071 - categorical_crossentropy: 0.2899\n",
            "Epoch 78/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2872 - accuracy: 0.9088 - categorical_crossentropy: 0.2872\n",
            "Epoch 79/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2953 - accuracy: 0.9054 - categorical_crossentropy: 0.2953\n",
            "Epoch 80/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2905 - accuracy: 0.9090 - categorical_crossentropy: 0.2905\n",
            "Epoch 81/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2877 - accuracy: 0.9077 - categorical_crossentropy: 0.2877\n",
            "Epoch 82/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2809 - accuracy: 0.9092 - categorical_crossentropy: 0.2809\n",
            "Epoch 83/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2892 - accuracy: 0.9074 - categorical_crossentropy: 0.2892\n",
            "Epoch 84/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.3011 - accuracy: 0.9039 - categorical_crossentropy: 0.3011\n",
            "Epoch 85/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2882 - accuracy: 0.9081 - categorical_crossentropy: 0.2882\n",
            "Epoch 86/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2841 - accuracy: 0.9081 - categorical_crossentropy: 0.2841\n",
            "Epoch 87/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2855 - accuracy: 0.9104 - categorical_crossentropy: 0.2855\n",
            "Epoch 88/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2898 - accuracy: 0.9067 - categorical_crossentropy: 0.2898\n",
            "Epoch 89/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2901 - accuracy: 0.9076 - categorical_crossentropy: 0.2901\n",
            "Epoch 90/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2844 - accuracy: 0.9085 - categorical_crossentropy: 0.2844\n",
            "Epoch 91/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2828 - accuracy: 0.9087 - categorical_crossentropy: 0.2828\n",
            "Epoch 92/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2847 - accuracy: 0.9072 - categorical_crossentropy: 0.2847\n",
            "Epoch 93/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2787 - accuracy: 0.9112 - categorical_crossentropy: 0.2787\n",
            "Epoch 94/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2905 - accuracy: 0.9050 - categorical_crossentropy: 0.2905\n",
            "Epoch 95/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2916 - accuracy: 0.9045 - categorical_crossentropy: 0.2916\n",
            "Epoch 96/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2933 - accuracy: 0.9054 - categorical_crossentropy: 0.2933\n",
            "Epoch 97/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2890 - accuracy: 0.9057 - categorical_crossentropy: 0.2890\n",
            "Epoch 98/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2992 - accuracy: 0.9037 - categorical_crossentropy: 0.2992\n",
            "Epoch 99/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2807 - accuracy: 0.9073 - categorical_crossentropy: 0.2807\n",
            "Epoch 100/100\n",
            "201/201 [==============================] - 1s 3ms/step - loss: 0.2899 - accuracy: 0.9069 - categorical_crossentropy: 0.2899\n"
          ]
        }
      ],
      "source": [
        "model = define_model_2(lr=0.005)\n",
        "train_model(model, nom_bal_X, nom_bal_one_hot_Y, epochs=100, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_model_lite(model, \"no_magneto_b64_003_91_small\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64EYvZdmiyq3",
        "outputId": "514520be-e2fb-4b63-be57-bb1568bb0930"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) Dense1_input with unsupported characters which will be renamed to dense1_input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpgni0yqfe/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpgni0yqfe/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model is 21844 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = define_model_3(lr=0.01)\n",
        "train_model(model, yoyo, nom_bal_one_hot_Y, epochs=100, batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPElLhr9ceLh",
        "outputId": "37e5de0d-bee1-4631-eee3-5248bf57e080"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.9051 - accuracy: 0.5546 - categorical_crossentropy: 0.9051\n",
            "Epoch 2/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.6385 - accuracy: 0.7329 - categorical_crossentropy: 0.6385\n",
            "Epoch 3/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.5362 - accuracy: 0.7400 - categorical_crossentropy: 0.5362\n",
            "Epoch 4/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.5367 - accuracy: 0.7366 - categorical_crossentropy: 0.5367\n",
            "Epoch 5/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.5217 - accuracy: 0.7419 - categorical_crossentropy: 0.5217\n",
            "Epoch 6/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.5175 - accuracy: 0.7467 - categorical_crossentropy: 0.5175\n",
            "Epoch 7/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.5203 - accuracy: 0.7380 - categorical_crossentropy: 0.5203\n",
            "Epoch 8/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.5047 - accuracy: 0.7496 - categorical_crossentropy: 0.5047\n",
            "Epoch 9/100\n",
            "194/194 [==============================] - 1s 3ms/step - loss: 0.5041 - accuracy: 0.7474 - categorical_crossentropy: 0.5041\n",
            "Epoch 10/100\n",
            "194/194 [==============================] - 1s 3ms/step - loss: 0.5083 - accuracy: 0.7539 - categorical_crossentropy: 0.5083\n",
            "Epoch 11/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.4801 - accuracy: 0.7877 - categorical_crossentropy: 0.4801\n",
            "Epoch 12/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.4620 - accuracy: 0.7967 - categorical_crossentropy: 0.4620\n",
            "Epoch 13/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.4531 - accuracy: 0.7972 - categorical_crossentropy: 0.4531\n",
            "Epoch 14/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.4540 - accuracy: 0.7953 - categorical_crossentropy: 0.4540\n",
            "Epoch 15/100\n",
            "194/194 [==============================] - 1s 3ms/step - loss: 0.4557 - accuracy: 0.8000 - categorical_crossentropy: 0.4557\n",
            "Epoch 16/100\n",
            "194/194 [==============================] - 1s 3ms/step - loss: 0.4430 - accuracy: 0.7993 - categorical_crossentropy: 0.4430\n",
            "Epoch 17/100\n",
            "194/194 [==============================] - 1s 3ms/step - loss: 0.4466 - accuracy: 0.8019 - categorical_crossentropy: 0.4466\n",
            "Epoch 18/100\n",
            "194/194 [==============================] - 1s 3ms/step - loss: 0.4459 - accuracy: 0.7973 - categorical_crossentropy: 0.4459\n",
            "Epoch 19/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.4585 - accuracy: 0.7925 - categorical_crossentropy: 0.4585\n",
            "Epoch 20/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.4519 - accuracy: 0.7990 - categorical_crossentropy: 0.4519\n",
            "Epoch 21/100\n",
            "194/194 [==============================] - 1s 3ms/step - loss: 0.4402 - accuracy: 0.8021 - categorical_crossentropy: 0.4402\n",
            "Epoch 22/100\n",
            "194/194 [==============================] - 1s 3ms/step - loss: 0.4365 - accuracy: 0.7990 - categorical_crossentropy: 0.4365\n",
            "Epoch 23/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.4441 - accuracy: 0.8027 - categorical_crossentropy: 0.4441\n",
            "Epoch 24/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.4394 - accuracy: 0.8030 - categorical_crossentropy: 0.4394\n",
            "Epoch 25/100\n",
            "194/194 [==============================] - 1s 3ms/step - loss: 0.4520 - accuracy: 0.7981 - categorical_crossentropy: 0.4520\n",
            "Epoch 26/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.4475 - accuracy: 0.7988 - categorical_crossentropy: 0.4475\n",
            "Epoch 27/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.4415 - accuracy: 0.7966 - categorical_crossentropy: 0.4415\n",
            "Epoch 28/100\n",
            "194/194 [==============================] - 1s 3ms/step - loss: 0.4418 - accuracy: 0.8031 - categorical_crossentropy: 0.4418\n",
            "Epoch 29/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.4475 - accuracy: 0.7948 - categorical_crossentropy: 0.4475\n",
            "Epoch 30/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.4434 - accuracy: 0.8020 - categorical_crossentropy: 0.4434\n",
            "Epoch 31/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.4335 - accuracy: 0.8048 - categorical_crossentropy: 0.4335\n",
            "Epoch 32/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.4346 - accuracy: 0.8081 - categorical_crossentropy: 0.4346\n",
            "Epoch 33/100\n",
            "194/194 [==============================] - 1s 3ms/step - loss: 0.4460 - accuracy: 0.7974 - categorical_crossentropy: 0.4460\n",
            "Epoch 34/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.4366 - accuracy: 0.8061 - categorical_crossentropy: 0.4366\n",
            "Epoch 35/100\n",
            "194/194 [==============================] - 1s 3ms/step - loss: 0.4393 - accuracy: 0.8018 - categorical_crossentropy: 0.4393\n",
            "Epoch 36/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.4460 - accuracy: 0.8032 - categorical_crossentropy: 0.4460\n",
            "Epoch 37/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.4376 - accuracy: 0.8092 - categorical_crossentropy: 0.4376\n",
            "Epoch 38/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.4325 - accuracy: 0.8097 - categorical_crossentropy: 0.4325\n",
            "Epoch 39/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.4475 - accuracy: 0.7977 - categorical_crossentropy: 0.4475\n",
            "Epoch 40/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.4395 - accuracy: 0.8018 - categorical_crossentropy: 0.4395\n",
            "Epoch 41/100\n",
            "194/194 [==============================] - 1s 3ms/step - loss: 0.4349 - accuracy: 0.8024 - categorical_crossentropy: 0.4349\n",
            "Epoch 42/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.4245 - accuracy: 0.8111 - categorical_crossentropy: 0.4245\n",
            "Epoch 43/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.4303 - accuracy: 0.8099 - categorical_crossentropy: 0.4303\n",
            "Epoch 44/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.4349 - accuracy: 0.8082 - categorical_crossentropy: 0.4349\n",
            "Epoch 45/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.4303 - accuracy: 0.8048 - categorical_crossentropy: 0.4303\n",
            "Epoch 46/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.4327 - accuracy: 0.8073 - categorical_crossentropy: 0.4327\n",
            "Epoch 47/100\n",
            "194/194 [==============================] - 1s 3ms/step - loss: 0.4347 - accuracy: 0.8050 - categorical_crossentropy: 0.4347\n",
            "Epoch 48/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.4277 - accuracy: 0.8044 - categorical_crossentropy: 0.4277\n",
            "Epoch 49/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.4274 - accuracy: 0.8104 - categorical_crossentropy: 0.4274\n",
            "Epoch 50/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.4269 - accuracy: 0.8080 - categorical_crossentropy: 0.4269\n",
            "Epoch 51/100\n",
            "194/194 [==============================] - 1s 3ms/step - loss: 0.4280 - accuracy: 0.8124 - categorical_crossentropy: 0.4280\n",
            "Epoch 52/100\n",
            "194/194 [==============================] - 1s 3ms/step - loss: 0.4227 - accuracy: 0.8080 - categorical_crossentropy: 0.4227\n",
            "Epoch 53/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.4281 - accuracy: 0.8040 - categorical_crossentropy: 0.4281\n",
            "Epoch 54/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.4136 - accuracy: 0.8216 - categorical_crossentropy: 0.4136\n",
            "Epoch 55/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.3904 - accuracy: 0.8417 - categorical_crossentropy: 0.3904\n",
            "Epoch 56/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.3895 - accuracy: 0.8470 - categorical_crossentropy: 0.3895\n",
            "Epoch 57/100\n",
            "194/194 [==============================] - 1s 3ms/step - loss: 0.3844 - accuracy: 0.8579 - categorical_crossentropy: 0.3844\n",
            "Epoch 58/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.3814 - accuracy: 0.8597 - categorical_crossentropy: 0.3814\n",
            "Epoch 59/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.3688 - accuracy: 0.8583 - categorical_crossentropy: 0.3688\n",
            "Epoch 60/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.3708 - accuracy: 0.8598 - categorical_crossentropy: 0.3708\n",
            "Epoch 61/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.3669 - accuracy: 0.8573 - categorical_crossentropy: 0.3669\n",
            "Epoch 62/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.3711 - accuracy: 0.8596 - categorical_crossentropy: 0.3711\n",
            "Epoch 63/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.3692 - accuracy: 0.8575 - categorical_crossentropy: 0.3692\n",
            "Epoch 64/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.3692 - accuracy: 0.8588 - categorical_crossentropy: 0.3692\n",
            "Epoch 65/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.3614 - accuracy: 0.8637 - categorical_crossentropy: 0.3614\n",
            "Epoch 66/100\n",
            "194/194 [==============================] - 1s 3ms/step - loss: 0.3632 - accuracy: 0.8641 - categorical_crossentropy: 0.3632\n",
            "Epoch 67/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.3710 - accuracy: 0.8581 - categorical_crossentropy: 0.3710\n",
            "Epoch 68/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.3733 - accuracy: 0.8596 - categorical_crossentropy: 0.3733\n",
            "Epoch 69/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.3726 - accuracy: 0.8600 - categorical_crossentropy: 0.3726\n",
            "Epoch 70/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.3764 - accuracy: 0.8580 - categorical_crossentropy: 0.3764\n",
            "Epoch 71/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.3740 - accuracy: 0.8600 - categorical_crossentropy: 0.3740\n",
            "Epoch 72/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.3643 - accuracy: 0.8604 - categorical_crossentropy: 0.3643\n",
            "Epoch 73/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.3671 - accuracy: 0.8588 - categorical_crossentropy: 0.3671\n",
            "Epoch 74/100\n",
            "194/194 [==============================] - 1s 3ms/step - loss: 0.3627 - accuracy: 0.8634 - categorical_crossentropy: 0.3627\n",
            "Epoch 75/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.3701 - accuracy: 0.8592 - categorical_crossentropy: 0.3701\n",
            "Epoch 76/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.3657 - accuracy: 0.8667 - categorical_crossentropy: 0.3657\n",
            "Epoch 77/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.3567 - accuracy: 0.8638 - categorical_crossentropy: 0.3567\n",
            "Epoch 78/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.3680 - accuracy: 0.8610 - categorical_crossentropy: 0.3680\n",
            "Epoch 79/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.3628 - accuracy: 0.8604 - categorical_crossentropy: 0.3628\n",
            "Epoch 80/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.3636 - accuracy: 0.8631 - categorical_crossentropy: 0.3636\n",
            "Epoch 81/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.3584 - accuracy: 0.8636 - categorical_crossentropy: 0.3584\n",
            "Epoch 82/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.3620 - accuracy: 0.8617 - categorical_crossentropy: 0.3620\n",
            "Epoch 83/100\n",
            "194/194 [==============================] - 1s 3ms/step - loss: 0.3651 - accuracy: 0.8645 - categorical_crossentropy: 0.3651\n",
            "Epoch 84/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.3609 - accuracy: 0.8646 - categorical_crossentropy: 0.3609\n",
            "Epoch 85/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.3659 - accuracy: 0.8617 - categorical_crossentropy: 0.3659\n",
            "Epoch 86/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.3716 - accuracy: 0.8583 - categorical_crossentropy: 0.3716\n",
            "Epoch 87/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.3756 - accuracy: 0.8560 - categorical_crossentropy: 0.3756\n",
            "Epoch 88/100\n",
            "194/194 [==============================] - 1s 3ms/step - loss: 0.3552 - accuracy: 0.8674 - categorical_crossentropy: 0.3552\n",
            "Epoch 89/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.3629 - accuracy: 0.8649 - categorical_crossentropy: 0.3629\n",
            "Epoch 90/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.3626 - accuracy: 0.8638 - categorical_crossentropy: 0.3626\n",
            "Epoch 91/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.3582 - accuracy: 0.8625 - categorical_crossentropy: 0.3582\n",
            "Epoch 92/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.3679 - accuracy: 0.8596 - categorical_crossentropy: 0.3679\n",
            "Epoch 93/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.3632 - accuracy: 0.8654 - categorical_crossentropy: 0.3632\n",
            "Epoch 94/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.3600 - accuracy: 0.8642 - categorical_crossentropy: 0.3600\n",
            "Epoch 95/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.3531 - accuracy: 0.8655 - categorical_crossentropy: 0.3531\n",
            "Epoch 96/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.3597 - accuracy: 0.8638 - categorical_crossentropy: 0.3597\n",
            "Epoch 97/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.3591 - accuracy: 0.8654 - categorical_crossentropy: 0.3591\n",
            "Epoch 98/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.3558 - accuracy: 0.8659 - categorical_crossentropy: 0.3558\n",
            "Epoch 99/100\n",
            "194/194 [==============================] - 1s 3ms/step - loss: 0.3546 - accuracy: 0.8643 - categorical_crossentropy: 0.3546\n",
            "Epoch 100/100\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 0.3476 - accuracy: 0.8637 - categorical_crossentropy: 0.3476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = define_model_3(lr=0.02)\n",
        "train_model(model, nom_bal_X, nom_bal_one_hot_Y, epochs=100, batch_size=64)"
      ],
      "metadata": {
        "id": "8YqTku_7rDw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1t73xrytD2bD",
        "outputId": "d6b27302-e311-4f0d-d158-3584c3fcde86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) Dense1_input with unsupported characters which will be renamed to dense1_input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpozlvffr0/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpozlvffr0/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model is 21844 bytes\n"
          ]
        }
      ],
      "source": [
        "save_model_lite(model, \"no_magneto_b64_003_90_small\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kE2O2ms-U9wE",
        "outputId": "52d03e8e-7918-4c1b-d802-9948790071db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) Dense1_input with unsupported characters which will be renamed to dense1_input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpxkc8aezj/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpxkc8aezj/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9ORJLlGEU9yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8De_94zXU92C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "_N-v0Wp8D2bD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53d496e1-eb27-48c8-bb1d-3eb721907ff4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting previously unselected package xxd.\n",
            "(Reading database ... 155335 files and directories currently installed.)\n",
            "Preparing to unpack .../xxd_2%3a8.0.1453-1ubuntu1.8_amd64.deb ...\n",
            "Unpacking xxd (2:8.0.1453-1ubuntu1.8) ...\n",
            "Setting up xxd (2:8.0.1453-1ubuntu1.8) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Header file, model.h, is 134,745 bytes.\n",
            "\n",
            "Open the side panel (refresh if needed). Double click model.h to download the file.\n"
          ]
        }
      ],
      "source": [
        "! apt-get -qq install xxd\n",
        "\n",
        "\n",
        "!echo \"const unsigned char model_data[] = {\" > /content/model_small.h\n",
        "!cat no_magneto_b64_005_93_small_all_data.tflite | xxd -i      >> /content/model_small.h\n",
        "!echo \"};\"                              >> /content/model_small.h\n",
        "\n",
        "import os\n",
        "model_h_size = os.path.getsize(\"model_small.h\")\n",
        "print(f\"Header file, model.h, is {model_h_size:,} bytes.\")\n",
        "print(\"\\nOpen the side panel (refresh if needed). Double click model.h to download the file.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "############## tflite check"
      ],
      "metadata": {
        "id": "iOFQDDUz74V8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask = np.random.rand(len(nom_bal_X)) <= 0.8\n",
        "training_X = nom_bal_X[mask].astype(np.float32)\n",
        "testing_X = nom_bal_X[~mask].astype(np.float32)\n",
        "training_Y = nom_bal_one_hot_Y[mask]\n",
        "testing_Y = nom_bal_one_hot_Y[~mask]"
      ],
      "metadata": {
        "id": "ATQNLTpI74ZT"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pxPO6AKq-Ec",
        "outputId": "e2277b73-29c4-4d9b-8d0d-6c8faf2f2bb7"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9888, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model = define_model_3(lr=0.01)\n",
        "train_model(test_model, training_X, training_Y, epochs=100, batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSIhS69n-1HF",
        "outputId": "e07751dd-033d-407f-9f59-bea930277bd7"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.7004 - accuracy: 0.7182 - categorical_crossentropy: 0.7004\n",
            "Epoch 2/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.4317 - accuracy: 0.8622 - categorical_crossentropy: 0.4317\n",
            "Epoch 3/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.4082 - accuracy: 0.8636 - categorical_crossentropy: 0.4082\n",
            "Epoch 4/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.4086 - accuracy: 0.8615 - categorical_crossentropy: 0.4086\n",
            "Epoch 5/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.4051 - accuracy: 0.8615 - categorical_crossentropy: 0.4051\n",
            "Epoch 6/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.4109 - accuracy: 0.8541 - categorical_crossentropy: 0.4109\n",
            "Epoch 7/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3891 - accuracy: 0.8664 - categorical_crossentropy: 0.3891\n",
            "Epoch 8/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.3872 - accuracy: 0.8675 - categorical_crossentropy: 0.3872\n",
            "Epoch 9/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3817 - accuracy: 0.8690 - categorical_crossentropy: 0.3817\n",
            "Epoch 10/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.3869 - accuracy: 0.8653 - categorical_crossentropy: 0.3869\n",
            "Epoch 11/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3854 - accuracy: 0.8677 - categorical_crossentropy: 0.3854\n",
            "Epoch 12/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3748 - accuracy: 0.8701 - categorical_crossentropy: 0.3748\n",
            "Epoch 13/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3783 - accuracy: 0.8683 - categorical_crossentropy: 0.3783\n",
            "Epoch 14/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3750 - accuracy: 0.8712 - categorical_crossentropy: 0.3750\n",
            "Epoch 15/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.3775 - accuracy: 0.8680 - categorical_crossentropy: 0.3775\n",
            "Epoch 16/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.3747 - accuracy: 0.8707 - categorical_crossentropy: 0.3747\n",
            "Epoch 17/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.3714 - accuracy: 0.8703 - categorical_crossentropy: 0.3714\n",
            "Epoch 18/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3778 - accuracy: 0.8680 - categorical_crossentropy: 0.3778\n",
            "Epoch 19/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.3651 - accuracy: 0.8748 - categorical_crossentropy: 0.3651\n",
            "Epoch 20/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3716 - accuracy: 0.8679 - categorical_crossentropy: 0.3716\n",
            "Epoch 21/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.3657 - accuracy: 0.8699 - categorical_crossentropy: 0.3657\n",
            "Epoch 22/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3610 - accuracy: 0.8711 - categorical_crossentropy: 0.3610\n",
            "Epoch 23/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3722 - accuracy: 0.8663 - categorical_crossentropy: 0.3722\n",
            "Epoch 24/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3519 - accuracy: 0.8780 - categorical_crossentropy: 0.3519\n",
            "Epoch 25/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3614 - accuracy: 0.8753 - categorical_crossentropy: 0.3614\n",
            "Epoch 26/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.3489 - accuracy: 0.8809 - categorical_crossentropy: 0.3489\n",
            "Epoch 27/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3564 - accuracy: 0.8738 - categorical_crossentropy: 0.3564\n",
            "Epoch 28/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.3529 - accuracy: 0.8800 - categorical_crossentropy: 0.3529\n",
            "Epoch 29/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3494 - accuracy: 0.8826 - categorical_crossentropy: 0.3494\n",
            "Epoch 30/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.3360 - accuracy: 0.8885 - categorical_crossentropy: 0.3360\n",
            "Epoch 31/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3331 - accuracy: 0.8951 - categorical_crossentropy: 0.3331\n",
            "Epoch 32/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.3045 - accuracy: 0.9042 - categorical_crossentropy: 0.3045\n",
            "Epoch 33/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.3155 - accuracy: 0.9021 - categorical_crossentropy: 0.3155\n",
            "Epoch 34/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3102 - accuracy: 0.9061 - categorical_crossentropy: 0.3102\n",
            "Epoch 35/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.3097 - accuracy: 0.9011 - categorical_crossentropy: 0.3097\n",
            "Epoch 36/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3078 - accuracy: 0.9021 - categorical_crossentropy: 0.3078\n",
            "Epoch 37/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.3059 - accuracy: 0.9059 - categorical_crossentropy: 0.3059\n",
            "Epoch 38/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3013 - accuracy: 0.9060 - categorical_crossentropy: 0.3013\n",
            "Epoch 39/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.3044 - accuracy: 0.9056 - categorical_crossentropy: 0.3044\n",
            "Epoch 40/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.3089 - accuracy: 0.9033 - categorical_crossentropy: 0.3089\n",
            "Epoch 41/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.3109 - accuracy: 0.9024 - categorical_crossentropy: 0.3109\n",
            "Epoch 42/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3114 - accuracy: 0.9018 - categorical_crossentropy: 0.3114\n",
            "Epoch 43/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3137 - accuracy: 0.9014 - categorical_crossentropy: 0.3137\n",
            "Epoch 44/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.2979 - accuracy: 0.9076 - categorical_crossentropy: 0.2979\n",
            "Epoch 45/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3082 - accuracy: 0.9035 - categorical_crossentropy: 0.3082\n",
            "Epoch 46/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.3112 - accuracy: 0.9026 - categorical_crossentropy: 0.3112\n",
            "Epoch 47/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3004 - accuracy: 0.9052 - categorical_crossentropy: 0.3004\n",
            "Epoch 48/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3080 - accuracy: 0.9030 - categorical_crossentropy: 0.3080\n",
            "Epoch 49/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3082 - accuracy: 0.9024 - categorical_crossentropy: 0.3082\n",
            "Epoch 50/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3042 - accuracy: 0.9033 - categorical_crossentropy: 0.3042\n",
            "Epoch 51/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3132 - accuracy: 0.9021 - categorical_crossentropy: 0.3132\n",
            "Epoch 52/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3109 - accuracy: 0.9016 - categorical_crossentropy: 0.3109\n",
            "Epoch 53/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.2994 - accuracy: 0.9060 - categorical_crossentropy: 0.2994\n",
            "Epoch 54/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3032 - accuracy: 0.9052 - categorical_crossentropy: 0.3032\n",
            "Epoch 55/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.2957 - accuracy: 0.9087 - categorical_crossentropy: 0.2957\n",
            "Epoch 56/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.3384 - accuracy: 0.8912 - categorical_crossentropy: 0.3384\n",
            "Epoch 57/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3517 - accuracy: 0.8794 - categorical_crossentropy: 0.3517\n",
            "Epoch 58/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3412 - accuracy: 0.8835 - categorical_crossentropy: 0.3412\n",
            "Epoch 59/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.3456 - accuracy: 0.8831 - categorical_crossentropy: 0.3456\n",
            "Epoch 60/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3515 - accuracy: 0.8822 - categorical_crossentropy: 0.3515\n",
            "Epoch 61/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3381 - accuracy: 0.8865 - categorical_crossentropy: 0.3381\n",
            "Epoch 62/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3405 - accuracy: 0.8872 - categorical_crossentropy: 0.3405\n",
            "Epoch 63/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.3395 - accuracy: 0.8824 - categorical_crossentropy: 0.3395\n",
            "Epoch 64/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3355 - accuracy: 0.8855 - categorical_crossentropy: 0.3355\n",
            "Epoch 65/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3500 - accuracy: 0.8812 - categorical_crossentropy: 0.3500\n",
            "Epoch 66/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3381 - accuracy: 0.8881 - categorical_crossentropy: 0.3381\n",
            "Epoch 67/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3442 - accuracy: 0.8838 - categorical_crossentropy: 0.3442\n",
            "Epoch 68/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.3453 - accuracy: 0.8829 - categorical_crossentropy: 0.3453\n",
            "Epoch 69/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.3384 - accuracy: 0.8862 - categorical_crossentropy: 0.3384\n",
            "Epoch 70/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3419 - accuracy: 0.8859 - categorical_crossentropy: 0.3419\n",
            "Epoch 71/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3320 - accuracy: 0.8895 - categorical_crossentropy: 0.3320\n",
            "Epoch 72/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.3409 - accuracy: 0.8863 - categorical_crossentropy: 0.3409\n",
            "Epoch 73/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3261 - accuracy: 0.8909 - categorical_crossentropy: 0.3261\n",
            "Epoch 74/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3421 - accuracy: 0.8873 - categorical_crossentropy: 0.3421\n",
            "Epoch 75/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.3428 - accuracy: 0.8823 - categorical_crossentropy: 0.3428\n",
            "Epoch 76/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3317 - accuracy: 0.8875 - categorical_crossentropy: 0.3317\n",
            "Epoch 77/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3341 - accuracy: 0.8870 - categorical_crossentropy: 0.3341\n",
            "Epoch 78/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.3343 - accuracy: 0.8856 - categorical_crossentropy: 0.3343\n",
            "Epoch 79/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.3328 - accuracy: 0.8875 - categorical_crossentropy: 0.3328\n",
            "Epoch 80/100\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 0.3441 - accuracy: 0.8828 - categorical_crossentropy: 0.3441\n",
            "Epoch 81/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.3366 - accuracy: 0.8874 - categorical_crossentropy: 0.3366\n",
            "Epoch 82/100\n",
            "155/155 [==============================] - 1s 7ms/step - loss: 0.3418 - accuracy: 0.8846 - categorical_crossentropy: 0.3418\n",
            "Epoch 83/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.3364 - accuracy: 0.8877 - categorical_crossentropy: 0.3364\n",
            "Epoch 84/100\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 0.3340 - accuracy: 0.8873 - categorical_crossentropy: 0.3340\n",
            "Epoch 85/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3301 - accuracy: 0.8895 - categorical_crossentropy: 0.3301\n",
            "Epoch 86/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3377 - accuracy: 0.8881 - categorical_crossentropy: 0.3377\n",
            "Epoch 87/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3281 - accuracy: 0.8906 - categorical_crossentropy: 0.3281\n",
            "Epoch 88/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3321 - accuracy: 0.8893 - categorical_crossentropy: 0.3321\n",
            "Epoch 89/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3313 - accuracy: 0.8881 - categorical_crossentropy: 0.3313\n",
            "Epoch 90/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3389 - accuracy: 0.8873 - categorical_crossentropy: 0.3389\n",
            "Epoch 91/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3395 - accuracy: 0.8862 - categorical_crossentropy: 0.3395\n",
            "Epoch 92/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.3343 - accuracy: 0.8866 - categorical_crossentropy: 0.3343\n",
            "Epoch 93/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3275 - accuracy: 0.8893 - categorical_crossentropy: 0.3275\n",
            "Epoch 94/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3287 - accuracy: 0.8888 - categorical_crossentropy: 0.3287\n",
            "Epoch 95/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3340 - accuracy: 0.8881 - categorical_crossentropy: 0.3340\n",
            "Epoch 96/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3286 - accuracy: 0.8906 - categorical_crossentropy: 0.3286\n",
            "Epoch 97/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3208 - accuracy: 0.8932 - categorical_crossentropy: 0.3208\n",
            "Epoch 98/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3190 - accuracy: 0.8938 - categorical_crossentropy: 0.3190\n",
            "Epoch 99/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3335 - accuracy: 0.8871 - categorical_crossentropy: 0.3335\n",
            "Epoch 100/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3207 - accuracy: 0.8956 - categorical_crossentropy: 0.3207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_model_lite(test_model, \"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRoBytULAjCp",
        "outputId": "2c007613-20e6-4f30-e370-ad4af6775170"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) Dense3_input with unsupported characters which will be renamed to dense3_input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpg67nwjbr/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpg67nwjbr/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model is 4748 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter = tf.lite.Interpreter(model_path=\"test.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "s = 0\n",
        "# Test model on random input data.\n",
        "input_shape = input_details[0]['shape']\n",
        "for idx in range(len(testing_X)):\n",
        "  inp = testing_X[idx].reshape((1,30))\n",
        "  #input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
        "  interpreter.set_tensor(input_details[0]['index'], inp)\n",
        "\n",
        "  interpreter.invoke()\n",
        "\n",
        "  # The function `get_tensor()` returns a copy of the tensor data.\n",
        "  # Use `tensor()` in order to get a pointer to the tensor.\n",
        "  output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "  ok = np.argmax(output_data[0]) == np.argmax(testing_Y[idx])\n",
        "  s+=ok\n",
        "  print(output_data[0])\n",
        "print(s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zi4n2Rc97SUF",
        "outputId": "4e2541a4-0108-486e-8ec2-63f47f9ebd03"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.45375878 0.54037255 0.00586866]\n",
            "[0.3392856  0.65692526 0.00378912]\n",
            "[0.03778636 0.0561224  0.9060912 ]\n",
            "[0.421932   0.57282263 0.00524531]\n",
            "[0.21278031 0.06947193 0.71774775]\n",
            "[0.42915034 0.5654662  0.00538342]\n",
            "[0.37684777 0.61872876 0.00442349]\n",
            "[0.4035195  0.5915791  0.00490136]\n",
            "[0.01404926 0.05115787 0.9347929 ]\n",
            "[0.5983222  0.35936004 0.04231774]\n",
            "[0.8528423  0.05919959 0.08795808]\n",
            "[0.47911385 0.51289314 0.00799308]\n",
            "[0.75896984 0.21020515 0.03082506]\n",
            "[0.46026108 0.5337382  0.00600073]\n",
            "[0.44282535 0.5515244  0.00565027]\n",
            "[0.44292992 0.55141777 0.00565234]\n",
            "[0.7048969  0.28243554 0.0126676 ]\n",
            "[0.4606302  0.53336155 0.00600828]\n",
            "[0.6884154  0.2995171  0.01206746]\n",
            "[0.5030026  0.48378524 0.01321224]\n",
            "[0.46805805 0.5257807  0.0061613 ]\n",
            "[0.67032075 0.17376608 0.15591316]\n",
            "[0.46783984 0.52600336 0.00615678]\n",
            "[0.4144094  0.5804873  0.00510336]\n",
            "[0.6741682  0.10707662 0.21875516]\n",
            "[0.51241726 0.4804593  0.0071235 ]\n",
            "[0.61132914 0.37864676 0.01002418]\n",
            "[0.44586545 0.548424   0.00571054]\n",
            "[0.6364677  0.0572711  0.30626118]\n",
            "[0.4950377  0.498226   0.00673629]\n",
            "[0.40384346 0.59124917 0.00490731]\n",
            "[0.4028807  0.5922296  0.00488964]\n",
            "[0.87472713 0.05051064 0.07476218]\n",
            "[0.5647894  0.16740415 0.26780647]\n",
            "[0.5338211  0.45855907 0.00761991]\n",
            "[0.46491802 0.5289857  0.00609635]\n",
            "[0.55025405 0.43733925 0.01240674]\n",
            "[0.02565067 0.05093587 0.92341346]\n",
            "[0.55966043 0.4320892  0.00825041]\n",
            "[0.3975125  0.5976959  0.00479167]\n",
            "[0.6380432  0.32344702 0.03850976]\n",
            "[0.42385718 0.5708608  0.00528196]\n",
            "[0.02012771 0.05367551 0.9261967 ]\n",
            "[0.4378174  0.5566309  0.00555174]\n",
            "[0.5244802  0.4681193  0.00740052]\n",
            "[0.54979205 0.44220263 0.00800538]\n",
            "[0.90264136 0.09211011 0.00524857]\n",
            "[0.5165141  0.47444394 0.00904199]\n",
            "[0.45757937 0.5364746  0.00594606]\n",
            "[0.6270649  0.10819773 0.2647374 ]\n",
            "[0.43536136 0.5591349  0.00550377]\n",
            "[0.3909781  0.6043481  0.00467372]\n",
            "[0.49250048 0.48936495 0.01813462]\n",
            "[0.48329264 0.50933236 0.00737508]\n",
            "[0.4044563  0.5906251  0.00491858]\n",
            "[0.58543026 0.40299287 0.01157692]\n",
            "[0.41678715 0.57806486 0.00514801]\n",
            "[0.5058337  0.48419178 0.00997451]\n",
            "[0.40319428 0.59191024 0.00489539]\n",
            "[0.03843739 0.04971283 0.91184974]\n",
            "[0.7509825  0.23446569 0.01455176]\n",
            "[0.45490023 0.53920805 0.00589173]\n",
            "[0.49520767 0.4976785  0.0071139 ]\n",
            "[0.4526919  0.54146093 0.00584715]\n",
            "[0.36784735 0.6278852  0.00426746]\n",
            "[0.04228273 0.04684458 0.91087276]\n",
            "[0.38558117 0.6098414  0.00457738]\n",
            "[9.1612607e-01 8.3681747e-02 1.9217213e-04]\n",
            "[0.37679198 0.6187855  0.00442252]\n",
            "[9.779472e-01 2.195296e-02 9.978726e-05]\n",
            "[0.3814129  0.6140835  0.00450362]\n",
            "[0.5373837  0.45491156 0.00770474]\n",
            "[0.33480418 0.66147953 0.00371633]\n",
            "[0.4356965 0.5587932 0.0055103]\n",
            "[0.43613437 0.55834675 0.00551884]\n",
            "[0.00998865 0.04360116 0.9464103 ]\n",
            "[0.9608838  0.03758442 0.00153169]\n",
            "[8.4086835e-01 1.5885285e-01 2.7872316e-04]\n",
            "[0.44888237 0.545347   0.00577069]\n",
            "[0.48398674 0.50618196 0.00983135]\n",
            "[0.76650006 0.11050515 0.12299483]\n",
            "[0.63349605 0.05796727 0.3085367 ]\n",
            "[0.8769724  0.09081685 0.03221082]\n",
            "[9.4043458e-01 5.8729392e-02 8.3594205e-04]\n",
            "[0.44552907 0.54876715 0.00570385]\n",
            "[0.44389802 0.5504305  0.00567149]\n",
            "[0.36729077 0.6284513  0.0042579 ]\n",
            "[0.94078416 0.05174553 0.00747031]\n",
            "[0.02893675 0.05610755 0.91495574]\n",
            "[0.449842  0.544368  0.0057899]\n",
            "[0.65259314 0.0564177  0.29098922]\n",
            "[0.45983088 0.53417724 0.00599194]\n",
            "[0.90208274 0.09688789 0.00102935]\n",
            "[0.5288832  0.46361342 0.00750339]\n",
            "[0.47393662 0.06754278 0.45852062]\n",
            "[0.834083   0.11983306 0.04608394]\n",
            "[0.3702459  0.6254453  0.00430879]\n",
            "[0.38626826 0.6091422  0.0045896 ]\n",
            "[0.5689541  0.42255974 0.00848619]\n",
            "[0.6065653  0.3772188  0.01621584]\n",
            "[0.6886785  0.29924473 0.01207678]\n",
            "[0.43836555 0.55607206 0.00556248]\n",
            "[0.6256294  0.3085768  0.06579374]\n",
            "[0.34711942 0.64896274 0.00391782]\n",
            "[0.3349571  0.6613241  0.00371881]\n",
            "[0.4812843  0.5122764  0.00643935]\n",
            "[0.96233845 0.03633814 0.00132338]\n",
            "[0.01472925 0.05748101 0.9277898 ]\n",
            "[0.8164229  0.04939479 0.1341823 ]\n",
            "[0.5930249  0.39785403 0.00912102]\n",
            "[0.4583969  0.53564036 0.0059627 ]\n",
            "[0.45956582 0.53444767 0.00598653]\n",
            "[0.0356568  0.04740098 0.9169422 ]\n",
            "[0.28330132 0.71377665 0.00292205]\n",
            "[0.40995175 0.5850281  0.00502018]\n",
            "[0.44110712 0.5532765  0.00561636]\n",
            "[0.01626961 0.05457428 0.9291562 ]\n",
            "[0.92566186 0.03255234 0.04178582]\n",
            "[0.4157273  0.5791446  0.00512808]\n",
            "[0.37394622 0.6216809  0.00437291]\n",
            "[9.0856391e-01 9.1231301e-02 2.0481851e-04]\n",
            "[0.6764568  0.31189135 0.01165193]\n",
            "[0.96695143 0.02985539 0.00319325]\n",
            "[0.01377856 0.04654908 0.9396724 ]\n",
            "[0.45641252 0.537665   0.00592237]\n",
            "[0.46420503 0.52971333 0.00608165]\n",
            "[0.5939966  0.39685598 0.00914742]\n",
            "[0.4812826  0.51227814 0.00643931]\n",
            "[0.5748784  0.4164825  0.00863913]\n",
            "[0.6221954  0.27301535 0.10478922]\n",
            "[0.5392307  0.4530203  0.00774899]\n",
            "[0.01832621 0.05141317 0.93026066]\n",
            "[0.47844982 0.5151711  0.00637915]\n",
            "[0.4635997  0.5303311  0.00606919]\n",
            "[0.51634544 0.47569954 0.0079551 ]\n",
            "[0.6696694  0.3189077  0.01142294]\n",
            "[0.39887387 0.5963097  0.00481642]\n",
            "[0.5065644  0.48448458 0.00895098]\n",
            "[0.44044    0.55395675 0.00560322]\n",
            "[0.4461477  0.5481362  0.00571615]\n",
            "[0.03323634 0.04885514 0.9179085 ]\n",
            "[0.81177723 0.09690425 0.09131856]\n",
            "[0.39338547 0.6018976  0.00471701]\n",
            "[0.67614555 0.05747736 0.26637703]\n",
            "[0.79642797 0.18674599 0.016826  ]\n",
            "[0.47799724 0.5133764  0.0086263 ]\n",
            "[0.3741366  0.6214872  0.00437622]\n",
            "[0.05157869 0.04838704 0.90003425]\n",
            "[0.48296404 0.51056075 0.00647517]\n",
            "[0.57717   0.4048577 0.0179723]\n",
            "[0.83429945 0.04829925 0.11740136]\n",
            "[0.40444157 0.5906401  0.0049183 ]\n",
            "[0.95989096 0.03816578 0.00194327]\n",
            "[0.03857904 0.04999955 0.91142136]\n",
            "[0.7945898  0.09045018 0.11495996]\n",
            "[0.37563536 0.6199623  0.00440232]\n",
            "[0.8835656  0.06350976 0.05292465]\n",
            "[0.46543917 0.5284537  0.0061071 ]\n",
            "[9.7775078e-01 2.2157129e-02 9.2042857e-05]\n",
            "[0.38844264 0.60692906 0.00462834]\n",
            "[0.4900631  0.503309   0.00662794]\n",
            "[0.48042858 0.51315033 0.00642114]\n",
            "[0.52288574 0.46650636 0.01060784]\n",
            "[0.48745465 0.5059738  0.00657156]\n",
            "[9.8527335e-02 9.0090662e-01 5.6603347e-04]\n",
            "[0.4760641  0.5176071  0.00632874]\n",
            "[0.46800175 0.5258382  0.00616014]\n",
            "[0.5183412  0.47440013 0.00725866]\n",
            "[0.51942945 0.47328687 0.00728368]\n",
            "[9.363107e-01 6.303838e-02 6.509693e-04]\n",
            "[0.4700161  0.52378196 0.00620201]\n",
            "[0.8165557  0.1358713  0.04757302]\n",
            "[0.4150061  0.57987934 0.00511455]\n",
            "[0.8585414  0.08486581 0.05659282]\n",
            "[0.6216725  0.3684008  0.00992673]\n",
            "[9.4784957e-01 5.1881209e-02 2.6928683e-04]\n",
            "[0.55438465 0.43732074 0.00829463]\n",
            "[0.4296385  0.5649687  0.00539283]\n",
            "[8.90438080e-01 1.08812846e-01 7.49076658e-04]\n",
            "[0.7492718  0.18990527 0.06082293]\n",
            "[0.4366103  0.55786157 0.00552813]\n",
            "[0.46199924 0.5319644  0.00603632]\n",
            "[0.44213828 0.55222505 0.0056367 ]\n",
            "[0.44565225 0.5486415  0.0057063 ]\n",
            "[0.55572027 0.43103305 0.01324667]\n",
            "[0.3885475  0.60682225 0.00463022]\n",
            "[0.8594004  0.10222532 0.03837431]\n",
            "[0.46910766 0.5247092  0.00618311]\n",
            "[0.45941737 0.5345991  0.0059835 ]\n",
            "[0.3972331  0.59798026 0.0047866 ]\n",
            "[0.59463435 0.39620087 0.00916478]\n",
            "[0.46446472 0.5294482  0.006087  ]\n",
            "[0.40073076 0.59441894 0.00485028]\n",
            "[0.40746847 0.58755744 0.00497414]\n",
            "[0.49842042 0.49456832 0.00701129]\n",
            "[0.8338574  0.09713029 0.06901232]\n",
            "[0.4379598  0.5564857  0.00555453]\n",
            "[0.62394255 0.31523007 0.06082736]\n",
            "[0.46444252 0.529471   0.00608655]\n",
            "[0.40408903 0.59099907 0.00491183]\n",
            "[0.46834219 0.5254906  0.00616721]\n",
            "[0.4249197  0.5697781  0.00530225]\n",
            "[0.4639588  0.52996457 0.00607658]\n",
            "[0.8234029  0.05465436 0.12194278]\n",
            "[9.2730951e-01 7.2184436e-02 5.0609990e-04]\n",
            "[0.07377157 0.04592801 0.8803004 ]\n",
            "[0.50504553 0.48157609 0.01337844]\n",
            "[0.42362222 0.5711003  0.00527749]\n",
            "[0.01589497 0.04355902 0.94054604]\n",
            "[0.4597689  0.5342404  0.00599068]\n",
            "[0.58644676 0.40460932 0.00894393]\n",
            "[0.01291948 0.05193755 0.93514293]\n",
            "[0.4107967  0.5841674  0.00503589]\n",
            "[0.03287746 0.0509189  0.9162036 ]\n",
            "[0.59479344 0.39430648 0.01090008]\n",
            "[0.61282945 0.37672323 0.01044731]\n",
            "[0.8806625  0.10825918 0.01107836]\n",
            "[0.4678939  0.52594817 0.0061579 ]\n",
            "[0.39874908 0.59643674 0.00481415]\n",
            "[0.2249692  0.77298963 0.00204115]\n",
            "[0.7131095  0.25112447 0.03576605]\n",
            "[0.8890891  0.06624976 0.04466122]\n",
            "[0.5984416  0.39117044 0.01038793]\n",
            "[0.45243347 0.5417246  0.00584195]\n",
            "[0.3936586  0.6016195  0.00472194]\n",
            "[0.45979774 0.534211   0.00599127]\n",
            "[0.84004813 0.07337602 0.08657589]\n",
            "[0.03042743 0.04962651 0.919946  ]\n",
            "[0.32500803 0.6714326  0.0035593 ]\n",
            "[0.44396502 0.55036217 0.00567282]\n",
            "[0.21124555 0.78690875 0.00184569]\n",
            "[0.47972408 0.51381606 0.00645984]\n",
            "[0.44057387 0.55382025 0.00560586]\n",
            "[0.534082   0.45829195 0.0076261 ]\n",
            "[0.29465503 0.7022544  0.00309058]\n",
            "[0.10983997 0.05519839 0.8349617 ]\n",
            "[0.40936685 0.5856238  0.00500932]\n",
            "[0.39870778 0.59647876 0.0048134 ]\n",
            "[0.32314917 0.673321   0.00352982]\n",
            "[0.4386492  0.5557828  0.00556804]\n",
            "[0.8599343  0.05041146 0.08965421]\n",
            "[0.44171923 0.5526523  0.00562843]\n",
            "[0.74951494 0.04697986 0.20350523]\n",
            "[0.37357593 0.62205756 0.00436647]\n",
            "[0.45227277 0.54188854 0.00583871]\n",
            "[0.7061509  0.05180321 0.24204591]\n",
            "[0.47867832 0.51493764 0.00638399]\n",
            "[0.412267  0.5826697 0.0050633]\n",
            "[0.4781353  0.5154922  0.00637249]\n",
            "[0.8552149  0.10535519 0.03942993]\n",
            "[0.6556524  0.33077255 0.01357502]\n",
            "[0.6935358  0.29386872 0.01259555]\n",
            "[0.36706764 0.6286783  0.00425407]\n",
            "[0.42097571 0.57379717 0.00522716]\n",
            "[0.46226045 0.39073431 0.14700525]\n",
            "[0.4165522  0.07006457 0.5133832 ]\n",
            "[0.5472039  0.44485417 0.007942  ]\n",
            "[0.3694482  0.62625676 0.00429503]\n",
            "[0.4217107  0.5730482  0.00524111]\n",
            "[0.4261357  0.56853884 0.00532551]\n",
            "[0.33829913 0.6579278  0.00377305]\n",
            "[0.45839062 0.53564686 0.00596257]\n",
            "[0.0580438  0.04679123 0.8951651 ]\n",
            "[0.43267325 0.06936859 0.49795815]\n",
            "[0.5461949  0.44588774 0.00791739]\n",
            "[0.29272294 0.70421547 0.00306164]\n",
            "[0.50137985 0.4917441  0.006876  ]\n",
            "[0.3389019  0.6573152  0.00378287]\n",
            "[0.33434364 0.6619475  0.00370888]\n",
            "[0.4153501 0.5795289 0.005121 ]\n",
            "[0.01401987 0.04663932 0.9393408 ]\n",
            "[0.46870652 0.5251187  0.00617477]\n",
            "[0.65523887 0.2995325  0.0452286 ]\n",
            "[0.42063835 0.57414097 0.00522076]\n",
            "[0.5518112  0.44013372 0.00805508]\n",
            "[0.3320553  0.66427267 0.00367198]\n",
            "[0.32583648 0.67059106 0.00357247]\n",
            "[0.7591363 0.2259399 0.0149238]\n",
            "[0.38963392 0.6057164  0.00464964]\n",
            "[0.45855963 0.5354743  0.00596602]\n",
            "[0.5291457  0.4629436  0.00791069]\n",
            "[0.4510693  0.5431162  0.00581452]\n",
            "[0.37865075 0.6168941  0.00445506]\n",
            "[0.51207435 0.48081    0.00711572]\n",
            "[0.38289237 0.61257786 0.00452974]\n",
            "[0.02064835 0.05614112 0.9232105 ]\n",
            "[0.38594422 0.609472   0.00458383]\n",
            "[0.4757819  0.51789534 0.0063228 ]\n",
            "[0.5298439  0.46263003 0.00752597]\n",
            "[0.37472966 0.62088376 0.00438654]\n",
            "[0.40201575 0.59311044 0.00487378]\n",
            "[0.01500866 0.0553129  0.9296785 ]\n",
            "[0.40020704 0.5949522  0.00484072]\n",
            "[0.4511945  0.5429885  0.00581703]\n",
            "[0.7113883  0.26247913 0.02613257]\n",
            "[0.4199427  0.5748497  0.00520758]\n",
            "[0.55528635 0.4358427  0.00887087]\n",
            "[0.04076229 0.04952402 0.9097137 ]\n",
            "[0.46232694 0.53163004 0.00604304]\n",
            "[0.58679396 0.40425286 0.0089532 ]\n",
            "[0.14309677 0.06043469 0.7964685 ]\n",
            "[0.47816744 0.5154594  0.00637317]\n",
            "[0.40212137 0.593003   0.00487572]\n",
            "[0.3895598  0.60579187 0.00464831]\n",
            "[0.8395049  0.05716529 0.1033299 ]\n",
            "[0.332818   0.6634977  0.00368426]\n",
            "[0.456377   0.5377013  0.00592164]\n",
            "[9.7339523e-01 2.6539158e-02 6.5638844e-05]\n",
            "[0.52665675 0.45900375 0.01433945]\n",
            "[0.45819187 0.53584963 0.00595852]\n",
            "[0.7384133  0.13412409 0.12746269]\n",
            "[0.45963925 0.53437275 0.00598803]\n",
            "[0.37415352 0.07062772 0.55521876]\n",
            "[0.52826685 0.45914838 0.01258477]\n",
            "[0.52657926 0.46517852 0.00824226]\n",
            "[0.5859285 0.4051414 0.0089301]\n",
            "[0.41073924 0.58422595 0.00503482]\n",
            "[0.88599604 0.06569295 0.048311  ]\n",
            "[0.08281904 0.05301856 0.86416245]\n",
            "[0.8459618  0.1338305  0.02020768]\n",
            "[0.4529831  0.54116386 0.00585302]\n",
            "[0.37746668 0.61809903 0.00443432]\n",
            "[0.3230335  0.67343843 0.00352799]\n",
            "[0.4950113  0.49782205 0.00716666]\n",
            "[0.48327786 0.51024026 0.00648188]\n",
            "[0.46084392 0.5324984  0.00665771]\n",
            "[0.23850924 0.06812119 0.6933696 ]\n",
            "[0.39928746 0.59588856 0.00482395]\n",
            "[0.5010687  0.48624432 0.0126869 ]\n",
            "[0.710239   0.0514438  0.23831715]\n",
            "[0.51063555 0.48228118 0.00708316]\n",
            "[0.20869759 0.78949213 0.00181035]\n",
            "[0.52883476 0.46175686 0.00940835]\n",
            "[0.49739638 0.49404636 0.00855724]\n",
            "[0.42816597 0.5664695  0.00536447]\n",
            "[0.681749   0.30641717 0.01183386]\n",
            "[0.44057593 0.5538182  0.0056059 ]\n",
            "[0.23548318 0.76232004 0.00219681]\n",
            "[0.5329382  0.45946288 0.00759899]\n",
            "[8.3083677e-01 1.6888787e-01 2.7542372e-04]\n",
            "[0.40235516 0.5927648  0.00488   ]\n",
            "[0.36746752 0.6282716  0.00426094]\n",
            "[0.3676711  0.6280644  0.00426444]\n",
            "[0.03009736 0.05575348 0.9141491 ]\n",
            "[0.9360369  0.03250148 0.03146169]\n",
            "[0.43852934 0.555905   0.00556569]\n",
            "[0.4799831  0.51360524 0.00641167]\n",
            "[0.02721288 0.05533852 0.91744864]\n",
            "[0.96829176 0.0267093  0.00499894]\n",
            "[0.661866   0.0546816  0.28345242]\n",
            "[0.7230796  0.05652382 0.22039656]\n",
            "[0.10605861 0.05948141 0.83446   ]\n",
            "[0.96604216 0.03055813 0.00339968]\n",
            "[0.94368047 0.04881555 0.00750406]\n",
            "[0.4435021  0.55083424 0.00566366]\n",
            "[0.88535094 0.07056273 0.04408631]\n",
            "[0.58747834 0.40355015 0.00897151]\n",
            "[0.47115567 0.52261865 0.00622578]\n",
            "[0.43070742 0.5638791  0.00541346]\n",
            "[0.9345668  0.06346126 0.00197194]\n",
            "[0.0168986  0.0507341  0.93236727]\n",
            "[0.93144315 0.06416178 0.00439501]\n",
            "[0.40217143 0.5929519  0.00487664]\n",
            "[0.494928   0.49833804 0.00673388]\n",
            "[0.3836797  0.61177665 0.00454367]\n",
            "[0.45534942 0.5387498  0.00590082]\n",
            "[1.0608715e-01 8.9327949e-01 6.3337677e-04]\n",
            "[0.5842146  0.40690097 0.00888447]\n",
            "[0.5353363  0.45211542 0.01254826]\n",
            "[0.05037224 0.04823571 0.9013921 ]\n",
            "[0.40410584 0.590982   0.00491213]\n",
            "[0.4774448  0.5026306  0.01992456]\n",
            "[0.49083963 0.5025156  0.00664478]\n",
            "[0.4584602  0.5355758  0.00596399]\n",
            "[0.02175598 0.04881935 0.9294246 ]\n",
            "[0.5947446  0.06013213 0.3451232 ]\n",
            "[0.10269283 0.05151175 0.84579545]\n",
            "[0.47110137 0.52267396 0.00622465]\n",
            "[9.5706058e-01 4.2834125e-02 1.0531059e-04]\n",
            "[0.9696835  0.02866948 0.00164702]\n",
            "[0.4218194  0.5729375  0.00524317]\n",
            "[0.8979786  0.09986313 0.00215832]\n",
            "[0.884448   0.06985175 0.04570028]\n",
            "[0.39144406 0.6038739  0.00468209]\n",
            "[0.85691226 0.12113049 0.0219572 ]\n",
            "[0.4785244  0.5150948  0.00638073]\n",
            "[0.398487   0.59670365 0.00480938]\n",
            "[0.5467387  0.06389537 0.389366  ]\n",
            "[0.7347158  0.24045625 0.02482801]\n",
            "[0.60681957 0.3754905  0.01768997]\n",
            "[0.5117538  0.4806633  0.00758287]\n",
            "[0.4467719  0.54749954 0.00572858]\n",
            "[0.42648906 0.56817865 0.00533228]\n",
            "[0.45522112 0.5388807  0.00589822]\n",
            "[0.4006614  0.59448963 0.00484902]\n",
            "[0.87751883 0.04493982 0.0775414 ]\n",
            "[0.36621076 0.62954986 0.00423937]\n",
            "[0.32058442 0.67592627 0.00348932]\n",
            "[0.43071932 0.563867   0.00541368]\n",
            "[0.4934624  0.49983567 0.00670185]\n",
            "[0.38947216 0.6058811  0.00464675]\n",
            "[0.5931636  0.39771163 0.00912479]\n",
            "[0.4411843  0.55319774 0.00561788]\n",
            "[0.5931737  0.39770123 0.00912506]\n",
            "[0.63339454 0.3563315  0.01027393]\n",
            "[0.36717346 0.62857074 0.00425589]\n",
            "[0.46712467 0.52673334 0.00614196]\n",
            "[0.47460744 0.5190945  0.00629808]\n",
            "[0.868348   0.09369329 0.03795871]\n",
            "[0.57530475 0.40247244 0.02222281]\n",
            "[0.54437095 0.43919393 0.0164351 ]\n",
            "[9.301929e-01 6.939219e-02 4.149506e-04]\n",
            "[9.6312648e-01 3.6532160e-02 3.4131602e-04]\n",
            "[0.40637895 0.58866704 0.004954  ]\n",
            "[0.44502246 0.54928374 0.00569379]\n",
            "[0.07655006 0.04891172 0.8745383 ]\n",
            "[0.58072466 0.41048318 0.00879213]\n",
            "[0.86841065 0.10639959 0.02518976]\n",
            "[0.39394557 0.60132736 0.00472711]\n",
            "[0.47029683 0.5234953  0.00620786]\n",
            "[0.44656962 0.5477058  0.00572455]\n",
            "[0.43904775 0.55537635 0.00557586]\n",
            "[0.42426082 0.5704495  0.00528966]\n",
            "[0.40701637 0.5880178  0.00496578]\n",
            "[0.87695897 0.0501315  0.07290956]\n",
            "[8.9619929e-01 1.0354486e-01 2.5584665e-04]\n",
            "[0.6132562  0.37705985 0.00968394]\n",
            "[0.500592   0.49171162 0.00769637]\n",
            "[0.625785   0.36416763 0.01004731]\n",
            "[0.42199755 0.5727559  0.00524656]\n",
            "[0.3709885  0.6246899  0.00432162]\n",
            "[0.4455042  0.5487924  0.00570336]\n",
            "[0.43329918 0.5612372  0.00546365]\n",
            "[0.4927387  0.4873547  0.01990666]\n",
            "[0.41940254 0.5754001  0.00519736]\n",
            "[0.40742067 0.5876062  0.00497325]\n",
            "[0.57720876 0.4140914  0.00869986]\n",
            "[0.40781316 0.5872063  0.00498052]\n",
            "[0.8316338  0.14577022 0.02259597]\n",
            "[8.999178e-01 9.957021e-02 5.120063e-04]\n",
            "[0.39117077 0.604152   0.00467718]\n",
            "[0.27223578 0.72500294 0.00276129]\n",
            "[0.663728   0.32504565 0.01122636]\n",
            "[0.5972173  0.06092349 0.34185916]\n",
            "[0.4273267  0.567325   0.00534835]\n",
            "[0.6017447  0.38274306 0.01551221]\n",
            "[0.38698727 0.6084103  0.00460239]\n",
            "[0.46791965 0.525922   0.00615843]\n",
            "[0.2629075  0.7344651  0.00262738]\n",
            "[0.3680284  0.62770104 0.00427058]\n",
            "[0.59436697 0.39098793 0.01464512]\n",
            "[0.61817294 0.0597099  0.3221172 ]\n",
            "[0.03152077 0.05464603 0.91383314]\n",
            "[0.353467   0.6425095  0.00402348]\n",
            "[0.09783157 0.04921588 0.85295254]\n",
            "[0.4162176  0.57864505 0.0051373 ]\n",
            "[0.7839296  0.12105782 0.09501263]\n",
            "[0.6282795  0.05845619 0.3132643 ]\n",
            "[0.3884365  0.60693526 0.00462824]\n",
            "[0.50697523 0.06533159 0.42769316]\n",
            "[0.3737411  0.07005456 0.55620426]\n",
            "[0.43380156 0.56072503 0.00547341]\n",
            "[0.45296884 0.5411784  0.00585273]\n",
            "[0.4680728  0.52576566 0.00616161]\n",
            "[0.02062283 0.04994274 0.9294345 ]\n",
            "[0.7447859  0.04740917 0.20780493]\n",
            "[0.6977012  0.28989738 0.01240146]\n",
            "[0.33116096 0.6651814  0.0036576 ]\n",
            "[0.4211561  0.5736133  0.00523058]\n",
            "[9.6352482e-01 3.6175087e-02 3.0008110e-04]\n",
            "[0.5371726 0.4551277 0.0076997]\n",
            "[0.45331973 0.5408204  0.0058598 ]\n",
            "[0.9007396  0.09784514 0.00141526]\n",
            "[0.4675072  0.5263429  0.00614988]\n",
            "[8.8428241e-01 1.1552577e-01 1.9184618e-04]\n",
            "[0.44670647 0.5475662  0.00572727]\n",
            "[0.41965854 0.5751393  0.0052022 ]\n",
            "[0.58327097 0.40786964 0.00885942]\n",
            "[0.5825231  0.40863723 0.00883961]\n",
            "[0.44370243 0.55063    0.00566762]\n",
            "[0.45561707 0.5384767  0.00590624]\n",
            "[0.46256235 0.5313031  0.00613446]\n",
            "[0.40304315 0.5920642  0.00489262]\n",
            "[0.36940977 0.62629586 0.00429437]\n",
            "[0.4032655  0.59183776 0.00489669]\n",
            "[0.45783964 0.536209   0.00595136]\n",
            "[0.37872562 0.616818   0.00445638]\n",
            "[0.38476866 0.61066836 0.00456296]\n",
            "[0.45451063 0.5396055  0.00588385]\n",
            "[0.41456077 0.58033305 0.0051062 ]\n",
            "[0.45218828 0.54197466 0.00583701]\n",
            "[0.38810813 0.60726947 0.00462237]\n",
            "[0.4637005  0.53022826 0.00607127]\n",
            "[0.40167558 0.59345686 0.00486756]\n",
            "[0.39542007 0.5998262  0.00475375]\n",
            "[0.43150738 0.5630637  0.00542892]\n",
            "[0.87904763 0.10887629 0.01207606]\n",
            "[0.3463947  0.6496995  0.00390584]\n",
            "[0.01213275 0.05265487 0.9352124 ]\n",
            "[0.5396001  0.45264205 0.00775786]\n",
            "[0.4115425  0.5834077  0.00504978]\n",
            "[0.48341802 0.50895137 0.00763053]\n",
            "[0.4762596  0.5174076  0.00633286]\n",
            "[0.2987354  0.6981126  0.00315205]\n",
            "[0.6138867  0.07534872 0.31076455]\n",
            "[0.5632195  0.42502406 0.01175646]\n",
            "[0.56986755 0.42162284 0.00850963]\n",
            "[0.90502256 0.060629   0.03434844]\n",
            "[0.6485915  0.33142984 0.01997865]\n",
            "[0.4481908  0.54605234 0.00575687]\n",
            "[0.3743904  0.62122893 0.00438063]\n",
            "[0.39632064 0.5989093  0.00477005]\n",
            "[0.404925   0.59014785 0.0049272 ]\n",
            "[0.60315776 0.38698038 0.0098619 ]\n",
            "[0.87458724 0.04541054 0.08000226]\n",
            "[0.45699155 0.5370743  0.00593412]\n",
            "[0.41400787 0.5808963  0.00509584]\n",
            "[0.36845624 0.6272659  0.00427794]\n",
            "[0.03549552 0.0520045  0.9125    ]\n",
            "[0.09302785 0.05602496 0.8509472 ]\n",
            "[0.5681341  0.42340073 0.00846519]\n",
            "[0.3697782  0.6259211  0.00430072]\n",
            "[0.43676    0.5577089  0.00553106]\n",
            "[0.91978395 0.07908177 0.00113429]\n",
            "[0.6297586  0.05881095 0.31143045]\n",
            "[0.8225853  0.1327627  0.04465201]\n",
            "[0.6104522  0.37814558 0.0114022 ]\n",
            "[0.32456782 0.6718798  0.00355231]\n",
            "[0.48256463 0.5098458  0.00758957]\n",
            "[0.41936332 0.57544    0.00519662]\n",
            "[0.6807294  0.30747193 0.01179858]\n",
            "[0.4564446  0.5376324  0.00592302]\n",
            "[0.4415599  0.5528148  0.00562528]\n",
            "[0.50222844 0.4908767  0.00689483]\n",
            "[0.5391179  0.44463417 0.01624794]\n",
            "[0.38512865 0.61030203 0.00456935]\n",
            "[0.65192664 0.3339835  0.01408983]\n",
            "[0.7224772  0.24802966 0.02949318]\n",
            "[0.4307325  0.5638536  0.00541394]\n",
            "[0.43492252 0.55958235 0.00549521]\n",
            "[0.51803523 0.46878695 0.01317774]\n",
            "[0.55085504 0.44111347 0.00803152]\n",
            "[0.43761846 0.5568337  0.00554785]\n",
            "[0.4557416  0.53834957 0.00590876]\n",
            "[0.56815886 0.06381605 0.36802512]\n",
            "[0.29403552 0.7028831  0.00308129]\n",
            "[0.43752837 0.5569256  0.00554608]\n",
            "[0.4215739  0.57318765 0.00523851]\n",
            "[0.4038708  0.59122133 0.00490781]\n",
            "[0.22605346 0.77188957 0.00205697]\n",
            "[0.61664885 0.37356994 0.00978117]\n",
            "[0.8671962  0.08725231 0.04555146]\n",
            "[0.5238428  0.46614054 0.01001662]\n",
            "[0.42858008 0.56604743 0.00537244]\n",
            "[0.76369613 0.05822619 0.1780777 ]\n",
            "[0.35425484 0.64170843 0.00403668]\n",
            "[0.46381456 0.53011185 0.00607361]\n",
            "[0.95789844 0.03965478 0.0024467 ]\n",
            "[0.5099408  0.48299167 0.00706747]\n",
            "[0.4042717  0.5908131  0.00491518]\n",
            "[0.43512434 0.5593766  0.00549914]\n",
            "[0.40028194 0.594876   0.00484209]\n",
            "[0.5387922  0.45305198 0.00815576]\n",
            "[0.4350004  0.55950284 0.00549673]\n",
            "[0.5531775  0.43873367 0.00808884]\n",
            "[0.3394718  0.6567361  0.00379216]\n",
            "[0.53141236 0.45854706 0.01004056]\n",
            "[0.58567023 0.40540656 0.0089232 ]\n",
            "[0.42026648 0.5745198  0.00521371]\n",
            "[0.01329898 0.05122735 0.93547374]\n",
            "[0.4816008  0.51195306 0.00644609]\n",
            "[0.42029503 0.57449067 0.00521425]\n",
            "[0.425992   0.56868523 0.00532276]\n",
            "[0.4330031 0.561539  0.0054579]\n",
            "[0.39089912 0.6044286  0.00467231]\n",
            "[0.57446384 0.41690776 0.00862836]\n",
            "[0.36538848 0.6303863  0.00422529]\n",
            "[0.4758836  0.51779145 0.00632494]\n",
            "[0.4604521  0.5335432  0.00600464]\n",
            "[0.4523533  0.54180634 0.00584033]\n",
            "[0.03988186 0.04869506 0.9114231 ]\n",
            "[0.53451407 0.39998138 0.06550449]\n",
            "[0.5522641 0.4354256 0.0123102]\n",
            "[0.08309358 0.05647749 0.8604289 ]\n",
            "[0.45812136 0.5359215  0.00595709]\n",
            "[0.4256494 0.5690344 0.0053162]\n",
            "[0.71537626 0.27155626 0.01306743]\n",
            "[0.05184635 0.04864477 0.89950883]\n",
            "[0.8780672  0.11982869 0.00210413]\n",
            "[0.8057219  0.04719638 0.14708175]\n",
            "[0.43291757 0.5616262  0.00545624]\n",
            "[0.73778003 0.23704393 0.02517598]\n",
            "[0.5334125  0.45897722 0.00761022]\n",
            "[0.45196068 0.5422068  0.00583243]\n",
            "[0.52436876 0.4653553  0.01027598]\n",
            "[0.54321915 0.06485761 0.39192325]\n",
            "[0.34645447 0.6496387  0.00390683]\n",
            "[0.4645473 0.529364  0.0060887]\n",
            "[0.4071463  0.58788556 0.00496818]\n",
            "[0.43797588 0.55646926 0.00555485]\n",
            "[0.87398374 0.09664087 0.02937543]\n",
            "[0.49371925 0.49957335 0.00670746]\n",
            "[0.39660448 0.59862036 0.00477519]\n",
            "[0.3990377  0.59614295 0.0048194 ]\n",
            "[9.5808226e-01 4.1789412e-02 1.2835381e-04]\n",
            "[0.71419215 0.15074663 0.13506122]\n",
            "[0.04771335 0.05084069 0.90144604]\n",
            "[0.3916616  0.60365236 0.004686  ]\n",
            "[0.524592   0.4648691  0.01053893]\n",
            "[0.44047534 0.5539207  0.00560392]\n",
            "[0.47375226 0.5199676  0.00628012]\n",
            "[0.7092832  0.2576462  0.03307059]\n",
            "[0.39974764 0.59542006 0.00483234]\n",
            "[0.72530055 0.17123905 0.10346041]\n",
            "[0.36870685 0.62701094 0.00428225]\n",
            "[0.85844696 0.11386812 0.027685  ]\n",
            "[0.02634343 0.05158138 0.9220752 ]\n",
            "[0.62203157 0.3107148  0.06725365]\n",
            "[0.43734655 0.55711097 0.00554252]\n",
            "[0.4749289  0.5187663  0.00630484]\n",
            "[0.32135484 0.6751437  0.00350147]\n",
            "[0.26518035 0.7321591  0.00266058]\n",
            "[0.4036756  0.59142023 0.00490423]\n",
            "[0.5271479  0.4653893  0.00746273]\n",
            "[0.83917356 0.13112529 0.02970117]\n",
            "[0.63341904 0.3497297  0.01685131]\n",
            "[0.02634464 0.04984677 0.9238086 ]\n",
            "[0.39654607 0.5986798  0.00477414]\n",
            "[0.4852905 0.5081845 0.006525 ]\n",
            "[0.01285831 0.04712066 0.940021  ]\n",
            "[0.47554606 0.5181361  0.00631783]\n",
            "[0.4139325  0.5809731  0.00509443]\n",
            "[0.57822436 0.32485592 0.09691969]\n",
            "[0.4238049  0.57091415 0.00528097]\n",
            "[0.44215244 0.55221057 0.00563698]\n",
            "[0.49962452 0.4907634  0.00961203]\n",
            "[0.4143497  0.58054805 0.00510224]\n",
            "[0.5282676  0.46246803 0.00926438]\n",
            "[0.6036542  0.38014504 0.01620079]\n",
            "[0.5674163  0.42114598 0.01143765]\n",
            "[0.0222637  0.05490291 0.9228334 ]\n",
            "[0.0092579  0.04980115 0.9409409 ]\n",
            "[0.95520455 0.03314126 0.01165417]\n",
            "[0.5485481  0.44213098 0.00932093]\n",
            "[0.4751468  0.5185438  0.00630942]\n",
            "[0.04863471 0.05049384 0.90087146]\n",
            "[0.41332954 0.5815873  0.00508315]\n",
            "[0.41935772 0.5754458  0.00519651]\n",
            "[0.9613602  0.03756917 0.00107059]\n",
            "[0.52431244 0.45895103 0.01673659]\n",
            "[0.43740162 0.5570548  0.0055436 ]\n",
            "[0.3768413  0.6187353  0.00442338]\n",
            "[0.48419148 0.50655574 0.00925277]\n",
            "[0.01979776 0.04554567 0.93465656]\n",
            "[0.47727922 0.5163664  0.00635439]\n",
            "[0.0350185  0.05113128 0.91385025]\n",
            "[0.47207555 0.52167946 0.006245  ]\n",
            "[0.6162639  0.37396592 0.0097701 ]\n",
            "[0.451525   0.5426513  0.00582367]\n",
            "[9.7344774e-01 2.6465964e-02 8.6375032e-05]\n",
            "[0.6866287  0.301367   0.01200435]\n",
            "[0.42969748 0.5649085  0.00539396]\n",
            "[0.51561433 0.47718936 0.00719624]\n",
            "[0.02200386 0.04475057 0.93324554]\n",
            "[0.65903324 0.31618056 0.02478623]\n",
            "[0.8204666  0.16125047 0.01828292]\n",
            "[0.2919979 0.0710243 0.6369778]\n",
            "[0.44325012 0.540765   0.01598488]\n",
            "[0.44397998 0.49530867 0.06071135]\n",
            "[0.5661867  0.42243546 0.01137781]\n",
            "[0.38449815 0.61094373 0.00455816]\n",
            "[0.33394802 0.66234946 0.00370249]\n",
            "[0.46482667 0.5290788  0.00609446]\n",
            "[0.41969702 0.5751     0.00520293]\n",
            "[0.42094365 0.5738298  0.00522655]\n",
            "[0.45295155 0.54119605 0.00585238]\n",
            "[0.6559871  0.2190954  0.12491754]\n",
            "[0.37932453 0.6162085  0.00446688]\n",
            "[0.40764266 0.58737993 0.00497736]\n",
            "[0.61471164 0.3755628  0.00972555]\n",
            "[0.34056425 0.65562576 0.00381   ]\n",
            "[0.44722065 0.54704183 0.00573752]\n",
            "[0.0495334  0.05033066 0.90013593]\n",
            "[0.5420533  0.4501298  0.00781693]\n",
            "[0.66120994 0.32764593 0.0111441 ]\n",
            "[9.7641546e-01 2.3234660e-02 3.4991701e-04]\n",
            "[0.08833003 0.0566018  0.8550682 ]\n",
            "[0.48461047 0.50887907 0.00651041]\n",
            "[0.66460747 0.2643001  0.0710924 ]\n",
            "[0.46118748 0.53279287 0.00601969]\n",
            "[0.44856244 0.5456732  0.0057643 ]\n",
            "[0.40512925 0.5899397  0.00493096]\n",
            "[0.32738796 0.6690149  0.00359719]\n",
            "[0.36670458 0.62904763 0.00424784]\n",
            "[0.03048994 0.04945609 0.9200539 ]\n",
            "[0.464109   0.5298113  0.00607968]\n",
            "[0.41872004 0.5760955  0.00518446]\n",
            "[0.4008083 0.59434   0.0048517]\n",
            "[0.47442156 0.51928425 0.00629418]\n",
            "[0.5409457  0.45126408 0.00779022]\n",
            "[0.47612974 0.51754016 0.00633013]\n",
            "[0.4192637  0.5755416  0.00519473]\n",
            "[0.33854854 0.6576744  0.00377711]\n",
            "[0.8711622  0.1006653  0.02817245]\n",
            "[0.42325535 0.57147413 0.00527049]\n",
            "[0.02503002 0.04904319 0.9259268 ]\n",
            "[0.93320256 0.06333071 0.00346676]\n",
            "[0.68513626 0.30291182 0.01195193]\n",
            "[0.9303975  0.06709769 0.00250482]\n",
            "[0.8206235  0.03762287 0.14175364]\n",
            "[0.5204382  0.4711748  0.00838695]\n",
            "[0.63074905 0.3590563  0.01019462]\n",
            "[0.38399786 0.6114528  0.0045493 ]\n",
            "[0.46906683 0.5247509  0.00618226]\n",
            "[0.40366322 0.59143275 0.004904  ]\n",
            "[0.52815175 0.46436203 0.00748624]\n",
            "[0.48008642 0.51349974 0.00641386]\n",
            "[0.4531598  0.5409836  0.00585658]\n",
            "[0.5221051  0.06596146 0.41193348]\n",
            "[0.59477925 0.39233828 0.0128825 ]\n",
            "[0.39683518 0.5983854  0.00477938]\n",
            "[0.4305936  0.56399506 0.00541126]\n",
            "[0.4258656  0.56881416 0.00532034]\n",
            "[0.05626464 0.05534919 0.8883862 ]\n",
            "[0.39435354 0.6009119  0.00473448]\n",
            "[0.40420562 0.5908804  0.00491397]\n",
            "[0.5560213  0.4343673  0.00961139]\n",
            "[0.4171018  0.57774425 0.00515393]\n",
            "[0.5206864  0.47200096 0.00731264]\n",
            "[0.92422277 0.05201556 0.02376159]\n",
            "[0.50102955 0.49210215 0.00686824]\n",
            "[0.01705159 0.05108742 0.931861  ]\n",
            "[0.69429636 0.29342586 0.01227779]\n",
            "[0.3727744  0.62287307 0.00435256]\n",
            "[0.7007754  0.06128066 0.23794399]\n",
            "[0.41993165 0.574861   0.00520737]\n",
            "[0.42401674 0.06976205 0.50622123]\n",
            "[0.5231474  0.43111563 0.04573699]\n",
            "[0.5389177  0.4533408  0.00774148]\n",
            "[0.0577955  0.04738747 0.8948171 ]\n",
            "[0.44757223 0.54668325 0.00574453]\n",
            "[0.43912137 0.55530137 0.00557731]\n",
            "[0.34151924 0.6546551  0.00382563]\n",
            "[0.46202254 0.53194064 0.0060368 ]\n",
            "[0.14741042 0.07616109 0.7764284 ]\n",
            "[9.6829480e-01 3.1446755e-02 2.5842796e-04]\n",
            "[0.04365235 0.04957338 0.9067743 ]\n",
            "[0.6031893  0.37765887 0.01915182]\n",
            "[0.6801224  0.30810001 0.01177762]\n",
            "[0.4847283  0.5087587  0.00651294]\n",
            "[0.4259533  0.56872463 0.00532202]\n",
            "[0.6329295  0.35681057 0.01025995]\n",
            "[0.52394164 0.46867046 0.007388  ]\n",
            "[0.41674533 0.5781074  0.00514723]\n",
            "[0.96190685 0.03447015 0.003623  ]\n",
            "[0.5550188  0.43684676 0.00813449]\n",
            "[0.08015109 0.05019893 0.86964995]\n",
            "[0.957362   0.03546735 0.00717071]\n",
            "[0.8721775  0.04218349 0.08563909]\n",
            "[0.01444008 0.05335429 0.9322055 ]\n",
            "[0.4054598  0.5896031  0.00493705]\n",
            "[0.01078676 0.04481326 0.94439995]\n",
            "[0.3676702  0.62806535 0.00426442]\n",
            "[0.54572403 0.43079522 0.02348075]\n",
            "[0.5289723  0.46089047 0.01013722]\n",
            "[0.5799787  0.409387   0.01063428]\n",
            "[0.6844604  0.26833972 0.04719985]\n",
            "[0.59085935 0.40007824 0.00906241]\n",
            "[0.94124323 0.05683756 0.00191928]\n",
            "[0.4769977  0.51665384 0.00634844]\n",
            "[0.52769095 0.46254206 0.00976697]\n",
            "[0.32680902 0.6696031  0.00358795]\n",
            "[0.745513   0.12412047 0.13036653]\n",
            "[0.50890195 0.4818368  0.00926126]\n",
            "[0.42024475 0.574542   0.0052133 ]\n",
            "[0.44825417 0.54598767 0.00575814]\n",
            "[0.41288283 0.58204234 0.0050748 ]\n",
            "[0.9658036  0.03085135 0.00334512]\n",
            "[0.3267122  0.6697014  0.00358641]\n",
            "[0.01484129 0.05119775 0.9339609 ]\n",
            "[0.4150461  0.57983863 0.0051153 ]\n",
            "[0.4016701  0.5934625  0.00486746]\n",
            "[0.20125534 0.7970359  0.00170884]\n",
            "[0.5321964  0.06396362 0.40383998]\n",
            "[0.4367588  0.5577102  0.00553104]\n",
            "[0.415983   0.57888407 0.00513289]\n",
            "[0.46398267 0.52994025 0.00607708]\n",
            "[0.47119293 0.52258044 0.00622656]\n",
            "[0.02855784 0.05013162 0.92131054]\n",
            "[0.2807098  0.07058453 0.64870566]\n",
            "[0.6352993  0.35436928 0.01033139]\n",
            "[0.6461416  0.19436803 0.15949044]\n",
            "[0.32137614 0.6751221  0.00350181]\n",
            "[0.39676243 0.5984595  0.00477806]\n",
            "[0.33916706 0.6570457  0.00378719]\n",
            "[0.6536929  0.33328044 0.0130266 ]\n",
            "[0.7516678  0.05693714 0.19139513]\n",
            "[0.32323688 0.6732319  0.00353121]\n",
            "[0.27754056 0.55473495 0.16772448]\n",
            "[0.46542498 0.52846825 0.00610681]\n",
            "[0.4068081  0.58822995 0.00496193]\n",
            "[0.46467704 0.52923155 0.00609138]\n",
            "[0.38445687 0.61098576 0.00455743]\n",
            "[0.829167   0.15126498 0.01956808]\n",
            "[0.43542048 0.5590746  0.00550491]\n",
            "[0.48935366 0.44361442 0.06703187]\n",
            "[0.44730502 0.54695576 0.0057392 ]\n",
            "[0.91005147 0.08751404 0.00243446]\n",
            "[0.3781658  0.37372914 0.24810505]\n",
            "[0.47559434 0.517694   0.0067117 ]\n",
            "[0.38262153 0.6128535  0.00452495]\n",
            "[0.45267862 0.5414745  0.00584688]\n",
            "[0.47308913 0.5206446  0.00626622]\n",
            "[0.4282292  0.56640506 0.00536569]\n",
            "[0.4227116  0.5720283  0.00526014]\n",
            "[0.4055598  0.58950126 0.0049389 ]\n",
            "[0.49591047 0.487676   0.01641359]\n",
            "[0.46104074 0.5329426  0.00601668]\n",
            "[0.41167867 0.583269   0.00505232]\n",
            "[0.6150366  0.36973038 0.01523303]\n",
            "[0.30955008 0.07215409 0.61829585]\n",
            "[0.9761682  0.02176327 0.00206845]\n",
            "[0.77621764 0.20803195 0.01575037]\n",
            "[0.509242   0.48370636 0.00705172]\n",
            "[0.02404858 0.04967878 0.9262727 ]\n",
            "[0.5220624  0.47059315 0.00734443]\n",
            "[0.541131   0.4510743  0.00779468]\n",
            "[0.67023325 0.31832492 0.0114418 ]\n",
            "[0.20968996 0.78848594 0.00182408]\n",
            "[0.39193702 0.60337204 0.00469094]\n",
            "[0.5340998  0.4551711  0.01072904]\n",
            "[0.4868689  0.46052542 0.05260567]\n",
            "[0.44379285 0.55053777 0.00566941]\n",
            "[0.8129896  0.15009639 0.036914  ]\n",
            "[0.6930177  0.1982646  0.10871766]\n",
            "[0.94948834 0.04829451 0.00221716]\n",
            "[0.90666413 0.08892056 0.00441524]\n",
            "[9.3206799e-01 6.7929626e-02 2.4021447e-06]\n",
            "[0.8986712  0.10012086 0.00120787]\n",
            "[0.8927362  0.10612781 0.00113603]\n",
            "[9.082944e-01 9.108196e-02 6.236596e-04]\n",
            "[0.16001761 0.06477661 0.77520573]\n",
            "[0.86857736 0.10758932 0.02383334]\n",
            "[9.0033865e-01 9.8866843e-02 7.9456752e-04]\n",
            "[0.94710356 0.05110333 0.00179312]\n",
            "[0.5617607  0.12053075 0.31770852]\n",
            "[0.9173566  0.0811697  0.00147368]\n",
            "[9.2228246e-01 7.7440485e-02 2.7705159e-04]\n",
            "[9.2364138e-01 7.5537644e-02 8.2090404e-04]\n",
            "[0.9501442  0.04864491 0.00121094]\n",
            "[9.4891632e-01 5.0770104e-02 3.1359558e-04]\n",
            "[0.719239   0.21947314 0.06128791]\n",
            "[0.49542305 0.18397254 0.32060435]\n",
            "[8.9381468e-01 1.0599098e-01 1.9435411e-04]\n",
            "[0.9024793  0.06632549 0.03119526]\n",
            "[0.9323904  0.06574049 0.00186908]\n",
            "[9.1807646e-01 8.1610598e-02 3.1292430e-04]\n",
            "[9.142706e-01 8.490647e-02 8.229815e-04]\n",
            "[9.2465442e-01 7.5203344e-02 1.4234861e-04]\n",
            "[9.309708e-01 6.902705e-02 2.257245e-06]\n",
            "[0.8365409  0.1129684  0.05049067]\n",
            "[9.0292162e-01 9.6357107e-02 7.2123995e-04]\n",
            "[0.89936215 0.09947028 0.0011675 ]\n",
            "[9.2351186e-01 7.5668536e-02 8.1958628e-04]\n",
            "[0.7332019  0.21330883 0.0534893 ]\n",
            "[0.55875534 0.11567087 0.32557383]\n",
            "[9.4779712e-01 5.2096747e-02 1.0620229e-04]\n",
            "[9.413360e-01 5.860280e-02 6.126972e-05]\n",
            "[0.9185564  0.07891717 0.0025264 ]\n",
            "[9.1253674e-01 8.6672261e-02 7.9092436e-04]\n",
            "[0.79611295 0.19754131 0.00634576]\n",
            "[0.02774715 0.05630909 0.9159438 ]\n",
            "[0.86335576 0.13414903 0.00249523]\n",
            "[0.15635253 0.06241221 0.7812352 ]\n",
            "[9.1891652e-01 8.0999136e-02 8.4323707e-05]\n",
            "[0.7429962  0.181294   0.07570975]\n",
            "[9.4645023e-01 5.3532220e-02 1.7566319e-05]\n",
            "[9.4191074e-01 5.7913914e-02 1.7533769e-04]\n",
            "[9.2238313e-01 7.7459596e-02 1.5718615e-04]\n",
            "[0.782237   0.13826871 0.07949427]\n",
            "[0.9250212  0.07387763 0.00110112]\n",
            "[0.8980132  0.10108293 0.00090388]\n",
            "[0.9156659  0.08334956 0.00098444]\n",
            "[0.9270156  0.07031756 0.00266678]\n",
            "[0.8892688  0.10943452 0.00129669]\n",
            "[0.93527824 0.05611711 0.00860464]\n",
            "[0.74305063 0.18131062 0.07563869]\n",
            "[9.6650141e-01 3.2554667e-02 9.4400294e-04]\n",
            "[0.02894862 0.05526783 0.9157836 ]\n",
            "[0.9044606  0.09449861 0.00104083]\n",
            "[9.0822589e-01 9.1492847e-02 2.8124405e-04]\n",
            "[9.2039186e-01 7.8724951e-02 8.8315108e-04]\n",
            "[0.70176744 0.16709344 0.1311391 ]\n",
            "[0.89002144 0.10885724 0.00112123]\n",
            "[0.43941483 0.0722756  0.4883096 ]\n",
            "[0.957832   0.04102099 0.00114708]\n",
            "[0.87553686 0.12252055 0.00194257]\n",
            "[0.02835003 0.05667869 0.91497123]\n",
            "[9.2615414e-01 7.3107399e-02 7.3835597e-04]\n",
            "[0.9305422  0.06550492 0.0039529 ]\n",
            "[9.185644e-01 8.063367e-02 8.019500e-04]\n",
            "[0.90870476 0.08843611 0.00285917]\n",
            "[0.8118446  0.18728709 0.00086843]\n",
            "[0.8769344  0.12136259 0.00170303]\n",
            "[0.11603115 0.05954044 0.82442844]\n",
            "[0.68573725 0.19698738 0.11727541]\n",
            "[0.9216105  0.07661191 0.00177758]\n",
            "[0.8314284  0.1676571  0.00091456]\n",
            "[0.9215747  0.07578637 0.002639  ]\n",
            "[0.9046295  0.08797606 0.00739443]\n",
            "[9.2801422e-01 7.1077384e-02 9.0837438e-04]\n",
            "[0.8834036  0.11338072 0.0032156 ]\n",
            "[9.352291e-01 6.393250e-02 8.383874e-04]\n",
            "[0.9500584  0.04872921 0.00121243]\n",
            "[0.9174487  0.08034167 0.00220959]\n",
            "[0.5391321  0.06646936 0.39439854]\n",
            "[0.8844423  0.11419187 0.00136582]\n",
            "[0.90150434 0.09448779 0.0040079 ]\n",
            "[0.79521555 0.19658263 0.00820187]\n",
            "[9.4249731e-01 5.7361741e-02 1.4092067e-04]\n",
            "[0.8151167  0.14481467 0.04006858]\n",
            "[9.5905054e-01 4.0806349e-02 1.4308614e-04]\n",
            "[9.5101398e-01 4.8856128e-02 1.2994677e-04]\n",
            "[9.2628914e-01 7.3668607e-02 4.2149350e-05]\n",
            "[0.90091705 0.09806873 0.00101423]\n",
            "[9.298641e-01 7.002796e-02 1.079226e-04]\n",
            "[0.71171355 0.19426046 0.09402601]\n",
            "[0.92624885 0.07123978 0.0025113 ]\n",
            "[0.69331944 0.19831307 0.10836744]\n",
            "[9.2255765e-01 7.7245474e-02 1.9685317e-04]\n",
            "[9.5111340e-01 4.8786487e-02 1.0006402e-04]\n",
            "[0.8413311  0.11665554 0.04201333]\n",
            "[9.5027965e-01 4.9681094e-02 3.9242124e-05]\n",
            "[9.2215765e-01 7.7681534e-02 1.6080213e-04]\n",
            "[0.21754448 0.06755819 0.71489733]\n",
            "[9.5207572e-01 4.7834862e-02 8.9447327e-05]\n",
            "[0.9356111  0.06013384 0.00425501]\n",
            "[9.5264727e-01 4.6807155e-02 5.4556318e-04]\n",
            "[9.544990e-01 4.545096e-02 5.004644e-05]\n",
            "[9.0355510e-01 9.6160598e-02 2.8437193e-04]\n",
            "[0.4933423  0.06570125 0.4409564 ]\n",
            "[9.4823337e-01 5.1731244e-02 3.5389457e-05]\n",
            "[9.5425385e-01 4.5216423e-02 5.2975403e-04]\n",
            "[0.9073029  0.09111717 0.00157987]\n",
            "[0.72220975 0.21665119 0.06113907]\n",
            "[0.82005227 0.17691368 0.00303409]\n",
            "[9.4695300e-01 5.2460585e-02 5.8646942e-04]\n",
            "[0.9096608  0.08864218 0.00169696]\n",
            "[8.8652575e-01 1.1340146e-01 7.2829098e-05]\n",
            "[0.9022747  0.0660962  0.03162904]\n",
            "[0.9143121  0.0830431  0.00264476]\n",
            "[9.4084567e-01 5.8976319e-02 1.7801729e-04]\n",
            "[9.48382378e-01 5.15142977e-02 1.03343315e-04]\n",
            "[9.4696754e-01 5.2419569e-02 6.1284803e-04]\n",
            "[9.5651406e-01 4.3439452e-02 4.6554476e-05]\n",
            "[0.91798985 0.07390435 0.00810576]\n",
            "[0.9183971  0.07899304 0.00260981]\n",
            "[0.80411994 0.13942902 0.05645107]\n",
            "[9.4581240e-01 5.4175027e-02 1.2546973e-05]\n",
            "[0.39711967 0.08700901 0.5158713 ]\n",
            "[9.1643089e-01 8.2734324e-02 8.3477912e-04]\n",
            "[0.89003694 0.104366   0.00559706]\n",
            "[9.5097363e-01 4.8319247e-02 7.0703251e-04]\n",
            "[0.9057223  0.08699193 0.00728569]\n",
            "[0.95927054 0.03883928 0.00189013]\n",
            "[9.5198381e-01 4.7930520e-02 8.5731546e-05]\n",
            "[9.2870551e-01 7.0924968e-02 3.6949047e-04]\n",
            "[0.38172838 0.07308684 0.54518485]\n",
            "[0.9016866  0.09518883 0.00312451]\n",
            "[9.2742610e-01 7.2529972e-02 4.3864267e-05]\n",
            "[0.909391   0.08759941 0.00300964]\n",
            "[0.90615183 0.08905324 0.00479501]\n",
            "[9.3374634e-01 6.5596566e-02 6.5708754e-04]\n",
            "[8.80332768e-01 1.18814826e-01 8.52411205e-04]\n",
            "[0.88203186 0.11378911 0.00417909]\n",
            "[0.9233936  0.06364168 0.01296463]\n",
            "[0.84747875 0.1482252  0.00429612]\n",
            "[9.4641405e-01 5.3470161e-02 1.1573676e-04]\n",
            "[0.7759815  0.19391184 0.03010667]\n",
            "[0.9381737  0.06055225 0.00127409]\n",
            "[0.79410106 0.20304301 0.00285595]\n",
            "[0.0272789  0.05600441 0.91671675]\n",
            "[9.0934783e-01 9.0427548e-02 2.2461329e-04]\n",
            "[0.9184371  0.08030941 0.00125354]\n",
            "[0.8794304  0.10227826 0.01829129]\n",
            "[0.9318753  0.06699107 0.00113363]\n",
            "[0.89533675 0.10367917 0.00098405]\n",
            "[9.2643833e-01 7.2948843e-02 6.1285973e-04]\n",
            "[8.81177604e-01 1.18637614e-01 1.84796532e-04]\n",
            "[9.27147210e-01 7.27461576e-02 1.06641026e-04]\n",
            "[0.7751604  0.1368437  0.08799591]\n",
            "[0.92869055 0.0681935  0.00311601]\n",
            "[0.9360176  0.05537414 0.00860838]\n",
            "[9.5077115e-01 4.9130622e-02 9.8219673e-05]\n",
            "[9.3992335e-01 5.9780128e-02 2.9662138e-04]\n",
            "[9.3273330e-01 6.6487283e-02 7.7946414e-04]\n",
            "[9.4302464e-01 5.6797970e-02 1.7737479e-04]\n",
            "[0.7175368  0.16353846 0.1189247 ]\n",
            "[8.9564103e-01 1.0414765e-01 2.1130152e-04]\n",
            "[0.9333452  0.06484627 0.00180857]\n",
            "[0.33638585 0.07208007 0.59153414]\n",
            "[9.2305243e-01 7.6124862e-02 8.2269422e-04]\n",
            "[0.92422193 0.07469309 0.00108501]\n",
            "[0.93295914 0.06301564 0.00402522]\n",
            "[0.8733025  0.1253637  0.00133376]\n",
            "[0.8887692  0.10999534 0.00123547]\n",
            "[9.3159801e-01 6.8244018e-02 1.5795788e-04]\n",
            "[0.903317   0.09150658 0.00517644]\n",
            "[0.93686324 0.06167943 0.00145731]\n",
            "[8.9639050e-01 1.0339664e-01 2.1288428e-04]\n",
            "[8.6478263e-01 1.3490693e-01 3.1040728e-04]\n",
            "[0.08171903 0.06046899 0.8578119 ]\n",
            "[9.1255987e-01 8.6638056e-02 8.0212869e-04]\n",
            "[0.91095513 0.08736839 0.0016765 ]\n",
            "[0.90667886 0.08420517 0.00911591]\n",
            "[9.4815242e-01 5.1742665e-02 1.0484735e-04]\n",
            "[0.94123626 0.05763521 0.00112851]\n",
            "[0.918601   0.07429543 0.00710369]\n",
            "[0.90266263 0.09206332 0.00527408]\n",
            "[9.7967076e-01 2.0308957e-02 2.0350781e-05]\n",
            "[0.9354515  0.06330102 0.00124746]\n",
            "[0.7866078  0.12943104 0.08396125]\n",
            "[0.80918795 0.1882058  0.00260621]\n",
            "[0.9022269  0.09569289 0.0020802 ]\n",
            "[9.2901522e-01 7.0257038e-02 7.2774553e-04]\n",
            "[9.1740990e-01 8.1979059e-02 6.1102095e-04]\n",
            "[9.6340764e-01 3.6030822e-02 5.6158553e-04]\n",
            "[0.8414616  0.11634772 0.04219066]\n",
            "[9.2845505e-01 7.0757620e-02 7.8735239e-04]\n",
            "[0.89918417 0.09420389 0.00661187]\n",
            "[9.5881259e-01 4.1084316e-02 1.0314149e-04]\n",
            "[9.7246224e-01 2.7193816e-02 3.4390477e-04]\n",
            "[0.8792363  0.11197723 0.00878652]\n",
            "[0.02748752 0.05593389 0.9165786 ]\n",
            "[8.9993083e-01 9.9263653e-02 8.0559449e-04]\n",
            "[9.38939214e-01 6.09474406e-02 1.13249785e-04]\n",
            "[0.9024216  0.09652556 0.00105288]\n",
            "[0.89796907 0.1008621  0.00116885]\n",
            "[0.9611675  0.0366606  0.00217186]\n",
            "[0.10257569 0.05627306 0.84115124]\n",
            "[0.8321831  0.16676876 0.00104805]\n",
            "[0.8764058  0.11437576 0.00921849]\n",
            "[0.8638814  0.13505222 0.00106643]\n",
            "[0.8678696  0.09255913 0.03957123]\n",
            "[9.5162946e-01 4.8369154e-02 1.3218707e-06]\n",
            "[0.8896354  0.10922757 0.00113702]\n",
            "[0.8811845  0.10155404 0.01726152]\n",
            "[0.82845104 0.17059198 0.000957  ]\n",
            "[0.9310098  0.06793752 0.0010527 ]\n",
            "[9.2472064e-01 7.4367337e-02 9.1201038e-04]\n",
            "[9.47168887e-01 5.27110845e-02 1.20018696e-04]\n",
            "[0.7692589  0.19824485 0.03249613]\n",
            "[9.2826772e-01 7.1130104e-02 6.0221745e-04]\n",
            "[0.90317166 0.09172475 0.0051036 ]\n",
            "[0.9219828  0.07624419 0.00177307]\n",
            "[9.3037254e-01 6.9546096e-02 8.1354105e-05]\n",
            "[0.92632943 0.06725637 0.00641412]\n",
            "[9.4299966e-01 5.6926575e-02 7.3787269e-05]\n",
            "[9.4987023e-01 5.0091799e-02 3.7916456e-05]\n",
            "[0.90372413 0.09109819 0.00517761]\n",
            "[9.2666805e-01 7.2985217e-02 3.4677697e-04]\n",
            "[9.1915303e-01 8.0670379e-02 1.7663521e-04]\n",
            "[0.89998007 0.09884205 0.00117785]\n",
            "[9.3748999e-01 6.1747424e-02 7.6263479e-04]\n",
            "[0.88047373 0.11530332 0.00422289]\n",
            "[0.8728184  0.09412518 0.0330564 ]\n",
            "[9.1875046e-01 8.0913089e-02 3.3649339e-04]\n",
            "[0.8244237  0.17463517 0.00094121]\n",
            "[0.81794184 0.18102224 0.00103586]\n",
            "[0.91688967 0.08216896 0.00094138]\n",
            "[9.1381401e-01 8.5349306e-02 8.3671266e-04]\n",
            "[0.9074498  0.08802067 0.00452958]\n",
            "[9.3673193e-01 6.2786065e-02 4.8193877e-04]\n",
            "[9.1968864e-01 8.0285780e-02 2.5597812e-05]\n",
            "[0.912253   0.08477549 0.00297145]\n",
            "[0.773911   0.13939978 0.0866892 ]\n",
            "[8.9261383e-01 1.0670272e-01 6.8344106e-04]\n",
            "[8.6869740e-01 1.3113485e-01 1.6773875e-04]\n",
            "[9.4539744e-01 5.4486003e-02 1.1654699e-04]\n",
            "[0.83171076 0.16027085 0.00801841]\n",
            "[0.8628304  0.10163715 0.03553237]\n",
            "[9.5925564e-01 4.0413670e-02 3.3068663e-04]\n",
            "[0.04722957 0.05317426 0.89959615]\n",
            "[9.3429291e-01 6.5066613e-02 6.4040266e-04]\n",
            "[9.1552126e-01 8.4179677e-02 2.9908284e-04]\n",
            "[0.7037799  0.16192332 0.13429677]\n",
            "[9.4914275e-01 5.0401088e-02 4.5623261e-04]\n",
            "[0.9417811  0.05664426 0.00157466]\n",
            "[0.9001478  0.09325772 0.00659445]\n",
            "[8.8601786e-01 1.1382312e-01 1.5892190e-04]\n",
            "[9.149248e-01 8.422080e-02 8.544387e-04]\n",
            "[0.84057504 0.14518231 0.01424269]\n",
            "[0.9579685  0.04106764 0.00096392]\n",
            "[0.03027615 0.05722538 0.91249853]\n",
            "[9.007492e-01 9.896309e-02 2.876304e-04]\n",
            "[9.3875837e-01 6.1107434e-02 1.3414018e-04]\n",
            "[9.1095376e-01 8.8732727e-02 3.1345896e-04]\n",
            "[0.86430514 0.10044678 0.03524808]\n",
            "[0.91070586 0.0876474  0.0016467 ]\n",
            "[8.30018520e-01 1.69861615e-01 1.19839366e-04]\n",
            "[0.9032384 0.0924152 0.0043464]\n",
            "[9.209185e-01 7.902238e-02 5.921755e-05]\n",
            "[0.02858408 0.05674453 0.9146713 ]\n",
            "[0.88941884 0.1064863  0.00409488]\n",
            "[0.81256664 0.13351862 0.05391473]\n",
            "[8.3110756e-01 1.6876666e-01 1.2571365e-04]\n",
            "[8.7660676e-01 1.2301882e-01 3.7445617e-04]\n",
            "[0.90726495 0.08457089 0.00816416]\n",
            "[8.6439377e-01 1.3507229e-01 5.3389370e-04]\n",
            "[9.5537835e-01 4.4534788e-02 8.6919681e-05]\n",
            "[9.1276473e-01 8.6451225e-02 7.8413333e-04]\n",
            "[0.93019134 0.06507888 0.00472978]\n",
            "[0.92035896 0.07870559 0.00093547]\n",
            "[0.8864465  0.10423858 0.00931492]\n",
            "[0.9059605  0.09205957 0.00197994]\n",
            "[0.8987942  0.0924129  0.00879293]\n",
            "[9.4728422e-01 5.2681543e-02 3.4258137e-05]\n",
            "[0.8697142  0.12908402 0.00120187]\n",
            "[0.88515866 0.11393569 0.00090567]\n",
            "[0.80389416 0.19154465 0.00456118]\n",
            "[9.362055e-01 6.348832e-02 3.062518e-04]\n",
            "[0.9361871  0.06284288 0.00097009]\n",
            "[0.89710635 0.09415139 0.00874232]\n",
            "[9.2420220e-01 7.5795323e-02 2.5009465e-06]\n",
            "[8.7342995e-01 1.2587330e-01 6.9678447e-04]\n",
            "[0.8664107  0.13110918 0.00248019]\n",
            "[9.0460795e-01 9.5282704e-02 1.0936647e-04]\n",
            "[0.913074   0.08578788 0.00113805]\n",
            "[9.6904916e-01 3.0515663e-02 4.3518571e-04]\n",
            "[0.8577057  0.14099321 0.00130109]\n",
            "[0.91135734 0.08696295 0.00167973]\n",
            "[0.55085987 0.11248673 0.33665344]\n",
            "[0.79142964 0.20251381 0.00605654]\n",
            "[9.4764024e-01 5.2186508e-02 1.7328122e-04]\n",
            "[9.2918831e-01 7.0642091e-02 1.6958262e-04]\n",
            "[0.8828019  0.10858177 0.00861623]\n",
            "[9.4025880e-01 5.9601828e-02 1.3942276e-04]\n",
            "[0.93577063 0.06187501 0.00235441]\n",
            "[0.7859442  0.1728136  0.04124217]\n",
            "[0.928811   0.06926049 0.00192842]\n",
            "[9.120980e-01 8.775395e-02 1.481351e-04]\n",
            "[9.2306036e-01 7.6892324e-02 4.7292913e-05]\n",
            "[8.6144656e-01 1.3839236e-01 1.6107912e-04]\n",
            "[8.87337089e-01 1.12060025e-01 6.02971762e-04]\n",
            "[0.9058658  0.08984978 0.00428441]\n",
            "[9.3274057e-01 6.6927552e-02 3.3192313e-04]\n",
            "[9.2117333e-01 7.8663953e-02 1.6269175e-04]\n",
            "[9.1033059e-01 8.9479141e-02 1.9018148e-04]\n",
            "[0.90854186 0.08346894 0.00798921]\n",
            "[0.83491725 0.13841696 0.02666584]\n",
            "[0.8593613  0.11148083 0.0291579 ]\n",
            "[9.1437334e-01 8.4768057e-02 8.5861422e-04]\n",
            "[0.9642558  0.0337834  0.00196073]\n",
            "[0.791799   0.20200363 0.00619735]\n",
            "[0.8062652  0.13668787 0.05704692]\n",
            "[9.1247696e-01 8.7119043e-02 4.0400619e-04]\n",
            "[9.3747336e-01 6.2220935e-02 3.0580530e-04]\n",
            "[0.8879584  0.1021986  0.00984296]\n",
            "[9.1554409e-01 8.4019244e-02 4.3663793e-04]\n",
            "[9.1283643e-01 8.6875036e-02 2.8863069e-04]\n",
            "[9.3297732e-01 6.6855513e-02 1.6718071e-04]\n",
            "[0.9423795  0.05565726 0.00196323]\n",
            "[0.9346822  0.06344058 0.00187727]\n",
            "[0.9005156  0.0975347  0.00194965]\n",
            "[0.07905557 0.05339579 0.86754864]\n",
            "[0.9095648  0.08736197 0.00307323]\n",
            "[0.8291877  0.15537518 0.01543721]\n",
            "[0.876401   0.11446098 0.00913805]\n",
            "[0.8533536  0.10892174 0.03772457]\n",
            "[0.8472776  0.11546899 0.03725344]\n",
            "[0.94312865 0.0548664  0.002005  ]\n",
            "[8.9559382e-01 1.0402577e-01 3.8037638e-04]\n",
            "[0.91958916 0.0788696  0.00154127]\n",
            "[0.8753848  0.11477306 0.00984219]\n",
            "[9.2548215e-01 7.4186750e-02 3.3109460e-04]\n",
            "[0.89771634 0.09851234 0.00377135]\n",
            "[0.88712156 0.10985694 0.00302148]\n",
            "[9.4476795e-01 5.5180989e-02 5.0964161e-05]\n",
            "[0.21186957 0.06861654 0.7195139 ]\n",
            "[7.8578556e-01 2.1401325e-01 2.0117123e-04]\n",
            "[9.0053016e-01 9.9266388e-02 2.0344566e-04]\n",
            "[0.8004984  0.1931582  0.00634338]\n",
            "[9.1434020e-01 8.5467458e-02 1.9225608e-04]\n",
            "[9.5176208e-01 4.8228327e-02 9.6403737e-06]\n",
            "[0.7249206  0.16172297 0.11335649]\n",
            "[0.9050435  0.08904463 0.00591192]\n",
            "[0.91765046 0.07967989 0.0026696 ]\n",
            "[0.8677457  0.13124724 0.00100704]\n",
            "[9.4167179e-01 5.8218788e-02 1.0944771e-04]\n",
            "[0.9466806  0.05117833 0.00214111]\n",
            "[9.3482906e-01 6.4270847e-02 9.0009120e-04]\n",
            "[9.2477876e-01 7.4409239e-02 8.1199000e-04]\n",
            "[0.8919614  0.10653731 0.00150123]\n",
            "[0.937206   0.05435173 0.00844228]\n",
            "[0.3725165  0.07143078 0.55605274]\n",
            "[8.83583069e-01 1.16238594e-01 1.78358998e-04]\n",
            "[0.8903091  0.0990639  0.01062699]\n",
            "[0.9429054  0.05513896 0.00195557]\n",
            "[0.7771819  0.13983497 0.08298308]\n",
            "[0.8307868  0.1682247  0.00098848]\n",
            "[9.171101e-01 8.206524e-02 8.246185e-04]\n",
            "[9.2957628e-01 7.0421413e-02 2.2797249e-06]\n",
            "[8.8987368e-01 1.0950076e-01 6.2559551e-04]\n",
            "[0.94758296 0.0506719  0.00174508]\n",
            "[9.204935e-01 7.925488e-02 2.516538e-04]\n",
            "[0.88637906 0.10432597 0.00929504]\n",
            "[0.9141263  0.08413895 0.0017347 ]\n",
            "[9.1571355e-01 8.4178753e-02 1.0770270e-04]\n",
            "[0.82407695 0.1749803  0.0009428 ]\n",
            "[0.8928507  0.10318503 0.00396428]\n",
            "[9.3933606e-01 6.0521785e-02 1.4226642e-04]\n",
            "[9.1901428e-01 8.0816038e-02 1.6968348e-04]\n",
            "[0.6052826  0.06319088 0.33152652]\n",
            "[0.69835734 0.16743474 0.134208  ]\n",
            "[0.44937187 0.09728023 0.4533479 ]\n",
            "[0.9149828  0.07731166 0.00770558]\n",
            "[9.240931e-01 7.579172e-02 1.151636e-04]\n",
            "[9.4757962e-01 5.2139081e-02 2.8122612e-04]\n",
            "[0.9516217  0.04718482 0.00119356]\n",
            "[9.011309e-01 9.824845e-02 6.205483e-04]\n",
            "[0.821778   0.1772817  0.00094026]\n",
            "[9.2480046e-01 7.4482091e-02 7.1750116e-04]\n",
            "[8.4770662e-01 1.5146585e-01 8.2757405e-04]\n",
            "[9.1330582e-01 8.5866332e-02 8.2792673e-04]\n",
            "[0.80558175 0.18998985 0.00442843]\n",
            "[0.89353925 0.10250928 0.00395146]\n",
            "[0.9443956  0.03417728 0.02142718]\n",
            "[0.8928218  0.105522   0.00165623]\n",
            "[9.3509614e-01 6.4831413e-02 7.2488045e-05]\n",
            "[0.88357407 0.10090128 0.01552462]\n",
            "[0.92399126 0.0747465  0.00126217]\n",
            "[9.3530405e-01 6.4048067e-02 6.4791302e-04]\n",
            "[0.7184169  0.21839726 0.06318582]\n",
            "[0.44011012 0.08956572 0.47032413]\n",
            "[0.8155897  0.131352   0.05305818]\n",
            "[0.6922973  0.19824623 0.10945643]\n",
            "[9.3911743e-01 6.0583211e-02 2.9937277e-04]\n",
            "[0.8472477  0.11551942 0.03723286]\n",
            "[0.9472747  0.05099765 0.00172767]\n",
            "[0.9419836  0.05585444 0.00216201]\n",
            "[9.2070127e-01 7.9194695e-02 1.0408801e-04]\n",
            "[0.9595453  0.03855    0.00190465]\n",
            "[0.7935019  0.15578584 0.0507122 ]\n",
            "[0.6859821  0.16507328 0.14894468]\n",
            "[8.90218854e-01 1.09600075e-01 1.81087496e-04]\n",
            "[0.9357362  0.06262074 0.00164307]\n",
            "[0.68494177 0.15045065 0.16460757]\n",
            "[9.5276380e-01 4.7227543e-02 8.6339542e-06]\n",
            "[0.9489529  0.04979022 0.00125694]\n",
            "[8.8231164e-01 1.1735754e-01 3.3074839e-04]\n",
            "[9.3794000e-01 6.1756238e-02 3.0379172e-04]\n",
            "[9.2940605e-01 7.0537709e-02 5.6280376e-05]\n",
            "[8.9602727e-01 1.0331658e-01 6.5612636e-04]\n",
            "[0.93777645 0.05993295 0.00229064]\n",
            "[0.8688469  0.12871788 0.00243525]\n",
            "[0.82529986 0.17376809 0.00093199]\n",
            "[0.90269154 0.09206493 0.00524351]\n",
            "[0.57324606 0.12430522 0.30244875]\n",
            "[9.292145e-01 7.061081e-02 1.748364e-04]\n",
            "[0.9422527  0.05562193 0.00212539]\n",
            "[9.1244829e-01 8.7340742e-02 2.1090328e-04]\n",
            "[0.8468016  0.11621732 0.03698106]\n",
            "[9.2122006e-01 7.8618757e-02 1.6112193e-04]\n",
            "[0.9291958  0.06799993 0.00280424]\n",
            "[0.8738796  0.12465047 0.00146991]\n",
            "[0.8046569  0.13890745 0.05643555]\n",
            "[0.94259596 0.05544132 0.00196274]\n",
            "[0.9212147  0.07751849 0.00126671]\n",
            "[0.1068502  0.05876294 0.8343869 ]\n",
            "[9.249929e-01 7.467501e-02 3.321251e-04]\n",
            "[9.262604e-01 7.304765e-02 6.918358e-04]\n",
            "[0.89755005 0.09558161 0.00686825]\n",
            "[9.1288918e-01 8.6956605e-02 1.5417123e-04]\n",
            "[9.3623924e-01 6.3226715e-02 5.3400494e-04]\n",
            "[0.95772225 0.04039563 0.00188205]\n",
            "[9.2899626e-01 7.0906036e-02 9.7623022e-05]\n",
            "[9.1924936e-01 8.0583639e-02 1.6701840e-04]\n",
            "[9.2667228e-01 7.3325314e-02 2.4084395e-06]\n",
            "[0.94991404 0.0488685  0.00121757]\n",
            "[0.9073251  0.09155405 0.00112088]\n",
            "[0.93135476 0.06760263 0.00104269]\n",
            "[8.8248616e-01 1.1729543e-01 2.1835907e-04]\n",
            "[8.2315516e-01 1.7675062e-01 9.4167692e-05]\n",
            "[8.9698106e-01 1.0296302e-01 5.5957928e-05]\n",
            "[9.3024427e-01 6.9696896e-02 5.8922091e-05]\n",
            "[0.72284985 0.21892017 0.05823001]\n",
            "[0.88929945 0.10954361 0.00115687]\n",
            "[0.9167705  0.08115444 0.00207508]\n",
            "[9.041882e-01 9.522525e-02 5.865298e-04]\n",
            "[9.1507941e-01 8.4623545e-02 2.9706705e-04]\n",
            "[0.13453735 0.06114203 0.80432063]\n",
            "[0.95867825 0.03943436 0.00188736]\n",
            "[0.76570964 0.20295522 0.03133517]\n",
            "[0.89273417 0.10329081 0.00397493]\n",
            "[0.90047216 0.0932281  0.00629976]\n",
            "[0.6257361  0.12450501 0.24975896]\n",
            "[0.88491505 0.11397844 0.00110649]\n",
            "[9.5693380e-01 4.2287182e-02 7.7905919e-04]\n",
            "[0.83297133 0.15166394 0.01536466]\n",
            "[9.4554204e-01 5.4447688e-02 1.0208103e-05]\n",
            "[9.1240203e-01 8.7573111e-02 2.4760991e-05]\n",
            "[8.8242453e-01 1.1693514e-01 6.4031105e-04]\n",
            "[0.8796427  0.11884848 0.00150882]\n",
            "[9.4330740e-01 5.6445677e-02 2.4699842e-04]\n",
            "[0.91548765 0.08319112 0.00132119]\n",
            "[0.90066963 0.09813056 0.00119985]\n",
            "[0.0281331  0.05661743 0.91524947]\n",
            "[9.4019091e-01 5.9631117e-02 1.7794922e-04]\n",
            "[0.87876076 0.11488021 0.00635903]\n",
            "[0.8679771  0.1308062  0.00121667]\n",
            "[9.0912348e-01 9.0763688e-02 1.1276833e-04]\n",
            "[9.3529767e-01 6.4064465e-02 6.3781784e-04]\n",
            "[9.5301872e-01 4.6249993e-02 7.3135062e-04]\n",
            "[8.90164137e-01 1.09676406e-01 1.59422925e-04]\n",
            "[0.9331844  0.06580403 0.00101168]\n",
            "[8.6159503e-01 1.3824426e-01 1.6070544e-04]\n",
            "[0.03106381 0.05739085 0.91154534]\n",
            "[0.8971448  0.10170023 0.00115494]\n",
            "[8.7441784e-01 1.2540780e-01 1.7430400e-04]\n",
            "[9.0971178e-01 8.9877844e-02 4.1032161e-04]\n",
            "[0.80472237 0.18728907 0.0079885 ]\n",
            "[9.2002255e-01 7.9815313e-02 1.6223827e-04]\n",
            "[9.164904e-01 8.297492e-02 5.347286e-04]\n",
            "[9.5689964e-01 4.2954236e-02 1.4616644e-04]\n",
            "[0.86515486 0.1338704  0.00097468]\n",
            "[9.1540802e-01 8.3741687e-02 8.5030164e-04]\n",
            "[0.26497933 0.06927764 0.665743  ]\n",
            "[0.8995221  0.09460492 0.00587298]\n",
            "[0.915453   0.08239672 0.00215027]\n",
            "[8.7928653e-01 1.2029429e-01 4.1915459e-04]\n",
            "[0.8510153  0.14772649 0.00125818]\n",
            "[0.7456269  0.18210313 0.07226992]\n",
            "[0.8168428  0.17967322 0.00348399]\n",
            "[0.88916004 0.10958163 0.00125824]\n",
            "[9.3656683e-01 6.3119687e-02 3.1347506e-04]\n",
            "[0.8737307  0.11004221 0.01622712]\n",
            "[0.87072307 0.1262108  0.00306605]\n",
            "[9.5113927e-01 4.8859533e-02 1.2218426e-06]\n",
            "[0.8993039  0.09953346 0.00116259]\n",
            "[0.75054276 0.18364097 0.06581625]\n",
            "[0.81403553 0.18366082 0.00230367]\n",
            "[0.90694755 0.0914324  0.00162011]\n",
            "[9.2218298e-01 7.7602148e-02 2.1487636e-04]\n",
            "[9.5072466e-01 4.9203329e-02 7.1976385e-05]\n",
            "[0.89881873 0.09793647 0.0032447 ]\n",
            "[8.7411141e-01 1.2520841e-01 6.8017159e-04]\n",
            "[9.3506497e-01 6.4317785e-02 6.1719760e-04]\n",
            "[0.886215   0.11175553 0.00202943]\n",
            "[8.7771708e-01 1.2161661e-01 6.6634349e-04]\n",
            "[0.90042436 0.09845609 0.00111953]\n",
            "[0.90330404 0.09150187 0.00519404]\n",
            "[0.8152518  0.14277944 0.04196874]\n",
            "[0.86471975 0.13329358 0.0019867 ]\n",
            "[0.83865106 0.11452103 0.04682787]\n",
            "[0.9009965  0.0975829  0.00142061]\n",
            "[9.187853e-01 8.052325e-02 6.914021e-04]\n",
            "[0.8912155  0.10049877 0.00828576]\n",
            "[9.2867470e-01 7.0708260e-02 6.1713194e-04]\n",
            "[8.8315350e-01 1.1666749e-01 1.7898862e-04]\n",
            "[9.4522083e-01 5.4628491e-02 1.5060714e-04]\n",
            "[9.388473e-01 6.040576e-02 7.468984e-04]\n",
            "[0.7802575  0.19454595 0.02519658]\n",
            "[0.8592318  0.13706769 0.00370057]\n",
            "[9.2093086e-01 7.8910910e-02 1.5814902e-04]\n",
            "[0.9235213  0.07545707 0.00102167]\n",
            "[0.8170806  0.17937367 0.00354565]\n",
            "[0.03161293 0.05748552 0.91090155]\n",
            "[0.84210485 0.15321198 0.00468316]\n",
            "[0.910309   0.08800227 0.00168867]\n",
            "[9.3582529e-01 6.3567311e-02 6.0737645e-04]\n",
            "[0.8978457  0.10099143 0.00116285]\n",
            "[9.2432642e-01 7.5436167e-02 2.3745013e-04]\n",
            "[0.85874933 0.13977642 0.00147426]\n",
            "[0.8741362  0.12295339 0.00291046]\n",
            "[0.9256175  0.07343372 0.00094873]\n",
            "[0.8925484  0.10344282 0.00400881]\n",
            "[0.776844   0.17117189 0.05198409]\n",
            "[0.5568509  0.11518057 0.32796848]\n",
            "[9.5447630e-01 4.5499664e-02 2.4060961e-05]\n",
            "[8.7639356e-01 1.2323989e-01 3.6645611e-04]\n",
            "[0.8736477  0.12427173 0.0020805 ]\n",
            "[0.8209814  0.17604573 0.0029729 ]\n",
            "[0.9296446  0.06767109 0.00268432]\n",
            "[0.9332479  0.06305101 0.00370114]\n",
            "[0.556679   0.11352455 0.3297964 ]\n",
            "[0.8318578  0.15277207 0.01537006]\n",
            "[0.03014182 0.05718233 0.91267586]\n",
            "[9.078248e-01 9.175823e-02 4.169841e-04]\n",
            "[9.3935204e-01 6.0598463e-02 4.9481012e-05]\n",
            "[7.9231870e-01 2.0752461e-01 1.5656551e-04]\n",
            "[0.20146264 0.06844798 0.73008937]\n",
            "[0.9000615  0.09875482 0.00118366]\n",
            "[8.6598241e-01 1.3385175e-01 1.6576663e-04]\n",
            "[9.0020126e-01 9.8993517e-02 8.0524501e-04]\n",
            "[0.8992819  0.09800056 0.00271746]\n",
            "[0.3973356  0.087301   0.51536334]\n",
            "[9.4079477e-01 5.9098206e-02 1.0701354e-04]\n",
            "[9.4503564e-01 5.4232895e-02 7.3152850e-04]\n",
            "[0.8788504  0.09388942 0.02726021]\n",
            "[9.3696225e-01 6.2996425e-02 4.1327719e-05]\n",
            "[0.8261718  0.17290471 0.00092352]\n",
            "[0.02831024 0.05559148 0.91609824]\n",
            "[9.0279776e-01 9.6402295e-02 7.9998426e-04]\n",
            "[8.867822e-01 1.131391e-01 7.865871e-05]\n",
            "[0.9002475  0.09675669 0.00299577]\n",
            "[8.9480144e-01 1.0443199e-01 7.6651055e-04]\n",
            "[0.9303521  0.06669249 0.00295547]\n",
            "[0.9033878  0.0914824  0.00512976]\n",
            "[9.2224675e-01 7.7105246e-02 6.4798025e-04]\n",
            "[0.86334777 0.12394651 0.01270579]\n",
            "[9.5610261e-01 4.3787912e-02 1.0951132e-04]\n",
            "[0.7194704  0.2185951  0.06193458]\n",
            "[9.5304263e-01 4.6926897e-02 3.0467341e-05]\n",
            "[0.9003818  0.09582347 0.00379468]\n",
            "[0.88332325 0.10691994 0.00975685]\n",
            "[9.2629886e-01 7.3083878e-02 6.1732176e-04]\n",
            "[0.95889586 0.03919137 0.00191279]\n",
            "[9.5682311e-01 4.3034483e-02 1.4236322e-04]\n",
            "[9.5028085e-01 4.9479771e-02 2.3941211e-04]\n",
            "[0.6918799  0.19821496 0.10990519]\n",
            "[9.2003602e-01 7.9796277e-02 1.6771576e-04]\n",
            "[0.9102634  0.08809409 0.00164252]\n",
            "[0.73020566 0.16034968 0.10944462]\n",
            "[9.5732957e-01 4.2511553e-02 1.5884235e-04]\n",
            "[9.5162815e-01 4.7663413e-02 7.0840464e-04]\n",
            "[9.4743472e-01 5.2307133e-02 2.5817560e-04]\n",
            "[9.4234824e-01 5.6975286e-02 6.7646714e-04]\n",
            "[0.9494506  0.04832073 0.0022287 ]\n",
            "[0.25424477 0.06922305 0.6765322 ]\n",
            "[9.4015032e-01 5.9743293e-02 1.0635390e-04]\n",
            "[0.9111071  0.08721612 0.00167672]\n",
            "[0.53198916 0.1088567  0.3591541 ]\n",
            "[0.9148029  0.07751564 0.00768143]\n",
            "[0.03169036 0.05756906 0.9107406 ]\n",
            "[0.68766314 0.15364736 0.1586895 ]\n",
            "[0.8284409  0.16989633 0.00166284]\n",
            "[9.427770e-01 5.689879e-02 3.242782e-04]\n",
            "[0.93091124 0.06596702 0.0031217 ]\n",
            "[0.80207914 0.19036707 0.00755375]\n",
            "[9.650315e-01 3.444241e-02 5.260440e-04]\n",
            "[0.9004319  0.09458861 0.00497953]\n",
            "[0.93825316 0.06041487 0.00133195]\n",
            "[9.3401068e-01 6.5086409e-02 9.0286986e-04]\n",
            "[0.9111846  0.08787956 0.00093579]\n",
            "[0.88369435 0.11419376 0.00211197]\n",
            "[0.58441544 0.12399421 0.2915904 ]\n",
            "[9.5812660e-01 4.1607603e-02 2.6579364e-04]\n",
            "[0.89634347 0.10263366 0.00102291]\n",
            "[0.885946   0.10979397 0.00426001]\n",
            "[0.8419102  0.11561524 0.04247455]\n",
            "[0.902892   0.09198628 0.00512171]\n",
            "[0.6385181  0.09099706 0.27048483]\n",
            "[0.9009334  0.09578792 0.00327865]\n",
            "[0.9463335  0.05185992 0.00180659]\n",
            "[9.5785123e-01 4.1213684e-02 9.3509164e-04]\n",
            "[8.8326353e-01 1.1637608e-01 3.6045202e-04]\n",
            "[0.73609483 0.10753579 0.15636943]\n",
            "[9.2686629e-01 7.2931543e-02 2.0223757e-04]\n",
            "[9.1179907e-01 8.8178098e-02 2.2773938e-05]\n",
            "[0.75243074 0.21005957 0.03750969]\n",
            "[9.4801658e-01 5.1808685e-02 1.7466617e-04]\n",
            "[9.4838893e-01 5.1326849e-02 2.8417347e-04]\n",
            "[0.38089946 0.08460692 0.5344936 ]\n",
            "[9.3224418e-01 6.7126594e-02 6.2927377e-04]\n",
            "[0.8760666  0.12214342 0.00178992]\n",
            "[9.2515123e-01 7.4404553e-02 4.4423985e-04]\n",
            "[0.87860143 0.11971384 0.00168475]\n",
            "[0.9425847  0.05545763 0.00195757]\n",
            "[8.9276034e-01 1.0703440e-01 2.0529577e-04]\n",
            "[0.81443894 0.12570876 0.05985226]\n",
            "[9.1862059e-01 8.1196822e-02 1.8251847e-04]\n",
            "[0.79150176 0.20268537 0.00581289]\n",
            "[9.0192491e-01 9.7250000e-02 8.2513667e-04]\n",
            "[0.92798537 0.07005791 0.00195678]\n",
            "[9.3552315e-01 6.4380273e-02 9.6549396e-05]\n",
            "[0.9335093  0.06495199 0.00153872]\n",
            "[0.94894785 0.04979181 0.00126029]\n",
            "[0.8704642  0.12798998 0.00154586]\n",
            "[0.78945    0.1831965  0.02735347]\n",
            "[9.5720679e-01 4.2640064e-02 1.5308379e-04]\n",
            "[8.9095795e-01 1.0844296e-01 5.9899798e-04]\n",
            "[9.2301404e-01 7.6342396e-02 6.4360478e-04]\n",
            "[9.1401333e-01 8.5682116e-02 3.0450465e-04]\n",
            "[0.1311195  0.06084669 0.8080338 ]\n",
            "[8.8074172e-01 1.1860514e-01 6.5312802e-04]\n",
            "[0.93782485 0.06097429 0.00120085]\n",
            "[0.32684395 0.07210695 0.6010491 ]\n",
            "[0.8317646  0.16665961 0.00157579]\n",
            "[9.1494906e-01 8.5020334e-02 3.0656010e-05]\n",
            "[0.18632594 0.06731886 0.7463552 ]\n",
            "[0.93057716 0.06836185 0.00106096]\n",
            "[9.1120738e-01 8.8772304e-02 2.0334419e-05]\n",
            "[0.91202015 0.08561417 0.00236562]\n",
            "[9.5965368e-01 3.9693885e-02 6.5244455e-04]\n",
            "[9.3033928e-01 6.8752676e-02 9.0802857e-04]\n",
            "[9.3959969e-01 5.9882440e-02 5.1785726e-04]\n",
            "[0.8213947  0.17570424 0.00290112]\n",
            "[9.337690e-01 6.532514e-02 9.058796e-04]\n",
            "[9.5206827e-01 4.7921870e-02 9.9099798e-06]\n",
            "[9.2621726e-01 7.3780350e-02 2.4418750e-06]\n",
            "[0.81118745 0.13417727 0.0546352 ]\n",
            "[0.82654446 0.172519   0.00093655]\n",
            "[0.8877723  0.11031267 0.00191497]\n",
            "[9.1944057e-01 7.9654351e-02 9.0512505e-04]\n",
            "[9.5166236e-01 4.8262578e-02 7.4938711e-05]\n",
            "[9.1310877e-01 8.6865112e-02 2.6085316e-05]\n",
            "[0.84382194 0.11686419 0.03931386]\n",
            "[0.27748185 0.07044187 0.65207636]\n",
            "[9.2507541e-01 7.4307144e-02 6.1742985e-04]\n",
            "[9.48861480e-01 5.10193594e-02 1.19189135e-04]\n",
            "[0.8215068  0.17557642 0.00291682]\n",
            "[9.4759697e-01 5.1875874e-02 5.2705628e-04]\n",
            "[0.8974202  0.10145663 0.00112309]\n",
            "[0.9465568  0.05167587 0.00176728]\n",
            "[0.882245   0.11450817 0.00324674]\n",
            "[0.68643135 0.165195   0.14837362]\n",
            "[8.81276488e-01 1.18297525e-01 4.26050159e-04]\n",
            "[0.38846928 0.08515355 0.52637714]\n",
            "[0.88472515 0.1057227  0.00955223]\n",
            "[9.180669e-01 8.150611e-02 4.269863e-04]\n",
            "[0.76055527 0.18690792 0.05253684]\n",
            "[9.4215244e-01 5.7731073e-02 1.1645239e-04]\n",
            "[0.8557298  0.10752431 0.03674582]\n",
            "[0.9190103  0.07966617 0.00132356]\n",
            "[9.4637728e-01 5.3040367e-02 5.8234727e-04]\n",
            "[9.3661439e-01 6.2784374e-02 6.0124492e-04]\n",
            "[0.8985267  0.10027451 0.00119868]\n",
            "[0.8352096  0.15890731 0.00588312]\n",
            "[9.6995103e-01 2.9646920e-02 4.0198435e-04]\n",
            "[0.9364606  0.05495767 0.00858171]\n",
            "[7.9671341e-01 2.0299609e-01 2.9053376e-04]\n",
            "[0.85766    0.14099586 0.00134405]\n",
            "[0.83222693 0.15240197 0.01537112]\n",
            "[0.9004612  0.0966027  0.00293621]\n",
            "[8.7800777e-01 1.2160468e-01 3.8760353e-04]\n",
            "[0.94221777 0.05580701 0.00197529]\n",
            "[0.8986201  0.1003845  0.00099541]\n",
            "[0.813506   0.18162152 0.0048724 ]\n",
            "[0.9317601  0.06719927 0.00104063]\n",
            "[9.4275057e-01 5.7088573e-02 1.6084942e-04]\n",
            "[0.9489107  0.04982584 0.00126342]\n",
            "[0.92398006 0.07171437 0.00430549]\n",
            "[8.8988727e-01 1.0996089e-01 1.5177445e-04]\n",
            "[0.9431256  0.05492736 0.00194705]\n",
            "[0.83262545 0.15991002 0.0074645 ]\n",
            "[9.2637354e-01 7.3420756e-02 2.0568277e-04]\n",
            "[0.39576134 0.07014781 0.5340909 ]\n",
            "[0.6934772  0.19850878 0.10801406]\n",
            "[0.87493396 0.1239656  0.00110041]\n",
            "[0.19063647 0.067742   0.74162155]\n",
            "[9.4753319e-01 5.2258190e-02 2.0858663e-04]\n",
            "[0.8981637  0.10063861 0.00119768]\n",
            "[0.8578006  0.14091451 0.00128492]\n",
            "[0.86489886 0.13263892 0.00246227]\n",
            "[0.84079343 0.14531064 0.01389599]\n",
            "[9.1451466e-01 8.4633283e-02 8.5210148e-04]\n",
            "[0.9416002  0.05724515 0.00115473]\n",
            "[0.83616    0.15675241 0.00708758]\n",
            "[0.79820085 0.2007225  0.00107662]\n",
            "[0.896759   0.09946915 0.00377189]\n",
            "[0.93566686 0.0627876  0.00154553]\n",
            "[9.4431466e-01 5.5616722e-02 6.8515896e-05]\n",
            "[0.90344834 0.08915039 0.0074013 ]\n",
            "[0.9144709  0.08334523 0.00218385]\n",
            "[9.1404402e-01 8.5652851e-02 3.0309925e-04]\n",
            "[9.5061523e-01 4.9084309e-02 3.0044245e-04]\n",
            "[9.4775492e-01 5.1972155e-02 2.7296494e-04]\n",
            "[9.3517298e-01 6.4498074e-02 3.2899881e-04]\n",
            "[0.7393431  0.15242277 0.10823414]\n",
            "[0.93300813 0.06592907 0.0010629 ]\n",
            "[0.80929184 0.17619123 0.0145169 ]\n",
            "[0.911026   0.08258401 0.00638997]\n",
            "[0.88925904 0.10596944 0.00477147]\n",
            "[0.91146016 0.08685745 0.00168238]\n",
            "[0.9177896  0.07993346 0.00227695]\n",
            "[9.2730594e-01 7.2338611e-02 3.5542453e-04]\n",
            "[0.84588957 0.11691346 0.03719693]\n",
            "[0.96007967 0.03769739 0.00222298]\n",
            "[0.9575947  0.04120583 0.00119958]\n",
            "[0.8443962  0.10616833 0.0494355 ]\n",
            "[0.8667943  0.13019651 0.00300915]\n",
            "[9.0113258e-01 9.8657973e-02 2.0942847e-04]\n",
            "[9.275138e-01 7.185270e-02 6.336018e-04]\n",
            "[9.2022365e-01 7.9585515e-02 1.9081554e-04]\n",
            "[0.88071734 0.11709417 0.00218851]\n",
            "[8.80224288e-01 1.19594984e-01 1.80709671e-04]\n",
            "[0.8417832  0.10501233 0.05320442]\n",
            "[0.73318475 0.1556875  0.11112773]\n",
            "[0.8280812  0.170977   0.00094185]\n",
            "[0.31985217 0.07897104 0.6011768 ]\n",
            "[9.5218098e-01 4.7817562e-02 1.5176719e-06]\n",
            "[0.83977264 0.10568693 0.05454038]\n",
            "[0.7755245  0.1376496  0.08682592]\n",
            "[9.2498201e-01 7.4398093e-02 6.1988755e-04]\n",
            "[9.5800996e-01 4.1838218e-02 1.5184851e-04]\n",
            "[0.8817425  0.10962997 0.0086276 ]\n",
            "[9.4597334e-01 5.3995486e-02 3.1098345e-05]\n",
            "[0.90430003 0.09475631 0.00094373]\n",
            "[0.93557274 0.06310271 0.00132456]\n",
            "[0.90864253 0.09032962 0.00102781]\n",
            "[8.8733464e-01 1.1194164e-01 7.2376803e-04]\n",
            "[0.86947256 0.1292702  0.00125728]\n",
            "[0.8843839  0.11127561 0.00434042]\n",
            "[0.9078405  0.09060304 0.00155645]\n",
            "[9.2342204e-01 7.5760856e-02 8.1710448e-04]\n",
            "[0.8873454  0.10357273 0.00908196]\n",
            "[0.84510654 0.11408141 0.04081206]\n",
            "[9.1655308e-01 8.3014846e-02 4.3215408e-04]\n",
            "[9.4309157e-01 5.6435388e-02 4.7313113e-04]\n",
            "[0.872209   0.12611246 0.00167852]\n",
            "[0.78167677 0.17550889 0.0428144 ]\n",
            "[9.0170515e-01 9.8069437e-02 2.2540960e-04]\n",
            "[0.02789078 0.05646837 0.91564083]\n",
            "[9.3830287e-01 6.1393738e-02 3.0339812e-04]\n",
            "[0.866831   0.1316478  0.00152116]\n",
            "[0.866854   0.13050067 0.00264535]\n",
            "[0.8829179  0.11317324 0.00390884]\n",
            "[0.9160077  0.07590629 0.00808599]\n",
            "[0.88631105 0.11061576 0.0030731 ]\n",
            "[0.78575116 0.18698406 0.02726473]\n",
            "[0.8399107  0.14544566 0.01464375]\n",
            "[0.86034656 0.13834994 0.00130348]\n",
            "[9.5051599e-01 4.9193278e-02 2.9075216e-04]\n",
            "[9.4729054e-01 5.2170049e-02 5.3942227e-04]\n",
            "[0.9193764  0.07876024 0.00186343]\n",
            "[8.2943559e-01 1.7043251e-01 1.3188875e-04]\n",
            "[0.8978918  0.09852434 0.00358379]\n",
            "[0.8928614  0.10557714 0.00156142]\n",
            "[0.8947182  0.10189039 0.00339144]\n",
            "[0.8096927  0.18913862 0.00116867]\n",
            "[0.10531897 0.06240583 0.8322753 ]\n",
            "[0.87654036 0.12184384 0.00161571]\n",
            "[0.85581404 0.142854   0.00133194]\n",
            "[9.48651671e-01 5.13355248e-02 1.28097145e-05]\n",
            "[0.89705426 0.09610637 0.00683937]\n",
            "[9.2487335e-01 7.4486569e-02 6.4004242e-04]\n",
            "[8.8007343e-01 1.1916152e-01 7.6507567e-04]\n",
            "[0.9154669  0.08287431 0.00165884]\n",
            "[0.9006094  0.09819458 0.00119604]\n",
            "[9.2203861e-01 7.7798925e-02 1.6242874e-04]\n",
            "[0.742934   0.18127497 0.07579103]\n",
            "[9.3586814e-01 6.3650601e-02 4.8132360e-04]\n",
            "[0.9114831  0.08474708 0.00376971]\n",
            "[0.88024914 0.10413645 0.01561441]\n",
            "[0.43677574 0.08994238 0.4732819 ]\n",
            "[0.02219414 0.05386841 0.92393744]\n",
            "[0.867405   0.09853853 0.03405643]\n",
            "[0.9181259  0.07937038 0.00250363]\n",
            "[9.1242427e-01 8.7420247e-02 1.5546827e-04]\n",
            "[0.9073982  0.09107142 0.00153035]\n",
            "[0.8918641  0.10716335 0.00097245]\n",
            "[9.3151176e-01 6.7853533e-02 6.3470774e-04]\n",
            "[0.45699686 0.10416186 0.43884125]\n",
            "[0.94098085 0.05709672 0.00192246]\n",
            "[9.2035359e-01 7.8915142e-02 7.3124404e-04]\n",
            "[9.1916454e-01 8.0760427e-02 7.5027754e-05]\n",
            "[0.92101115 0.07730807 0.00168083]\n",
            "[9.6114451e-01 3.8815394e-02 4.0083585e-05]\n",
            "[0.82879907 0.1701963  0.00100465]\n",
            "[9.4018322e-01 5.9293229e-02 5.2347936e-04]\n",
            "[0.90999097 0.08648711 0.00352188]\n",
            "[0.84936905 0.14936621 0.00126478]\n",
            "[0.8318283  0.16719142 0.00098031]\n",
            "[9.4969970e-01 4.9592987e-02 7.0740137e-04]\n",
            "[0.76923466 0.13773088 0.09303439]\n",
            "[0.00703298 0.04849347 0.9444736 ]\n",
            "[0.02001293 0.04763195 0.9323551 ]\n",
            "[0.02516188 0.05753836 0.91729975]\n",
            "[0.0135863  0.04498058 0.94143313]\n",
            "[0.01726348 0.05014842 0.93258804]\n",
            "[0.03231064 0.05528691 0.91240245]\n",
            "[0.01452684 0.05415116 0.931322  ]\n",
            "[0.03213824 0.05520899 0.9126528 ]\n",
            "[0.01636811 0.04893939 0.93469256]\n",
            "[0.03591286 0.05304873 0.91103846]\n",
            "[0.03550443 0.05491203 0.90958345]\n",
            "[0.02316502 0.05205244 0.92478263]\n",
            "[0.0219829  0.04672857 0.9312885 ]\n",
            "[0.01561195 0.0500445  0.93434364]\n",
            "[0.01123036 0.04887224 0.9398974 ]\n",
            "[0.02347085 0.05736794 0.9191612 ]\n",
            "[0.0142998 0.0478785 0.9378216]\n",
            "[0.02400266 0.05319509 0.9228022 ]\n",
            "[0.01510879 0.05111086 0.9337803 ]\n",
            "[0.03038325 0.05208893 0.9175279 ]\n",
            "[0.01033566 0.05057022 0.93909407]\n",
            "[0.03099271 0.05322087 0.9157865 ]\n",
            "[0.0151426  0.04813386 0.9367235 ]\n",
            "[0.00795807 0.04319094 0.9488509 ]\n",
            "[0.01591461 0.05047471 0.9336106 ]\n",
            "[0.0105343  0.04617253 0.94329315]\n",
            "[0.03510049 0.05297785 0.9119217 ]\n",
            "[0.02851558 0.05124924 0.92023516]\n",
            "[0.01592856 0.05048666 0.9335848 ]\n",
            "[0.03281578 0.05271496 0.9144692 ]\n",
            "[0.03403404 0.05373149 0.9122345 ]\n",
            "[0.00741117 0.04317963 0.94940925]\n",
            "[0.00893229 0.04470838 0.9463593 ]\n",
            "[0.01204566 0.049162   0.93879247]\n",
            "[0.01796508 0.04825797 0.9337769 ]\n",
            "[0.03038988 0.05621435 0.9133958 ]\n",
            "[0.00503544 0.04332064 0.95164394]\n",
            "[0.02347804 0.04816275 0.92835927]\n",
            "[0.04710432 0.05650211 0.8963936 ]\n",
            "[0.00739275 0.04335255 0.94925463]\n",
            "[0.01184759 0.04386066 0.9442917 ]\n",
            "[0.01714692 0.04966127 0.93319184]\n",
            "[0.02168055 0.052554   0.92576545]\n",
            "[0.03234521 0.05524356 0.9124113 ]\n",
            "[0.02842847 0.04889677 0.9226747 ]\n",
            "[0.0231751  0.05111806 0.9257068 ]\n",
            "[0.03104153 0.05460839 0.9143501 ]\n",
            "[0.01867636 0.0468134  0.9345103 ]\n",
            "[0.03383898 0.05267339 0.9134876 ]\n",
            "[0.01131245 0.04601681 0.9426707 ]\n",
            "[0.03396166 0.05194204 0.9140963 ]\n",
            "[0.02928139 0.05148043 0.91923815]\n",
            "[0.03559395 0.05491471 0.90949124]\n",
            "[0.01214857 0.04808363 0.9397678 ]\n",
            "[0.01512724 0.05127883 0.93359387]\n",
            "[0.03648978 0.05270247 0.91080767]\n",
            "[0.03466501 0.05162108 0.9137139 ]\n",
            "[0.01316731 0.04976871 0.937064  ]\n",
            "[0.00668715 0.04216635 0.9511465 ]\n",
            "[0.04002994 0.05453983 0.9054303 ]\n",
            "[0.0207826  0.04709074 0.9321266 ]\n",
            "[0.02022198 0.04987947 0.9298986 ]\n",
            "[0.02191341 0.04871396 0.9293726 ]\n",
            "[0.00927524 0.0432402  0.9474845 ]\n",
            "[0.03759442 0.05414641 0.90825915]\n",
            "[0.01393154 0.05067782 0.9353907 ]\n",
            "[0.00753484 0.04368598 0.9487792 ]\n",
            "[0.03343282 0.05667261 0.9098945 ]\n",
            "[0.01665433 0.05072086 0.9326249 ]\n",
            "[0.01673343 0.04692543 0.9363412 ]\n",
            "[0.01091769 0.05007681 0.93900555]\n",
            "[0.029051   0.05074858 0.92020047]\n",
            "[0.02102769 0.04779236 0.93117994]\n",
            "[0.02416222 0.05347097 0.9223668 ]\n",
            "[0.0265632  0.05552448 0.91791224]\n",
            "[0.00574072 0.0424888  0.9517705 ]\n",
            "[0.00566509 0.04001958 0.9543154 ]\n",
            "[0.03697628 0.0555592  0.9074645 ]\n",
            "[0.01586087 0.04669244 0.93744665]\n",
            "[0.01507722 0.05551405 0.9294087 ]\n",
            "[0.0356129  0.05767054 0.9067166 ]\n",
            "[0.03905383 0.05709155 0.9038546 ]\n",
            "[0.01311608 0.04724786 0.939636  ]\n",
            "[0.01627469 0.05098465 0.93274057]\n",
            "[0.0140341  0.04941015 0.93655574]\n",
            "[0.03817066 0.05465483 0.90717447]\n",
            "[0.02546494 0.04985339 0.9246817 ]\n",
            "[0.03864137 0.0570747  0.90428394]\n",
            "[0.03633463 0.0549455  0.90871984]\n",
            "[0.01695587 0.04969754 0.93334657]\n",
            "[0.03667365 0.05551792 0.9078084 ]\n",
            "[0.02396912 0.05729927 0.91873163]\n",
            "[0.03076793 0.05614572 0.9130863 ]\n",
            "[0.02621062 0.05536652 0.9184229 ]\n",
            "[0.0129219  0.04382401 0.9432541 ]\n",
            "[0.01516457 0.05182513 0.93301034]\n",
            "[0.03181759 0.05425675 0.91392565]\n",
            "[0.01929506 0.04711415 0.9335909 ]\n",
            "[0.0073187  0.04148214 0.95119923]\n",
            "[0.03319173 0.05270226 0.9141061 ]\n",
            "[0.01588559 0.05265618 0.9314582 ]\n",
            "[0.02820376 0.05109391 0.9207023 ]\n",
            "[0.10093267 0.05831412 0.84075314]\n",
            "[0.04472082 0.05453851 0.9007406 ]\n",
            "[0.01315755 0.05261008 0.9342323 ]\n",
            "[0.00970562 0.04383209 0.9464623 ]\n",
            "[0.02955645 0.05584751 0.914596  ]\n",
            "[0.02727135 0.04665948 0.9260692 ]\n",
            "[0.0151629  0.04688177 0.93795544]\n",
            "[0.03070405 0.05628236 0.9130137 ]\n",
            "[0.01875975 0.04962803 0.9316122 ]\n",
            "[0.03486381 0.05586011 0.9092761 ]\n",
            "[0.01453768 0.05105678 0.93440557]\n",
            "[0.0208526  0.04790991 0.9312375 ]\n",
            "[0.01397427 0.05696856 0.9290572 ]\n",
            "[0.01614594 0.05543729 0.9284167 ]\n",
            "[0.04033852 0.05710933 0.9025522 ]\n",
            "[0.01011415 0.04612694 0.94375885]\n",
            "[0.0182162  0.0506162  0.93116766]\n",
            "[0.0145383  0.04559264 0.939869  ]\n",
            "[0.03332684 0.05666246 0.91001064]\n",
            "[0.01597904 0.05547718 0.9285438 ]\n",
            "[0.01466587 0.05027914 0.9350551 ]\n",
            "[0.02922147 0.05675853 0.91402   ]\n",
            "[0.04145467 0.05711527 0.9014301 ]\n",
            "[0.031353   0.05637775 0.9122693 ]\n",
            "[0.02846032 0.05320744 0.9183323 ]\n",
            "[0.01079894 0.04645088 0.94275016]\n",
            "[0.02910707 0.04636221 0.9245308 ]\n",
            "[0.04080738 0.05328463 0.9059079 ]\n",
            "[0.01590684 0.05239741 0.9316957 ]\n",
            "[0.01561928 0.0552231  0.9291576 ]\n",
            "[0.02805189 0.05483307 0.91711503]\n",
            "[0.02564934 0.05243069 0.92192   ]\n",
            "[0.01553478 0.04644716 0.938018  ]\n",
            "[0.03440998 0.05512698 0.9104631 ]\n",
            "[0.01813114 0.05130157 0.9305674 ]\n",
            "[0.01617305 0.04715534 0.9366716 ]\n",
            "[0.02571375 0.05454695 0.91973925]\n",
            "[0.00529787 0.04342218 0.95127994]\n",
            "[0.01635215 0.05594879 0.92769915]\n",
            "[0.03242853 0.05448643 0.91308504]\n",
            "[0.03249275 0.05519277 0.91231453]\n",
            "[0.02073736 0.05303634 0.9262264 ]\n",
            "[0.0279189  0.05069945 0.92138165]\n",
            "[0.03270057 0.05273198 0.9145674 ]\n",
            "[0.02786257 0.05553192 0.91660553]\n",
            "[0.01447813 0.05721857 0.9283033 ]\n",
            "[0.00767434 0.04730317 0.9450226 ]\n",
            "[0.00706511 0.04073183 0.95220304]\n",
            "[0.0324823  0.05826813 0.9092496 ]\n",
            "[0.01610634 0.05544242 0.92845124]\n",
            "[0.00516975 0.04337779 0.95145243]\n",
            "[0.02772076 0.05387913 0.91840005]\n",
            "[0.02350184 0.05253037 0.9239677 ]\n",
            "[0.03239314 0.05551993 0.91208684]\n",
            "[0.03469081 0.05328219 0.912027  ]\n",
            "[0.03240239 0.05517953 0.912418  ]\n",
            "[0.01591542 0.0502915  0.9337931 ]\n",
            "[0.01096688 0.05525925 0.9337739 ]\n",
            "[0.01364557 0.0459732  0.9403812 ]\n",
            "[0.02712101 0.05480656 0.91807246]\n",
            "[0.03246184 0.05508516 0.91245294]\n",
            "[0.01250123 0.04941531 0.93808335]\n",
            "[0.01390706 0.04612739 0.93996555]\n",
            "[0.01578447 0.04750489 0.9367106 ]\n",
            "[0.02079509 0.04713212 0.93207276]\n",
            "[0.01383466 0.0566052  0.9295601 ]\n",
            "[0.03406727 0.05255625 0.91337645]\n",
            "[0.06188784 0.05684515 0.881267  ]\n",
            "[0.02446197 0.04819744 0.92734057]\n",
            "[0.00878977 0.04539625 0.945814  ]\n",
            "[0.0108148  0.04887079 0.9403143 ]\n",
            "[0.00673666 0.04293399 0.9503293 ]\n",
            "[0.01271348 0.04837044 0.938916  ]\n",
            "[0.0196349  0.04669105 0.9336741 ]\n",
            "[0.01556161 0.05256301 0.9318754 ]\n",
            "[0.03535869 0.05773026 0.9069111 ]\n",
            "[0.01333788 0.05256464 0.93409747]\n",
            "[0.01533272 0.04549435 0.93917304]\n",
            "[0.01732088 0.05152865 0.9311505 ]\n",
            "[0.03782485 0.05459987 0.9075753 ]\n",
            "[0.04152685 0.05711078 0.90136236]\n",
            "[0.01683581 0.05036487 0.9327994 ]\n",
            "[0.03030572 0.05470055 0.91499376]\n",
            "[0.03544533 0.05018297 0.9143717 ]\n",
            "[0.02084142 0.04724661 0.931912  ]\n",
            "[0.03407871 0.05255545 0.9133659 ]\n",
            "[0.01585494 0.0553192  0.928826  ]\n",
            "[0.01380015 0.04474521 0.9414547 ]\n",
            "[0.05113461 0.05383319 0.8950321 ]\n",
            "[0.01559088 0.05253471 0.93187445]\n",
            "[0.0099575  0.04404196 0.94600046]\n",
            "[0.02651751 0.05073203 0.9227504 ]\n",
            "[0.03286342 0.05293142 0.91420513]\n",
            "[0.02411176 0.05510044 0.9207878 ]\n",
            "[0.02405671 0.05732331 0.91862   ]\n",
            "[0.00784516 0.04126691 0.950888  ]\n",
            "[0.01047781 0.04355831 0.94596386]\n",
            "[0.00454736 0.04097551 0.9544772 ]\n",
            "[0.0278485  0.05541913 0.9167324 ]\n",
            "[0.0131073 0.0472712 0.9396215]\n",
            "[0.03303757 0.05279188 0.91417056]\n",
            "[0.03797998 0.05707439 0.90494573]\n",
            "[0.03099349 0.0547202  0.9142863 ]\n",
            "[0.03076206 0.05197357 0.91726434]\n",
            "[0.02886144 0.04638383 0.9247547 ]\n",
            "[0.02346335 0.04955192 0.92698467]\n",
            "[0.00757628 0.04326826 0.9491554 ]\n",
            "[0.02259037 0.05037804 0.92703164]\n",
            "[0.03509216 0.05715926 0.9077486 ]\n",
            "[0.0652221  0.05073117 0.88404673]\n",
            "[0.01140822 0.0435905  0.94500124]\n",
            "[0.03025827 0.0550776  0.91466415]\n",
            "[0.01100348 0.04664633 0.94235015]\n",
            "[0.03041518 0.0555652  0.91401964]\n",
            "[0.01108889 0.0462601  0.94265103]\n",
            "[0.02674138 0.05573311 0.9175255 ]\n",
            "[0.00897266 0.04463277 0.9463946 ]\n",
            "[0.0130817  0.04965829 0.93726   ]\n",
            "[0.02220402 0.05176852 0.9260274 ]\n",
            "[0.02969664 0.05546215 0.9148413 ]\n",
            "[0.0340589  0.05255319 0.91338784]\n",
            "[0.02622265 0.05194041 0.9218369 ]\n",
            "[0.0340739  0.05255708 0.91336906]\n",
            "[0.0095948  0.04525825 0.94514704]\n",
            "[0.00720375 0.04855631 0.94424   ]\n",
            "[0.03071306 0.05554448 0.9137424 ]\n",
            "[0.01202255 0.04922441 0.93875307]\n",
            "[0.02205136 0.05677528 0.92117345]\n",
            "[0.0221008  0.05103653 0.9268627 ]\n",
            "[0.02632467 0.04967926 0.92399603]\n",
            "[0.01495105 0.05765033 0.9273986 ]\n",
            "[0.0323232  0.05523623 0.91244066]\n",
            "[0.00761602 0.04733182 0.94505215]\n",
            "[0.03403391 0.0513644  0.9146016 ]\n",
            "[0.00685331 0.04310613 0.9500405 ]\n",
            "[0.01930148 0.04899546 0.93170303]\n",
            "[0.06638037 0.05703716 0.8765825 ]\n",
            "[0.01709745 0.05199439 0.93090814]\n",
            "[0.01361974 0.04550204 0.94087815]\n",
            "[0.03213997 0.05441609 0.913444  ]\n",
            "[0.03617835 0.05264102 0.9111807 ]\n",
            "[0.02594057 0.04910479 0.92495465]\n",
            "[0.01715385 0.0502731  0.932573  ]\n",
            "[0.00788296 0.04322038 0.94889665]\n",
            "[0.01330585 0.05341367 0.9332805 ]\n",
            "[0.01832035 0.04660013 0.9350796 ]\n",
            "[0.02003215 0.04918971 0.93077815]\n",
            "[0.00747948 0.04884979 0.94367075]\n",
            "[0.04283431 0.05367725 0.9034885 ]\n",
            "[0.01144632 0.05240464 0.93614906]\n",
            "[0.00931346 0.04457375 0.9461128 ]\n",
            "[0.02805845 0.05489552 0.91704595]\n",
            "[0.02293339 0.05127386 0.9257928 ]\n",
            "[0.01966743 0.04858536 0.93174714]\n",
            "[0.03271539 0.05243909 0.9148456 ]\n",
            "[0.03400948 0.05261794 0.91337264]\n",
            "[0.00940294 0.04459785 0.9459992 ]\n",
            "[0.05789137 0.05439872 0.88771   ]\n",
            "[0.0349254  0.05010285 0.9149717 ]\n",
            "[0.01441938 0.05104231 0.93453836]\n",
            "[0.01679877 0.05611913 0.9270821 ]\n",
            "[0.01603335 0.05025598 0.9337107 ]\n",
            "[0.01086634 0.04424104 0.9448926 ]\n",
            "[0.01285153 0.0546269  0.9325216 ]\n",
            "[0.013498   0.04696973 0.9395322 ]\n",
            "[0.01725922 0.0501742  0.9325666 ]\n",
            "[0.00732202 0.03943349 0.9532445 ]\n",
            "[0.01384681 0.04997884 0.93617433]\n",
            "[0.01726104 0.05020762 0.93253136]\n",
            "[0.01564571 0.05252216 0.93183213]\n",
            "[0.02967149 0.04895221 0.9213763 ]\n",
            "[0.02078118 0.04710414 0.93211466]\n",
            "[0.01123934 0.05232058 0.93644   ]\n",
            "[0.0377472  0.05116903 0.91108376]\n",
            "[0.03082455 0.05195618 0.9172193 ]\n",
            "[0.03033167 0.05231511 0.9173532 ]\n",
            "[0.016061   0.05544986 0.92848915]\n",
            "[0.03027478 0.05609418 0.9136311 ]\n",
            "[0.01792805 0.05474624 0.9273257 ]\n",
            "[0.01706424 0.05184493 0.93109083]\n",
            "[0.01240656 0.04481685 0.94277656]\n",
            "[0.01706012 0.05293975 0.9300002 ]\n",
            "[0.02462725 0.05158576 0.92378706]\n",
            "[0.00502507 0.04348563 0.95148927]\n",
            "[0.02248014 0.05113756 0.92638224]\n",
            "[0.01201442 0.0524339  0.93555164]\n",
            "[0.02682028 0.05430787 0.9188718 ]\n",
            "[0.00774914 0.04482108 0.94742984]\n",
            "[0.01969152 0.04893403 0.93137443]\n",
            "[0.02904654 0.05374489 0.91720855]\n",
            "[0.01055376 0.05062417 0.9388221 ]\n",
            "[0.00710715 0.04393992 0.9489529 ]\n",
            "[0.01540805 0.04918657 0.9354053 ]\n",
            "[0.01131207 0.04290497 0.94578296]\n",
            "[0.01462252 0.04694663 0.93843085]\n",
            "[0.03881716 0.05143288 0.90975   ]\n",
            "[0.0498748 0.048593  0.9015322]\n",
            "[0.03235427 0.05282936 0.9148164 ]\n",
            "[0.01404226 0.05180639 0.9341514 ]\n",
            "[0.03111322 0.05327271 0.91561407]\n",
            "[0.0153982  0.05183531 0.9327665 ]\n",
            "[0.02064262 0.05560589 0.92375153]\n",
            "[0.01280054 0.05077404 0.9364254 ]\n",
            "[0.01835742 0.04870142 0.9329412 ]\n",
            "[0.02906766 0.05363361 0.91729873]\n",
            "[0.01238107 0.04712934 0.94048953]\n",
            "[0.0158765  0.05113012 0.9329933 ]\n",
            "[0.02623629 0.05478546 0.9189782 ]\n",
            "[0.01187004 0.0465087  0.94162136]\n",
            "[0.00675027 0.04501975 0.9482299 ]\n",
            "[0.02365093 0.05100702 0.92534196]\n",
            "[0.0113011  0.04402478 0.944674  ]\n",
            "[0.05052848 0.0486449  0.9008267 ]\n",
            "[0.03012332 0.05587136 0.9140054 ]\n",
            "[0.01073987 0.05104943 0.93821067]\n",
            "[0.01846988 0.05048989 0.9310403 ]\n",
            "[0.04297608 0.0537369  0.90328705]\n",
            "[0.01515741 0.04780831 0.93703425]\n",
            "[0.03395622 0.05174995 0.91429377]\n",
            "[0.00467267 0.04114796 0.9541793 ]\n",
            "[0.03321377 0.05586496 0.91092134]\n",
            "[0.00741213 0.04754603 0.94504195]\n",
            "[0.01627042 0.04681791 0.9369116 ]\n",
            "[0.020129   0.05234224 0.92752874]\n",
            "[0.0302679  0.05219852 0.91753364]\n",
            "[0.03856563 0.05870729 0.9027271 ]\n",
            "[0.01755066 0.04908419 0.93336517]\n",
            "[0.00859928 0.04473126 0.9466694 ]\n",
            "[0.03464146 0.05582955 0.90952903]\n",
            "[0.0069708  0.0485047  0.94452447]\n",
            "[0.01478365 0.04638868 0.93882763]\n",
            "[0.06768017 0.05663802 0.8756818 ]\n",
            "[0.01061192 0.04620058 0.94318753]\n",
            "[0.01049019 0.05048404 0.93902576]\n",
            "[0.01866343 0.05551709 0.9258195 ]\n",
            "[0.26362655 0.06911691 0.66725653]\n",
            "[0.00833634 0.04826312 0.9434005 ]\n",
            "[0.02082619 0.05299506 0.9261788 ]\n",
            "[0.01155007 0.05244987 0.936     ]\n",
            "[0.04087952 0.05427926 0.9048412 ]\n",
            "[0.01699267 0.05174375 0.93126357]\n",
            "[0.01953501 0.05494047 0.92552453]\n",
            "[0.01793639 0.05121961 0.930844  ]\n",
            "[0.00779065 0.04326396 0.9489454 ]\n",
            "[0.01655612 0.05579647 0.9276474 ]\n",
            "[0.03282811 0.05238691 0.9147849 ]\n",
            "[0.03764447 0.05292049 0.90943503]\n",
            "[0.01824715 0.04899882 0.932754  ]\n",
            "[0.01468951 0.05424836 0.9310622 ]\n",
            "[0.01519698 0.04838141 0.93642163]\n",
            "[0.03395085 0.0519154  0.9141338 ]\n",
            "[0.01778614 0.05115285 0.9310611 ]\n",
            "[0.01590815 0.05266512 0.93142676]\n",
            "[0.03192127 0.05429797 0.91378075]\n",
            "[0.02498872 0.05540593 0.9196054 ]\n",
            "[0.02937364 0.05021251 0.9204139 ]\n",
            "[0.03769879 0.05405399 0.9082472 ]\n",
            "[0.01329142 0.04979763 0.936911  ]\n",
            "[0.01003097 0.04841667 0.94155246]\n",
            "[0.03263597 0.05257741 0.91478664]\n",
            "[0.03077211 0.05449874 0.91472906]\n",
            "[0.01133215 0.05236214 0.9363057 ]\n",
            "[0.03106154 0.05314903 0.9157894 ]\n",
            "[0.00633269 0.04335384 0.95031345]\n",
            "[0.01075937 0.05500926 0.93423134]\n",
            "[0.03028504 0.05554556 0.9141693 ]\n",
            "[0.03196641 0.05503162 0.9130021 ]\n",
            "[0.07084446 0.05753629 0.8716192 ]\n",
            "[0.01297852 0.05259405 0.9344274 ]\n",
            "[0.00724809 0.04391411 0.94883776]\n",
            "[0.02409143 0.0542249  0.92168367]\n",
            "[0.03390558 0.05185947 0.914235  ]\n",
            "[0.02497425 0.05772782 0.91729796]\n",
            "[0.0136587  0.05065663 0.9356847 ]\n",
            "[0.00907456 0.04148083 0.9494446 ]\n",
            "[0.01845386 0.05208012 0.929466  ]\n",
            "[0.01693153 0.04968506 0.9333834 ]\n",
            "[0.01789415 0.05172582 0.93038005]\n",
            "[0.02381108 0.05522555 0.9209633 ]\n",
            "[0.02896901 0.05213461 0.9188964 ]\n",
            "[0.03689777 0.05468788 0.90841424]\n",
            "[0.02886213 0.05290642 0.9182314 ]\n",
            "[0.05860649 0.05650928 0.88488424]\n",
            "[0.02690983 0.05256612 0.920524  ]\n",
            "[0.02428276 0.04842184 0.9272954 ]\n",
            "[0.01488423 0.05220918 0.93290657]\n",
            "[0.03213621 0.05426928 0.91359454]\n",
            "[0.02979586 0.04905318 0.9211509 ]\n",
            "[0.02198399 0.05100318 0.92701274]\n",
            "[0.02848197 0.05349975 0.9180182 ]\n",
            "[0.03722143 0.05528549 0.9074932 ]\n",
            "[0.02748945 0.0532366  0.91927403]\n",
            "[0.02945668 0.05429121 0.91625214]\n",
            "[0.03020713 0.05221699 0.9175759 ]\n",
            "[0.03662746 0.05512303 0.9082495 ]\n",
            "[0.01734553 0.05097941 0.931675  ]\n",
            "[0.00543714 0.04354396 0.9510189 ]\n",
            "[0.00660398 0.04820189 0.9451942 ]\n",
            "[0.01562649 0.05252758 0.9318459 ]\n",
            "[0.03266757 0.05271868 0.91461366]\n",
            "[0.03561831 0.05606144 0.90832025]\n",
            "[0.02773217 0.05510995 0.9171578 ]\n",
            "[0.00846967 0.04500539 0.94652486]\n",
            "[0.0110127  0.04580202 0.9431853 ]\n",
            "[0.02765595 0.0506996  0.92164445]\n",
            "[0.02870827 0.05090034 0.9203914 ]\n",
            "[0.01868043 0.04712782 0.9341917 ]\n",
            "[0.01822579 0.04968001 0.9320943 ]\n",
            "[0.02963607 0.0489645  0.9213994 ]\n",
            "[0.01586802 0.05250201 0.93163   ]\n",
            "[0.01680509 0.04586376 0.9373312 ]\n",
            "[0.02307576 0.05095549 0.9259687 ]\n",
            "[0.01006777 0.05416038 0.9357719 ]\n",
            "[0.02061294 0.0524095  0.92697763]\n",
            "[0.01644755 0.05571683 0.9278356 ]\n",
            "[0.03630107 0.0550203  0.90867865]\n",
            "[0.02482872 0.05788133 0.91729003]\n",
            "[0.02247143 0.05114051 0.9263881 ]\n",
            "[0.01084013 0.04655512 0.9426047 ]\n",
            "[0.03318955 0.05665078 0.9101596 ]\n",
            "[0.01308531 0.04974538 0.9371693 ]\n",
            "[0.01560764 0.05257769 0.9318146 ]\n",
            "[0.01364818 0.04538728 0.9409646 ]\n",
            "[0.01770833 0.04992362 0.932368  ]\n",
            "[0.01308239 0.04939316 0.9375245 ]\n",
            "[0.01205017 0.04912683 0.938823  ]\n",
            "[0.01185198 0.04656428 0.94158375]\n",
            "[0.02895658 0.0528997  0.9181438 ]\n",
            "[0.03508081 0.05046974 0.91444945]\n",
            "[0.03272011 0.05522745 0.91205245]\n",
            "[0.02935732 0.0553041  0.9153385 ]\n",
            "[0.03300751 0.05360204 0.91339046]\n",
            "[0.01477528 0.04923101 0.9359936 ]\n",
            "[0.02937335 0.05236415 0.9182626 ]\n",
            "[0.00952451 0.04395205 0.9465235 ]\n",
            "[0.02828863 0.05385625 0.9178551 ]\n",
            "[0.00480101 0.04122511 0.9539739 ]\n",
            "[0.02232524 0.05181516 0.9258597 ]\n",
            "[0.03073846 0.05333159 0.91593   ]\n",
            "[0.0072338  0.04604437 0.94672185]\n",
            "[0.02987694 0.05250576 0.9176173 ]\n",
            "[0.02387918 0.05145804 0.92466277]\n",
            "[0.01766724 0.05266906 0.9296638 ]\n",
            "[0.01320743 0.04594298 0.94084966]\n",
            "[0.01144011 0.05491728 0.9336426 ]\n",
            "[0.0282505  0.05295077 0.91879874]\n",
            "[0.036877   0.05518643 0.90793663]\n",
            "[0.02382914 0.05428623 0.9218846 ]\n",
            "[0.01857008 0.04784813 0.9335817 ]\n",
            "[0.03023615 0.05391762 0.9158463 ]\n",
            "[0.01566199 0.05259507 0.9317429 ]\n",
            "[0.03313826 0.0536317  0.91323006]\n",
            "[0.01906922 0.04809211 0.9328387 ]\n",
            "[0.03357866 0.05838251 0.90803885]\n",
            "[0.03695556 0.05277472 0.9102696 ]\n",
            "[0.00735493 0.04860738 0.94403774]\n",
            "[0.02051447 0.04851334 0.9309722 ]\n",
            "[0.03011913 0.05475016 0.91513073]\n",
            "[0.00943809 0.04759045 0.94297147]\n",
            "[0.01442673 0.05097368 0.9345996 ]\n",
            "[0.03480597 0.05359797 0.9115961 ]\n",
            "[0.0058647  0.04045244 0.9536829 ]\n",
            "[0.03405872 0.05255638 0.913385  ]\n",
            "[0.01078453 0.05097736 0.93823814]\n",
            "[0.03115127 0.05326397 0.9155847 ]\n",
            "[0.01406126 0.05393856 0.93200016]\n",
            "[0.01059273 0.05067626 0.93873096]\n",
            "[0.0139583  0.04482894 0.9412128 ]\n",
            "[0.03781293 0.05701961 0.90516746]\n",
            "[0.03603189 0.05658783 0.9073803 ]\n",
            "[0.01584734 0.05113989 0.9330127 ]\n",
            "[0.02203412 0.05241294 0.9255529 ]\n",
            "[0.01639616 0.05042308 0.93318087]\n",
            "[0.03572978 0.05436009 0.90991014]\n",
            "[0.01800448 0.04976929 0.93222624]\n",
            "[0.00976116 0.04558932 0.9446496 ]\n",
            "[0.00698056 0.04418243 0.948837  ]\n",
            "[0.03043916 0.05206488 0.91749597]\n",
            "[0.03830928 0.05415817 0.9075325 ]\n",
            "[0.02321745 0.05368116 0.92310137]\n",
            "[0.02078755 0.04699907 0.93221337]\n",
            "[0.06764276 0.050359   0.8819983 ]\n",
            "[0.01213136 0.04379423 0.9440744 ]\n",
            "[0.02601771 0.05226335 0.921719  ]\n",
            "[0.03176793 0.05413215 0.91409993]\n",
            "[0.03152994 0.04627978 0.9221903 ]\n",
            "[0.01777039 0.04989222 0.9323374 ]\n",
            "[0.02242874 0.05112287 0.92644835]\n",
            "[0.01314137 0.05194142 0.9349172 ]\n",
            "[0.00877849 0.04513824 0.94608325]\n",
            "[0.01220771 0.04396575 0.9438265 ]\n",
            "[0.03425947 0.05781728 0.9079233 ]\n",
            "[0.0281471  0.04892806 0.9229249 ]\n",
            "[0.01517691 0.05156568 0.93325746]\n",
            "[0.05441863 0.055998   0.88958335]\n",
            "[0.03662862 0.05507593 0.90829545]\n",
            "[0.01560884 0.05518195 0.92920923]\n",
            "[0.03009717 0.05589082 0.9140121 ]\n",
            "[0.02353233 0.05743685 0.9190308 ]\n",
            "[0.02493957 0.0484764  0.926584  ]\n",
            "[0.00513816 0.04336609 0.9514958 ]\n",
            "[0.00668552 0.04406241 0.94925207]\n",
            "[0.03145674 0.05341879 0.91512454]\n",
            "[0.03144737 0.05311057 0.9154421 ]\n",
            "[0.03018474 0.05499808 0.9148173 ]\n",
            "[0.04240417 0.05371789 0.9038779 ]\n",
            "[0.01923573 0.04749526 0.93326896]\n",
            "[0.01733583 0.04881526 0.9338489 ]\n",
            "[0.03655047 0.05506995 0.9083796 ]\n",
            "[0.01421669 0.0508903  0.9348929 ]\n",
            "[0.07799537 0.05634264 0.865662  ]\n",
            "[0.03774652 0.05699475 0.9052587 ]\n",
            "[0.01058942 0.05481487 0.93459576]\n",
            "[0.02676687 0.05251872 0.92071444]\n",
            "[0.01205022 0.04896796 0.9389819 ]\n",
            "[0.01835849 0.05489005 0.9267515 ]\n",
            "[0.0657761  0.05071909 0.8835048 ]\n",
            "[0.03082488 0.05797903 0.9111961 ]\n",
            "[0.01612826 0.05081793 0.9330538 ]\n",
            "[0.02127663 0.05281577 0.9259076 ]\n",
            "[0.0397159  0.05712511 0.903159  ]\n",
            "[0.00664658 0.04306937 0.95028394]\n",
            "[0.03033423 0.05515443 0.9145114 ]\n",
            "[0.00609458 0.03937069 0.95453477]\n",
            "[0.02200014 0.05101345 0.92698634]\n",
            "[0.01105859 0.04880867 0.94013286]\n",
            "[0.02067583 0.05037707 0.92894703]\n",
            "[0.02412715 0.05775687 0.918116  ]\n",
            "[0.02869338 0.0529148  0.91839176]\n",
            "[0.03317263 0.05201507 0.91481227]\n",
            "[0.02177423 0.05386909 0.9243567 ]\n",
            "[0.03294884 0.05206373 0.9149875 ]\n",
            "[0.01406973 0.04487058 0.9410597 ]\n",
            "[0.01350367 0.046165   0.9403313 ]\n",
            "[0.02948585 0.05379578 0.9167183 ]\n",
            "[0.06763505 0.05061218 0.8817528 ]\n",
            "[0.03014657 0.05606496 0.91378856]\n",
            "[0.02393628 0.05005696 0.92600673]\n",
            "[0.03137553 0.0542507  0.9143738 ]\n",
            "[0.03459959 0.05740263 0.9079977 ]\n",
            "[0.00550859 0.0393209  0.95517045]\n",
            "[0.0339759  0.05263698 0.9133872 ]\n",
            "[0.03008022 0.05640469 0.9135151 ]\n",
            "[0.01694811 0.05094574 0.9321061 ]\n",
            "[0.02289172 0.05622932 0.920879  ]\n",
            "[0.01614073 0.05247305 0.9313862 ]\n",
            "[0.01641343 0.05249967 0.9310869 ]\n",
            "[0.01366305 0.05066312 0.9356738 ]\n",
            "[0.01819563 0.05132765 0.93047667]\n",
            "[0.01939659 0.05168027 0.92892313]\n",
            "[0.03564154 0.0549271  0.9094314 ]\n",
            "[0.01461979 0.04642297 0.9389572 ]\n",
            "[0.0105294  0.04416965 0.94530094]\n",
            "[0.01359165 0.04437656 0.94203186]\n",
            "[0.00528302 0.04130336 0.95341355]\n",
            "[0.02789952 0.05286457 0.9192358 ]\n",
            "[0.01324618 0.04949052 0.9372633 ]\n",
            "[0.01545093 0.0556572  0.9288919 ]\n",
            "[0.02726655 0.05236555 0.92036796]\n",
            "[0.00834049 0.0438016  0.9478579 ]\n",
            "[0.03541208 0.05613862 0.9084493 ]\n",
            "[0.02639871 0.05545281 0.9181485 ]\n",
            "[0.01052041 0.05044894 0.9390306 ]\n",
            "[0.06465646 0.05073062 0.884613  ]\n",
            "[0.01879535 0.04739756 0.93380713]\n",
            "[0.00600063 0.04004617 0.95395315]\n",
            "[0.06695681 0.05679224 0.876251  ]\n",
            "[0.03175932 0.05493696 0.91330373]\n",
            "[0.028191   0.05168375 0.92012525]\n",
            "[0.02345032 0.05189709 0.92465264]\n",
            "[0.01123053 0.04291234 0.9458571 ]\n",
            "[0.01377004 0.04471407 0.94151586]\n",
            "[0.02936264 0.05236385 0.91827357]\n",
            "[0.01472794 0.04737921 0.9378929 ]\n",
            "[0.01174628 0.04808354 0.9401702 ]\n",
            "[0.01293932 0.04493151 0.9421292 ]\n",
            "[0.05091223 0.06015381 0.8889339 ]\n",
            "[0.03998477 0.05240961 0.9076056 ]\n",
            "[0.00609681 0.03995813 0.95394504]\n",
            "[0.02525867 0.04842773 0.9263136 ]\n",
            "[0.02978478 0.05528697 0.9149282 ]\n",
            "[0.0160949  0.05585999 0.9280451 ]\n",
            "[0.03266563 0.05455936 0.91277504]\n",
            "[0.01321527 0.05260224 0.9341825 ]\n",
            "[0.02764913 0.05269767 0.91965324]\n",
            "[0.03186494 0.05434078 0.91379434]\n",
            "[0.00961012 0.04836099 0.942029  ]\n",
            "[0.01080029 0.0440176  0.9451821 ]\n",
            "[0.01052189 0.05042556 0.9390525 ]\n",
            "[0.01035996 0.04414526 0.9454947 ]\n",
            "[0.01445707 0.04690474 0.93863815]\n",
            "[0.02247741 0.05115291 0.92636967]\n",
            "[0.0360836  0.05395278 0.9099636 ]\n",
            "[0.01495396 0.04627824 0.93876785]\n",
            "[0.01434521 0.04493139 0.94072336]\n",
            "[0.01234091 0.04818267 0.9394765 ]\n",
            "[0.03515498 0.05784328 0.9070017 ]\n",
            "[0.00588534 0.03927568 0.954839  ]\n",
            "[0.03236428 0.05655261 0.91108316]\n",
            "[0.01232479 0.05289335 0.93478185]\n",
            "[0.01224103 0.04379758 0.9439614 ]\n",
            "[0.00525739 0.04065285 0.9540899 ]\n",
            "[0.02948734 0.05541034 0.91510236]\n",
            "[0.01250848 0.05435794 0.9331335 ]\n",
            "[0.01869942 0.04662638 0.93467426]\n",
            "[0.02943761 0.05238464 0.9181778 ]\n",
            "[0.01357451 0.04939947 0.93702596]\n",
            "[0.0105247  0.05058959 0.93888575]\n",
            "[0.01880109 0.0550312  0.92616767]\n",
            "[0.03725787 0.05531864 0.90742344]\n",
            "[0.04075299 0.05673922 0.90250784]\n",
            "[0.01873048 0.04749782 0.93377167]\n",
            "[0.01518793 0.04789717 0.9369149 ]\n",
            "[0.00576002 0.03861116 0.9556288 ]\n",
            "[0.01907657 0.05019754 0.9307259 ]\n",
            "[0.01080262 0.04661038 0.94258696]\n",
            "[0.00970526 0.04329702 0.9469977 ]\n",
            "[0.02370762 0.04828558 0.9280068 ]\n",
            "[0.00720355 0.04773105 0.94506544]\n",
            "[0.0092614  0.04510532 0.9456333 ]\n",
            "[0.02176494 0.05289464 0.9253404 ]\n",
            "[0.02276857 0.05307    0.92416143]\n",
            "[0.01558084 0.05162911 0.93279004]\n",
            "[0.0280679  0.05087152 0.92106056]\n",
            "[0.01205799 0.04453133 0.9434107 ]\n",
            "[0.02319895 0.05289743 0.9239035 ]\n",
            "[0.04519768 0.05455184 0.9002505 ]\n",
            "[0.00753356 0.04742869 0.9450378 ]\n",
            "[0.02450291 0.05782164 0.91767544]\n",
            "[0.03580828 0.0538911  0.91030055]\n",
            "[0.0133666  0.05625612 0.93037724]\n",
            "[0.01587111 0.05030043 0.9338285 ]\n",
            "[0.01634621 0.05011076 0.9335431 ]\n",
            "[0.01031778 0.05448249 0.93519974]\n",
            "[0.00723929 0.04769566 0.945065  ]\n",
            "[0.01371886 0.04992561 0.93635553]\n",
            "[0.00933023 0.04323747 0.9474324 ]\n",
            "[0.01347075 0.04983117 0.9366981 ]\n",
            "[0.01566137 0.05074848 0.93359023]\n",
            "[0.03247693 0.0528535  0.91466963]\n",
            "[0.05513209 0.05612508 0.8887428 ]\n",
            "[0.03468747 0.05583683 0.9094757 ]\n",
            "[0.02621599 0.05534862 0.9184354 ]\n",
            "[0.00613302 0.03996368 0.95390326]\n",
            "[0.01765137 0.05117863 0.9311699 ]\n",
            "[0.03152671 0.05427588 0.9141973 ]\n",
            "[0.02492784 0.04821266 0.92685956]\n",
            "[0.01728438 0.05453956 0.92817605]\n",
            "[0.00758366 0.04011056 0.95230585]\n",
            "[0.03034093 0.05597518 0.91368383]\n",
            "[0.03562923 0.054913   0.90945774]\n",
            "[0.01233993 0.05654537 0.93111473]\n",
            "[0.02235225 0.04801799 0.92962974]\n",
            "[0.01065798 0.04470698 0.944635  ]\n",
            "[0.01543515 0.05203915 0.93252575]\n",
            "[0.06491659 0.05712692 0.87795657]\n",
            "[0.01532326 0.04638573 0.93829095]\n",
            "[0.01313044 0.04720321 0.93966645]\n",
            "[0.01520933 0.05557964 0.92921096]\n",
            "[0.00710213 0.04902596 0.9438719 ]\n",
            "[0.01772477 0.05119444 0.9310808 ]\n",
            "[0.03680064 0.05517626 0.9080231 ]\n",
            "[0.01832406 0.05375968 0.9279163 ]\n",
            "[0.02980141 0.05329522 0.9169034 ]\n",
            "[0.01063501 0.05037743 0.9389875 ]\n",
            "[0.03094755 0.05467361 0.9143788 ]\n",
            "[0.01131531 0.04889303 0.9397916 ]\n",
            "[0.02761189 0.05391555 0.91847265]\n",
            "[0.0252137  0.04703311 0.9277531 ]\n",
            "[0.02997179 0.05321677 0.9168114 ]\n",
            "[0.01702995 0.05098113 0.93198884]\n",
            "[0.03726668 0.05528613 0.9074472 ]\n",
            "[0.01854101 0.05046881 0.9309902 ]\n",
            "[0.02441018 0.05332891 0.9222608 ]\n",
            "[0.01583011 0.05005601 0.93411386]\n",
            "[0.03033403 0.05211621 0.9175498 ]\n",
            "[0.02921936 0.05678789 0.91399276]\n",
            "[0.02383972 0.04834378 0.9278165 ]\n",
            "[0.00703541 0.04074258 0.952222  ]\n",
            "[0.01578732 0.05491995 0.9292927 ]\n",
            "[0.01420222 0.05014939 0.9356484 ]\n",
            "[0.02582471 0.05392177 0.9202535 ]\n",
            "[0.01703535 0.05464725 0.92831737]\n",
            "[0.00482534 0.04177147 0.95340323]\n",
            "[0.01759655 0.05112906 0.9312743 ]\n",
            "[0.00846638 0.04639714 0.9451365 ]\n",
            "[0.03683396 0.05516993 0.90799606]\n",
            "[0.01400054 0.05178733 0.9342121 ]\n",
            "[0.01692893 0.04969192 0.9333792 ]\n",
            "[0.01410807 0.05182936 0.9340626 ]\n",
            "[0.01489941 0.0543002  0.93080044]\n",
            "[0.0177962  0.05121317 0.9309906 ]\n",
            "[0.0225492  0.05692934 0.92052144]\n",
            "[0.00856362 0.03985072 0.95158565]\n",
            "[0.03773066 0.05714411 0.9051252 ]\n",
            "[0.0117618  0.04435262 0.9438855 ]\n",
            "[0.0301774 0.0527688 0.9170539]\n",
            "[0.00966525 0.0436242  0.9467105 ]\n",
            "[0.01583034 0.05264055 0.9315291 ]\n",
            "[0.01778879 0.04816252 0.93404865]\n",
            "[0.0177846  0.05079016 0.93142515]\n",
            "[0.0179574  0.05174782 0.93029475]\n",
            "[0.02885057 0.05344556 0.91770387]\n",
            "[0.04616058 0.05338503 0.9004543 ]\n",
            "[0.01756264 0.05114135 0.93129605]\n",
            "[0.0207203  0.04771955 0.93156016]\n",
            "[0.0105388  0.05041995 0.9390412 ]\n",
            "[0.03072199 0.05440995 0.91486806]\n",
            "[0.01672605 0.05251408 0.93075985]\n",
            "[0.03589725 0.05263974 0.911463  ]\n",
            "[0.03260711 0.05520889 0.912184  ]\n",
            "[0.01541292 0.05077927 0.93380773]\n",
            "[0.00863885 0.04625626 0.94510484]\n",
            "[0.03702    0.05661888 0.90636104]\n",
            "[0.0255958  0.05066747 0.9237367 ]\n",
            "[0.01821976 0.05076109 0.93101925]\n",
            "[0.01822938 0.05182386 0.9299468 ]\n",
            "[0.01143967 0.04420935 0.94435096]\n",
            "[0.01149943 0.04770454 0.94079596]\n",
            "[0.01326783 0.04404449 0.9426877 ]\n",
            "[0.03415215 0.05168816 0.91415966]\n",
            "[0.01477249 0.04640027 0.9388272 ]\n",
            "[0.03217842 0.05509809 0.9127234 ]\n",
            "[0.07167689 0.05385766 0.87446547]\n",
            "[0.04520179 0.05449897 0.9002993 ]\n",
            "[0.02422967 0.05151829 0.9242521 ]\n",
            "[0.00525817 0.04340255 0.95133924]\n",
            "[0.01346666 0.05250432 0.93402904]\n",
            "[0.03027168 0.05566404 0.91406435]\n",
            "[0.01039631 0.05047733 0.9391263 ]\n",
            "[0.01885395 0.05200825 0.92913777]\n",
            "[0.00961802 0.04778536 0.9425967 ]\n",
            "[0.01922766 0.05121179 0.92956054]\n",
            "[0.01479987 0.04827659 0.9369236 ]\n",
            "[0.02381185 0.05252657 0.9236616 ]\n",
            "[0.01761127 0.04917818 0.9332106 ]\n",
            "[0.01858213 0.04851314 0.93290466]\n",
            "[0.01929629 0.05101608 0.9296877 ]\n",
            "[0.02152939 0.05219902 0.92627156]\n",
            "[0.01877877 0.05552335 0.9256978 ]\n",
            "[0.00798202 0.0431443  0.9488737 ]\n",
            "[0.01434072 0.05181174 0.93384755]\n",
            "[0.01137303 0.05237593 0.93625104]\n",
            "[0.00505123 0.04219643 0.95275235]\n",
            "[0.01731128 0.04729863 0.93539006]\n",
            "[0.01116851 0.04761275 0.9412188 ]\n",
            "[0.01297983 0.04738075 0.9396394 ]\n",
            "[0.03682351 0.05586584 0.90731066]\n",
            "[0.0070069  0.04367897 0.9493142 ]\n",
            "[0.00607312 0.04027872 0.9536482 ]\n",
            "[0.02187285 0.05095826 0.9271689 ]\n",
            "[0.01194779 0.05634253 0.93170965]\n",
            "[0.01787066 0.05170097 0.9304283 ]\n",
            "[0.01101627 0.04428504 0.9446987 ]\n",
            "[0.02730613 0.05247505 0.9202188 ]\n",
            "[0.01605299 0.05025294 0.93369406]\n",
            "[0.02583034 0.04932987 0.92483985]\n",
            "[0.00624955 0.04251536 0.95123506]\n",
            "[0.01694786 0.0496989  0.9333532 ]\n",
            "[0.01495777 0.04625254 0.9387897 ]\n",
            "[0.0112166  0.04844913 0.94033426]\n",
            "[0.01808908 0.04670168 0.9352092 ]\n",
            "[0.01635753 0.05094119 0.9327013 ]\n",
            "[0.01357678 0.04693391 0.9394893 ]\n",
            "[0.03243822 0.05309347 0.9144684 ]\n",
            "[0.04321116 0.05319927 0.9035896 ]\n",
            "[0.02927043 0.05689334 0.91383624]\n",
            "[0.03124345 0.05339339 0.9153632 ]\n",
            "[0.03880681 0.05708029 0.9041129 ]\n",
            "[0.01352772 0.04467707 0.94179523]\n",
            "[0.01446206 0.04665454 0.9388833 ]\n",
            "[0.02112207 0.04871548 0.9301625 ]\n",
            "[0.01053676 0.05048031 0.93898296]\n",
            "[0.01129973 0.04733919 0.941361  ]\n",
            "[0.01664364 0.05084644 0.9325099 ]\n",
            "[0.01648128 0.05146832 0.93205047]\n",
            "[0.02942827 0.0525138  0.918058  ]\n",
            "[0.01697395 0.04969432 0.9333317 ]\n",
            "[0.01236368 0.04459722 0.9430392 ]\n",
            "[0.02592077 0.05188074 0.9221984 ]\n",
            "[0.01950804 0.05508556 0.9254064 ]\n",
            "[0.03002297 0.05387587 0.91610116]\n",
            "[0.03212323 0.05429735 0.91357946]\n",
            "[0.01665106 0.0515829  0.9317661 ]\n",
            "[0.00965528 0.0512325  0.9391121 ]\n",
            "[0.0110467  0.05162323 0.93733007]\n",
            "[0.01752292 0.051196   0.93128103]\n",
            "[0.01427637 0.0468606  0.93886304]\n",
            "[0.06856295 0.05498467 0.87645245]\n",
            "[0.00681652 0.04453048 0.948653  ]\n",
            "[0.03576506 0.05760723 0.90662766]\n",
            "[0.02829416 0.05273839 0.91896737]\n",
            "[0.01035384 0.04388131 0.94576484]\n",
            "[0.03516347 0.05793326 0.9069033 ]\n",
            "[0.02250483 0.05117028 0.92632496]\n",
            "[0.02129556 0.05275989 0.92594457]\n",
            "[0.03109912 0.05324357 0.91565734]\n",
            "[0.01589356 0.0502961  0.93381035]\n",
            "[0.03312254 0.05211395 0.9147635 ]\n",
            "[0.04082616 0.05330601 0.9058678 ]\n",
            "[0.01229697 0.04821219 0.9394909 ]\n",
            "[0.01680205 0.05069967 0.9324983 ]\n",
            "[0.01392716 0.04492478 0.94114804]\n",
            "[0.02901524 0.05298412 0.91800064]\n",
            "[0.03821869 0.05718234 0.904599  ]\n",
            "[0.01417029 0.04596411 0.93986565]\n",
            "[0.00727483 0.04400462 0.9487206 ]\n",
            "[0.03731197 0.05530658 0.9073814 ]\n",
            "[0.01065421 0.05036293 0.93898284]\n",
            "[0.01070529 0.04875822 0.94053644]\n",
            "[0.02180819 0.05272694 0.92546487]\n",
            "[0.02778276 0.05517525 0.9170419 ]\n",
            "[0.01305027 0.05472168 0.9322281 ]\n",
            "[0.06632417 0.05708338 0.8765924 ]\n",
            "[0.02173166 0.05060314 0.9276652 ]\n",
            "[0.0158445  0.04808624 0.93606925]\n",
            "[0.03088741 0.05191537 0.91719717]\n",
            "[0.01014337 0.04603342 0.94382316]\n",
            "[0.01759499 0.0491346  0.93327045]\n",
            "[0.10886615 0.05873017 0.83240366]\n",
            "[0.03133263 0.05312806 0.9155392 ]\n",
            "[0.03073003 0.05434077 0.9149292 ]\n",
            "[0.0364528  0.05501999 0.9085272 ]\n",
            "[0.02410267 0.05323226 0.922665  ]\n",
            "[0.06654143 0.05326391 0.88019454]\n",
            "[0.02992155 0.05225585 0.91782266]\n",
            "[0.01003103 0.05411346 0.9358555 ]\n",
            "[0.03267653 0.0528977  0.91442585]\n",
            "[0.00999584 0.05406752 0.9359366 ]\n",
            "[0.02461539 0.05340343 0.92198116]\n",
            "[0.04634359 0.05332179 0.90033466]\n",
            "[0.02135717 0.05245155 0.9261913 ]\n",
            "[0.03542488 0.05771445 0.90686065]\n",
            "[0.0109407  0.04542408 0.9436353 ]\n",
            "[0.00532167 0.04131318 0.9533652 ]\n",
            "2049\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(testing_X))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqHGjikJ-1J1",
        "outputId": "e6060220-cecd-4d98-ba75-7cec1b57a06f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2502\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! apt-get -qq install xxd\n",
        "\n",
        "\n",
        "!echo \"const unsigned char model_data[] = {\" > /content/model_small.h\n",
        "!cat test.tflite | xxd -i      >> /content/model_small.h\n",
        "!echo \"};\"                              >> /content/model_small.h\n",
        "\n",
        "import os\n",
        "model_h_size = os.path.getsize(\"model_small.h\")\n",
        "print(f\"Header file, model.h, is {model_h_size:,} bytes.\")\n",
        "print(\"\\nOpen the side panel (refresh if needed). Double click model.h to download the file.\")"
      ],
      "metadata": {
        "id": "U5AmiARm-1Oi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04168e39-b8bf-4390-9426-f3dc3f1b0e40"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting previously unselected package xxd.\n",
            "(Reading database ... 155335 files and directories currently installed.)\n",
            "Preparing to unpack .../xxd_2%3a8.0.1453-1ubuntu1.8_amd64.deb ...\n",
            "Unpacking xxd (2:8.0.1453-1ubuntu1.8) ...\n",
            "Setting up xxd (2:8.0.1453-1ubuntu1.8) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Header file, model.h, is 29,319 bytes.\n",
            "\n",
            "Open the side panel (refresh if needed). Double click model.h to download the file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "O8tMgcc77SXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PHhSfj4G7SaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "m0-5xKVy7SdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ETVCSrsa7SkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CpTjjcyr7Sng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFSUa_m3D2bD"
      },
      "outputs": [],
      "source": [
        "#try to create a bigger dataset that is split into train and testing, but first, let's port the model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tflite_interpreter = tf.lite.Interpreter(model_path='no_magneto_b64_007_94_small.tflite')\n",
        "tflite_interpreter.allocate_tensors()\n",
        "\n",
        "'''\n",
        "Check input/output details\n",
        "'''\n",
        "input_details = tflite_interpreter.get_input_details()\n",
        "output_details = tflite_interpreter.get_output_details()\n",
        "\n",
        "print(\"== Input details ==\")\n",
        "print(\"name:\", input_details[0]['name'])\n",
        "print(\"shape:\", input_details[0]['shape'])\n",
        "print(\"type:\", input_details[0]['dtype'])\n",
        "print(\"\\n== Output details ==\")\n",
        "print(\"name:\", output_details[0]['name'])\n",
        "print(\"shape:\", output_details[0]['shape'])\n",
        "print(\"type:\", output_details[0]['dtype'])\n",
        "\n",
        "'''\n",
        "Run prediction (optional), input_array has input's shape and dtype\n",
        "'''\n",
        "input_array = np.array([[[0.] for _ in range(30)]], dtype=np.float32)\n",
        "\n",
        "tflite_interpreter.set_tensor(input_details[0]['index'], input_array)\n",
        "tflite_interpreter.invoke()\n",
        "output_array = tflite_interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "'''\n",
        "This gives a list of dictionaries. \n",
        "'''\n",
        "tensor_details = tflite_interpreter.get_tensor_details()\n",
        "\n",
        "for dict in tensor_details:\n",
        "    i = dict['index']\n",
        "    tensor_name = dict['name']\n",
        "    scales = dict['quantization_parameters']['scales']\n",
        "    zero_points = dict['quantization_parameters']['zero_points']\n",
        "    tensor = tflite_interpreter.tensor(i)()\n",
        "\n",
        "    print(i, type, scales.shape, zero_points.shape, tensor.shape)\n",
        "\n",
        "    '''\n",
        "    See note below\n",
        "    '''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mEB1MYQWApN",
        "outputId": "39ab704a-4fac-4d41-f7b6-0aac7e170a57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Input details ==\n",
            "name: serving_default_Dense1_input:0\n",
            "shape: [ 1 30  1]\n",
            "type: <class 'numpy.float32'>\n",
            "\n",
            "== Output details ==\n",
            "name: StatefulPartitionedCall:0\n",
            "shape: [1 3]\n",
            "type: <class 'numpy.float32'>\n",
            "0 <class 'type'> (0,) (0,) (1, 30, 1)\n",
            "1 <class 'type'> (0,) (0,) (3,)\n",
            "2 <class 'type'> (0,) (0,) (8,)\n",
            "3 <class 'type'> (0,) (0,) (16,)\n",
            "4 <class 'type'> (0,) (0,) (32,)\n",
            "5 <class 'type'> (0,) (0,) (64,)\n",
            "6 <class 'type'> (0,) (0,) (2,)\n",
            "7 <class 'type'> (0,) (0,) (2,)\n",
            "8 <class 'type'> (0,) (0,) (1,)\n",
            "9 <class 'type'> (0,) (0,) (1,)\n",
            "10 <class 'type'> (0,) (0,) (1,)\n",
            "11 <class 'type'> (0,) (0,) (1,)\n",
            "12 <class 'type'> (0,) (0,) (1,)\n",
            "13 <class 'type'> (0,) (0,) (64, 1)\n",
            "14 <class 'type'> (0,) (0,) (32, 64)\n",
            "15 <class 'type'> (0,) (0,) (16, 32)\n",
            "16 <class 'type'> (0,) (0,) (8, 480)\n",
            "17 <class 'type'> (0,) (0,) (3, 8)\n",
            "18 <class 'type'> (0,) (0,) (3,)\n",
            "19 <class 'type'> (0,) (0,) (1,)\n",
            "20 <class 'type'> (0,) (0,) ()\n",
            "21 <class 'type'> (0,) (0,) (2,)\n",
            "22 <class 'type'> (0,) (0,) ()\n",
            "23 <class 'type'> (0,) (0,) (2,)\n",
            "24 <class 'type'> (0,) (0,) (3,)\n",
            "25 <class 'type'> (0,) (0,) (30, 1)\n",
            "26 <class 'type'> (0,) (0,) (30, 64)\n",
            "27 <class 'type'> (0,) (0,) (1, 30, 64)\n",
            "28 <class 'type'> (0,) (0,) (1, 30, 64)\n",
            "29 <class 'type'> (0,) (0,) (3,)\n",
            "30 <class 'type'> (0,) (0,) (2,)\n",
            "31 <class 'type'> (0,) (0,) ()\n",
            "32 <class 'type'> (0,) (0,) (3,)\n",
            "33 <class 'type'> (0,) (0,) (1,)\n",
            "34 <class 'type'> (0,) (0,) ()\n",
            "35 <class 'type'> (0,) (0,) (2,)\n",
            "36 <class 'type'> (0,) (0,) (30, 64)\n",
            "37 <class 'type'> (0,) (0,) (30, 32)\n",
            "38 <class 'type'> (0,) (0,) (1, 30, 32)\n",
            "39 <class 'type'> (0,) (0,) (1, 30, 32)\n",
            "40 <class 'type'> (0,) (0,) (3,)\n",
            "41 <class 'type'> (0,) (0,) (2,)\n",
            "42 <class 'type'> (0,) (0,) ()\n",
            "43 <class 'type'> (0,) (0,) (3,)\n",
            "44 <class 'type'> (0,) (0,) (1,)\n",
            "45 <class 'type'> (0,) (0,) ()\n",
            "46 <class 'type'> (0,) (0,) (2,)\n",
            "47 <class 'type'> (0,) (0,) (30, 32)\n",
            "48 <class 'type'> (0,) (0,) (30, 16)\n",
            "49 <class 'type'> (0,) (0,) (1, 30, 16)\n",
            "50 <class 'type'> (0,) (0,) (1, 30, 16)\n",
            "51 <class 'type'> (0,) (0,) (1, 480)\n",
            "52 <class 'type'> (0,) (0,) (1, 8)\n",
            "53 <class 'type'> (0,) (0,) (1, 3)\n",
            "54 <class 'type'> (0,) (0,) (1, 3)\n",
            "55 <class 'type'> (0,) (0,) (1,)\n",
            "56 <class 'type'> (0,) (0,) (1,)\n",
            "57 <class 'type'> (0,) (0,) (1,)\n",
            "58 <class 'type'> (0,) (0,) (1,)\n",
            "59 <class 'type'> (0,) (0,) (1,)\n",
            "60 <class 'type'> (0,) (0,) (1,)\n",
            "67 <class 'type'> (0,) (0,) (1,)\n",
            "68 <class 'type'> (0,) (0,) (1,)\n",
            "69 <class 'type'> (0,) (0,) (1,)\n",
            "70 <class 'type'> (0,) (0,) (1,)\n",
            "71 <class 'type'> (0,) (0,) (1,)\n",
            "72 <class 'type'> (0,) (0,) (1,)\n",
            "79 <class 'type'> (0,) (0,) (1,)\n",
            "80 <class 'type'> (0,) (0,) (1,)\n",
            "81 <class 'type'> (0,) (0,) (1,)\n",
            "82 <class 'type'> (0,) (0,) (1,)\n",
            "83 <class 'type'> (0,) (0,) (1,)\n",
            "84 <class 'type'> (0,) (0,) (1,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tinymlgen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilSOEmK-WArw",
        "outputId": "7f9f63a2-eaaa-47df-c32a-10612d22cfe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tinymlgen in /usr/local/lib/python3.7/dist-packages (0.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from tinymlgen) (2.8.0)\n",
            "Requirement already satisfied: hexdump in /usr/local/lib/python3.7/dist-packages (from tinymlgen) (3.3)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tinymlgen) (13.0.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tinymlgen) (1.1.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tinymlgen) (2.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tinymlgen) (3.10.0.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tinymlgen) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tinymlgen) (3.17.3)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tinymlgen) (2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tinymlgen) (1.44.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow->tinymlgen) (57.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tinymlgen) (0.24.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tinymlgen) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tinymlgen) (0.5.3)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tinymlgen) (2.8.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tinymlgen) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tinymlgen) (1.13.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tinymlgen) (1.6.3)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tinymlgen) (1.21.5)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tinymlgen) (1.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tinymlgen) (3.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tinymlgen) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tinymlgen) (1.1.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->tinymlgen) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->tinymlgen) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->tinymlgen) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->tinymlgen) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->tinymlgen) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->tinymlgen) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->tinymlgen) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->tinymlgen) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->tinymlgen) (2.23.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->tinymlgen) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->tinymlgen) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->tinymlgen) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->tinymlgen) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->tinymlgen) (4.11.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->tinymlgen) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->tinymlgen) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->tinymlgen) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->tinymlgen) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->tinymlgen) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->tinymlgen) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->tinymlgen) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tinymlgen import port\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    tf_model = model\n",
        "    c_code = port(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TRQsDPgWAvo",
        "outputId": "51dab2b4-cf51-4479-cfe7-97f0e749c9ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
            "WARNING:absl:Function `_wrapped_model` contains input name(s) Dense1_input with unsupported characters which will be renamed to dense1_input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpujk1x9mo/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpujk1x9mo/assets\n",
            "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
            "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_file = open(\"weights.txt\", \"w\")\n",
        "n = text_file.write(c_code)\n",
        "text_file.close()"
      ],
      "metadata": {
        "id": "2Gowh0nbWAxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kMM83kdyWAzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Rg8t2_wKWA2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UNhvVYDhWA49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kTwlowaBWA7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9kHGx1rD2bD"
      },
      "outputs": [],
      "source": [
        "#############STAHP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4-FDlYWD2bE"
      },
      "outputs": [],
      "source": [
        "#fft check for moves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NufgONyVD2bE"
      },
      "outputs": [],
      "source": [
        "def plot_signal_and_fft(sig):\n",
        "    \n",
        "    fourierTransform = np.fft.rfft(sig)/len(sig)           # Normalize amplitude\n",
        "    fourierTransform = fourierTransform[range(int(len(sig)/2))] # Exclude sampling frequency\n",
        "    np.abs(np.max(fourierTransform))\n",
        "    \n",
        "    tpCount     = len(sig)\n",
        "\n",
        "    values      = np.arange(int(tpCount/2))\n",
        "\n",
        "    timePeriod  = tpCount/SAMPLE_RATE\n",
        "\n",
        "    frequencies = values/(timePeriod)\n",
        "    \n",
        "    print(np.abs(np.max(fourierTransform)), np.argmax(fourierTransform))\n",
        "    \n",
        "    #print(Re(np.max(fourierTransform)) + Im(np.max(fourierTransform)))\n",
        "\n",
        "    \n",
        "    plot_sig = sig#np.subtract(sig,np.average(sig))\n",
        "    \n",
        "    #yf = fft(plot_sig)\n",
        "    #xf = fftfreq(len(plot_sig), 1 / SAMPLE_RATE)\n",
        "    \n",
        "    plt.grid()\n",
        "    plt.plot(np.abs(np.abs(fourierTransform)))\n",
        "    #plt.plot(frequencies, np.abs(fourierTransform))\n",
        "                 #plt.plot(xf, np.abs(yf))\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ac_RzF6OD2bE"
      },
      "outputs": [],
      "source": [
        "def check_signal(data, sig, index=0, normalize=True):    \n",
        "    signals = data.values\n",
        "    signals = copy.deepcopy(signals[:, 1:]) #don't need the time here\n",
        "    \n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        normalize_columns(signals, \"a\")\n",
        "        normalize_columns(signals, \"g\")\n",
        "        normalize_columns(signals, \"m\")\n",
        "    \"\"\"\n",
        "    signals = np.transpose(signals)\n",
        "    \n",
        "    to_transform = signals[sig, index:index+WINDOW_SIZE]\n",
        "    to_transform = to_transform - np.mean(to_transform)\n",
        "    \n",
        "    plot_signal_and_fft(to_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDUZmHEbD2bE",
        "outputId": "2dca5235-604c-4e6d-bb8b-c19cc4840b6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0010500698246999909 8\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "check_signal(data_df, 0, 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsiyG_t6D2bE"
      },
      "outputs": [],
      "source": [
        "no_idx, left_idx, right_idx = np.where(dY == 1), np.where(dY == 0), np.where(dY == 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FebqirE_D2bE",
        "outputId": "fb3bc6b4-0f3b-4763-9f3b-7a48a30fbad6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([ 6877,  6878,  6879, ..., 56306, 56307, 56308], dtype=int64),)"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "right_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqjOHWc9D2bE",
        "outputId": "634fba9c-bf53-47b8-c459-49136417551d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "6900 in right_idx[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X597xvekD2bF"
      },
      "outputs": [],
      "source": [
        "def plot_stuff(index=25):\n",
        "    ax = inputs[index][:, :1]\n",
        "    ay = inputs[index][:, 1:2]\n",
        "    az = inputs[index][:, 2:3]\n",
        "    gx = inputs[index][:, 3:4]\n",
        "    gy = inputs[index][:, 4:5]\n",
        "    gz = inputs[index][:, 5:]\n",
        "    \n",
        "    ax = ax.reshape((1,150))\n",
        "    ay = ay.reshape((1,150))\n",
        "    az = az.reshape((1,150))\n",
        "    gx = gx.reshape((1,150))\n",
        "    gy = gy.reshape((1,150))\n",
        "    gz = gz.reshape((1,150))\n",
        "    \n",
        "    xr = range(SAMPLES_PER_GESTURE)\n",
        "    plt.plot(xr, ax[0])\n",
        "    plt.plot(xr, ay[0])\n",
        "    plt.plot(xr, az[0])\n",
        "    plt.legend([\"aX\", \"aY\", \"aZ\"])\n",
        "    plt.grid()\n",
        "    plt.ylabel(\"Acceleration values\")\n",
        "    plt.xlabel(\"Samples\")\n",
        "    plt.savefig(\"acc_test_visualize_noisy.png\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CuiIUd5rD2bF"
      },
      "outputs": [],
      "source": [
        "data_df.agg([min, max])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TK-6BVLxD2bF"
      },
      "outputs": [],
      "source": [
        "nb_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCZUyhbqD2bF"
      },
      "outputs": [],
      "source": [
        "test_nb_values = copy.deepcopy(nb_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ocwa_S85D2bF"
      },
      "outputs": [],
      "source": [
        "test_nb_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLU5qywUD2bF"
      },
      "outputs": [],
      "source": [
        "normalize_columns(test_nb_values, column_type=\"a\")\n",
        "normalize_columns(test_nb_values, column_type=\"m\")\n",
        "normalize_columns(test_nb_values, column_type=\"g\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZFTdybkD2bF"
      },
      "outputs": [],
      "source": [
        "test_nb_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWhW81qBD2bF"
      },
      "outputs": [],
      "source": [
        "only_acc_gyro = test_nb_values[:, :-3]\n",
        "only_acc_gyro.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IExoo4mfD2bG"
      },
      "outputs": [],
      "source": [
        "summed_signals = np.sum(only_acc_gyro, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnfDgPYCD2bG"
      },
      "outputs": [],
      "source": [
        "summed_signals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmcUJTIPD2bG"
      },
      "outputs": [],
      "source": [
        "def plot_arr(arr, _range=None):\n",
        "    if _range is not None:\n",
        "        x = np.arange(0, _range[1] - _range[0])\n",
        "        plt.plot(x, arr[_range[0]: _range[1]])\n",
        "    else:\n",
        "        x = np.arange(0, len(arr))\n",
        "        plt.plot(x, arr)\n",
        "    #plt.plot(x, arr[_range[0]: _range[1]])\n",
        "    plt.grid()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGmFEeFPD2bG"
      },
      "outputs": [],
      "source": [
        "plot_arr(summed_signals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Oy_lyNpD2bG"
      },
      "outputs": [],
      "source": [
        "yf = fft(summed_signals)\n",
        "xf = fftfreq(len(summed_signals), 1 / SAMPLE_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUn3kL2vD2bG"
      },
      "outputs": [],
      "source": [
        "plt.plot(xf, np.abs(yf))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgWC31ZPD2bG"
      },
      "outputs": [],
      "source": [
        "np.argmax(yf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40TkCvE2D2bG"
      },
      "outputs": [],
      "source": [
        "yf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyI-bi4YD2bH"
      },
      "outputs": [],
      "source": [
        "fft to discriminate between the two settings\n",
        "windows on the signal (doing something, not doing anything) noise vs movement (find features to discriminate between these two situations)\n",
        "amplitude could be enough as well, but there could be more\n",
        "\n",
        "focus on analysis, training set etc\n",
        "windows around the gesture when it happens, and windows on when nothing happens\n",
        "\n",
        "windows of the time series, last 5 seconds for example (classifier for right, left, nothing)\n",
        "\n",
        "window size is important!!!\n",
        "\n",
        "features associated with larger time wondows or smaller windows\n",
        "\n",
        "document infrastructure, the way data was taken, analysis method, features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9AaQ2oID2bH"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoK1qXDZD2bH"
      },
      "outputs": [],
      "source": [
        "plot_signal_and_fft(test_nb_values[:, 2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obEm2TKND2bH"
      },
      "outputs": [],
      "source": [
        "test_nb_values.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lScJQPl6D2bH"
      },
      "outputs": [],
      "source": [
        "########### LOOKING INTO MIN, MAX, AVG, MEDIAN ETC for different windows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVSwhxRxD2bH"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhjqdhyMD2bH"
      },
      "outputs": [],
      "source": [
        "save_model_lite(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCh8aoiUD2bH"
      },
      "outputs": [],
      "source": [
        "print(np.sum(one_hot_Y, axis=0))\n",
        "print(dataX.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XCJt2plD2bH"
      },
      "outputs": [],
      "source": [
        "#### create a balanced smaller dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxxIjUzSD2bH"
      },
      "outputs": [],
      "source": [
        "get_balanced_dataset(dX, dY, one_hot_Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMB_24iND2bI"
      },
      "outputs": [],
      "source": [
        "no_idx, left_idx, right_idx = np.where(dY == 1), np.where(dY == 0), np.where(dY == 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llz_F58OD2bI"
      },
      "outputs": [],
      "source": [
        "print(no_idx, left_idx, right_idx)\n",
        "print(len(left_idx[0]))\n",
        "print(len(right_idx[0]))\n",
        "bal_size = min(len(left_idx[0]), len(right_idx[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUW78MYYD2bI"
      },
      "outputs": [],
      "source": [
        "bal_left, bal_nothing, bal_right = np.random.choice(left_idx[0], size=bal_size, replace=False), np.random.choice(no_idx[0], size=bal_size, replace=False), np.random.choice(right_idx[0], size=bal_size, replace=False)   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTYuc4JdD2bI"
      },
      "outputs": [],
      "source": [
        "bal_left"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbp5CEUND2bI"
      },
      "outputs": [],
      "source": [
        "leftX, left_Y = getX_Y_bal(bal_left, dataX, one_hot_Y)\n",
        "rightX, right_Y = getX_Y_bal(bal_right, dataX, one_hot_Y)\n",
        "noX, no_Y = getX_Y_bal(bal_nothing, dataX, one_hot_Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxEBRE8yD2bI"
      },
      "outputs": [],
      "source": [
        "allY_idxs = np.concatenate([bal_nothing, bal_left, bal_right])\n",
        "print(allY_idxs)\n",
        "print(bal_nothing)\n",
        "print(bal_left)\n",
        "print(bal_right)\n",
        "allY_no_one_hot = dY[allY_idxs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVQaxaROD2bI"
      },
      "outputs": [],
      "source": [
        "evaluate_model(yo, bal_Y, allY_no_one_hot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdpwbzioD2bI"
      },
      "outputs": [],
      "source": [
        "tt = np.array([0.9536290168762207,\n",
        "  0.955600380897522,\n",
        "  0.9525731801986694,\n",
        "  0.9515640735626221,\n",
        "  0.9646821618080139])\n",
        "tt.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WRLpyX6D2bI"
      },
      "outputs": [],
      "source": [
        "bal_Y = np.concatenate([no_Y, left_Y, right_Y], axis=0)\n",
        "bal_X = np.concatenate([noX, leftX, rightX], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKkiKSSzD2bJ"
      },
      "outputs": [],
      "source": [
        "testX = copy.deepcopy(bal_X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIC4iuL6D2bJ"
      },
      "outputs": [],
      "source": [
        "yo = testX[:, :30, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siBJkuBUD2bJ"
      },
      "outputs": [],
      "source": [
        "yo.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35j7FX_DD2bJ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCrbpmlvD2bJ"
      },
      "outputs": [],
      "source": [
        "bal_model = define_model(lr=0.007)\n",
        "train_model(bal_model, yo, bal_Y, epochs=75, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cU8eLJUcD2bJ"
      },
      "outputs": [],
      "source": [
        "save_model_lite(bal_model, \"balanced_trained_bs64_no_magneto_lr_007\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NH9vINfXD2bJ"
      },
      "outputs": [],
      "source": [
        "bal_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umQf2nF6D2bJ"
      },
      "outputs": [],
      "source": [
        "bal_model = define_model(lr=0.005)\n",
        "train_model(bal_model, bal_X, bal_Y, callbacks=[lrate], epochs=75, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dX5jj2OYD2bJ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ro6xRfQ_D2bJ"
      },
      "outputs": [],
      "source": [
        "def step_decay(epoch):\n",
        "   initial_lrate = 0.07\n",
        "   drop = 0.2\n",
        "   epochs_drop = 10.0\n",
        "   lrate = initial_lrate * math.pow(drop,  \n",
        "           math.floor((1+epoch)/epochs_drop))\n",
        "   return lrate\n",
        "\n",
        "lrate = tf.keras.callbacks.LearningRateScheduler(step_decay)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "prep_analyze.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}